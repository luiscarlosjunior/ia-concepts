# Evolu√ß√£o Diferencial (Differential Evolution - DE)

A **Evolu√ß√£o Diferencial** (Differential Evolution - DE) √© um algoritmo de otimiza√ß√£o evolutiva poderoso e eficiente, desenvolvido por Rainer Storn e Kenneth Price em 1995. √â especialmente eficaz para otimiza√ß√£o de fun√ß√µes cont√≠nuas, multimodais e n√£o-diferenci√°veis, sendo amplamente utilizado em engenharia, aprendizado de m√°quina e otimiza√ß√£o num√©rica.

![Differential Evolution Concept](../../images/differential_evolution_concept.png)

O algoritmo se destaca pela sua simplicidade de implementa√ß√£o, poucos par√¢metros de controle e excelente desempenho em problemas de alta dimens√£o. A ideia central √© usar diferen√ßas vetoriais entre membros da popula√ß√£o para gerar muta√ß√µes, criando um mecanismo de busca auto-adaptativo e robusto.

---

## **1. üéØ Fundamentos Te√≥ricos**

### **1.1 Conceito Central**

A Evolu√ß√£o Diferencial opera em espa√ßos de busca cont√≠nuos e se baseia em tr√™s operadores principais:

1. **Muta√ß√£o Diferencial:** Usa diferen√ßas entre vetores da popula√ß√£o para criar novos candidatos
2. **Crossover (Recombina√ß√£o):** Combina o vetor mutante com o vetor alvo
3. **Sele√ß√£o:** Escolhe o melhor entre o candidato atual e o novo

**Intui√ß√£o:**
> "Se a diferen√ßa entre dois bons vetores aponta em uma dire√ß√£o promissora, us√°-la para criar novos candidatos pode levar a solu√ß√µes ainda melhores."

### **1.2 Por Que DE Funciona?**

#### **üîç Vantagens da Abordagem Diferencial**

```
‚úÖ Auto-adapta√ß√£o:
   - O tamanho do passo se ajusta automaticamente
   - Passos grandes em regi√µes de explora√ß√£o
   - Passos pequenos pr√≥ximo ao √≥timo

‚úÖ Balanceamento Explora√ß√£o-Explota√ß√£o:
   - Diversidade mantida pela popula√ß√£o
   - Converg√™ncia atrav√©s da sele√ß√£o gulosa

‚úÖ Simplicidade:
   - Poucos par√¢metros: F (escala), CR (crossover), NP (popula√ß√£o)
   - N√£o requer informa√ß√µes de gradiente
   - Implementa√ß√£o direta
```

#### **üìä Diferen√ßa de Outros EAs**

| Aspecto | Algoritmos Gen√©ticos | Evolution Strategies | Differential Evolution |
|---------|---------------------|---------------------|------------------------|
| **Muta√ß√£o** | Bit-flip ou Gaussiana | Gaussiana adaptativa | Diferen√ßas vetoriais |
| **Adapta√ß√£o** | Externa | Auto-adapta√ß√£o | Impl√≠cita no operador |
| **Crossover** | Importante | Opcional | Essencial (binomial) |
| **Tipo de Vari√°vel** | Bin√°ria/Real | Real | Real |
| **Aplica√ß√£o Principal** | Combinat√≥ria | Cont√≠nua | Cont√≠nua |

---

## **2. üîß Algoritmo da Evolu√ß√£o Diferencial**

### **2.1 Estrutura Geral**

```
üöÄ 1. INICIALIZA√á√ÉO
   ‚îú‚îÄ‚îÄ Gerar popula√ß√£o inicial: X‚ÇÄ = {x‚ÇÅ, x‚ÇÇ, ..., x‚Çô‚Çö}
   ‚îú‚îÄ‚îÄ Definir par√¢metros: F (escala), CR (crossover), NP (tamanho)
   ‚îî‚îÄ‚îÄ Avaliar fitness de cada indiv√≠duo

üîÑ 2. LOOP EVOLUTIVO (para cada gera√ß√£o g):
   ‚îÇ
   PARA cada indiv√≠duo x·µ¢ na popula√ß√£o:
   ‚îÇ
   ‚îú‚îÄ‚îÄ üß¨ MUTA√á√ÉO
   ‚îÇ   ‚îú‚îÄ‚îÄ Selecionar 3 vetores distintos: x·µ£‚ÇÅ, x·µ£‚ÇÇ, x·µ£‚ÇÉ (r1‚â†r2‚â†r3‚â†i)
   ‚îÇ   ‚îî‚îÄ‚îÄ Criar vetor mutante: v·µ¢ = x·µ£‚ÇÅ + F¬∑(x·µ£‚ÇÇ - x·µ£‚ÇÉ)
   ‚îÇ
   ‚îú‚îÄ‚îÄ üîÄ CROSSOVER (RECOMBINA√á√ÉO)
   ‚îÇ   ‚îú‚îÄ‚îÄ PARA cada dimens√£o j:
   ‚îÇ   ‚îÇ   SE (rand() < CR) OU (j == j·µ£‚Çê‚Çôùíπ):
   ‚îÇ   ‚îÇ       u·µ¢‚±º = v·µ¢‚±º
   ‚îÇ   ‚îÇ   SEN√ÉO:
   ‚îÇ   ‚îÇ       u·µ¢‚±º = x·µ¢‚±º
   ‚îÇ   ‚îî‚îÄ‚îÄ Vetor trial: u·µ¢ = (u·µ¢‚ÇÅ, u·µ¢‚ÇÇ, ..., u·µ¢ùíπ)
   ‚îÇ
   ‚îî‚îÄ‚îÄ üéØ SELE√á√ÉO
       SE f(u·µ¢) ‚â§ f(x·µ¢):  # Para minimiza√ß√£o
           x·µ¢‚ÅΩ·µç‚Å∫¬π‚Åæ = u·µ¢
       SEN√ÉO:
           x·µ¢‚ÅΩ·µç‚Å∫¬π‚Åæ = x·µ¢

üèÜ 3. RETORNAR melhor solu√ß√£o encontrada
```

### **2.2 Variantes do Operador de Muta√ß√£o**

A nota√ß√£o DE/x/y/z especifica:
- **x**: Vetor base (rand, best, current-to-best)
- **y**: N√∫mero de diferen√ßas vetoriais
- **z**: Tipo de crossover (bin, exp)

#### **Estrat√©gias Principais:**

**1. DE/rand/1/bin (Cl√°ssica)**
```
v·µ¢ = x·µ£‚ÇÅ + F¬∑(x·µ£‚ÇÇ - x·µ£‚ÇÉ)
```
- ‚úÖ Boa diversidade
- ‚ö™ Converg√™ncia moderada
- üéØ Uso: Explora√ß√£o ampla

**2. DE/best/1/bin**
```
v·µ¢ = xbest + F¬∑(x·µ£‚ÇÅ - x·µ£‚ÇÇ)
```
- ‚úÖ Converg√™ncia r√°pida
- ‚ùå Pode ficar preso em √≥timos locais
- üéØ Uso: Fun√ß√µes unimodais

**3. DE/current-to-best/1/bin**
```
v·µ¢ = x·µ¢ + F¬∑(xbest - x·µ¢) + F¬∑(x·µ£‚ÇÅ - x·µ£‚ÇÇ)
```
- ‚úÖ Balanceamento explora√ß√£o-explota√ß√£o
- ‚úÖ Converg√™ncia est√°vel
- üéØ Uso: Problemas multimodais

**4. DE/best/2/bin**
```
v·µ¢ = xbest + F¬∑(x·µ£‚ÇÅ - x·µ£‚ÇÇ) + F¬∑(x·µ£‚ÇÉ - x·µ£‚ÇÑ)
```
- ‚úÖ Busca mais agressiva
- ‚ö™ Requer popula√ß√£o maior
- üéØ Uso: Fun√ß√µes complexas

**5. DE/rand/2/bin**
```
v·µ¢ = x·µ£‚ÇÅ + F¬∑(x·µ£‚ÇÇ - x·µ£‚ÇÉ) + F¬∑(x·µ£‚ÇÑ - x·µ£‚ÇÖ)
```
- ‚úÖ M√°xima diversidade
- ‚ö™ Converg√™ncia mais lenta
- üéØ Uso: Alta dimensionalidade

---

## **3. üíª Implementa√ß√£o em Python**

### **3.1 Implementa√ß√£o B√°sica**

```python
import numpy as np

class DifferentialEvolution:
    """
    Implementa√ß√£o da Evolu√ß√£o Diferencial (DE/rand/1/bin)
    """
    
    def __init__(self, objective_function, bounds, pop_size=50, 
                 F=0.8, CR=0.9, max_iter=1000):
        """
        Args:
            objective_function: Fun√ß√£o a ser minimizada
            bounds: Lista de tuplas (min, max) para cada dimens√£o
            pop_size: Tamanho da popula√ß√£o (NP)
            F: Fator de escala diferencial (0 < F ‚â§ 2)
            CR: Taxa de crossover (0 ‚â§ CR ‚â§ 1)
            max_iter: N√∫mero m√°ximo de gera√ß√µes
        """
        self.f = objective_function
        self.bounds = np.array(bounds)
        self.dim = len(bounds)
        self.NP = pop_size
        self.F = F
        self.CR = CR
        self.max_iter = max_iter
        
    def initialize_population(self):
        """Inicializa popula√ß√£o aleatoriamente dentro dos limites"""
        pop = np.random.rand(self.NP, self.dim)
        for i in range(self.dim):
            pop[:, i] = self.bounds[i, 0] + pop[:, i] * (
                self.bounds[i, 1] - self.bounds[i, 0]
            )
        return pop
    
    def mutate(self, population, current_idx):
        """
        Operador de muta√ß√£o DE/rand/1
        v·µ¢ = x·µ£‚ÇÅ + F¬∑(x·µ£‚ÇÇ - x·µ£‚ÇÉ)
        """
        # Selecionar 3 √≠ndices distintos (diferentes de current_idx)
        candidates = [idx for idx in range(self.NP) if idx != current_idx]
        r1, r2, r3 = np.random.choice(candidates, 3, replace=False)
        
        # Criar vetor mutante
        mutant = population[r1] + self.F * (population[r2] - population[r3])
        
        return mutant
    
    def crossover(self, target, mutant):
        """
        Operador de crossover binomial
        """
        trial = np.copy(target)
        
        # Garantir pelo menos uma dimens√£o do mutante
        j_rand = np.random.randint(0, self.dim)
        
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == j_rand:
                trial[j] = mutant[j]
        
        return trial
    
    def clip_to_bounds(self, vector):
        """Garante que o vetor est√° dentro dos limites"""
        return np.clip(vector, self.bounds[:, 0], self.bounds[:, 1])
    
    def optimize(self):
        """Executa o algoritmo DE"""
        # Inicializa√ß√£o
        population = self.initialize_population()
        fitness = np.array([self.f(ind) for ind in population])
        
        # Melhor solu√ß√£o
        best_idx = np.argmin(fitness)
        best_solution = population[best_idx].copy()
        best_fitness = fitness[best_idx]
        
        # Hist√≥rico
        history = {
            'best_fitness': [best_fitness],
            'avg_fitness': [np.mean(fitness)],
            'std_fitness': [np.std(fitness)]
        }
        
        # Loop evolutivo
        for generation in range(self.max_iter):
            # Para cada indiv√≠duo
            for i in range(self.NP):
                # Muta√ß√£o
                mutant = self.mutate(population, i)
                
                # Garantir limites
                mutant = self.clip_to_bounds(mutant)
                
                # Crossover
                trial = self.crossover(population[i], mutant)
                
                # Sele√ß√£o
                trial_fitness = self.f(trial)
                if trial_fitness < fitness[i]:
                    population[i] = trial
                    fitness[i] = trial_fitness
                    
                    # Atualizar melhor global
                    if trial_fitness < best_fitness:
                        best_solution = trial.copy()
                        best_fitness = trial_fitness
            
            # Registrar hist√≥rico
            history['best_fitness'].append(best_fitness)
            history['avg_fitness'].append(np.mean(fitness))
            history['std_fitness'].append(np.std(fitness))
            
            # Crit√©rio de parada (opcional)
            if history['std_fitness'][-1] < 1e-8:
                print(f"Converg√™ncia atingida na gera√ß√£o {generation}")
                break
        
        return best_solution, best_fitness, history

# Exemplo de uso
def sphere_function(x):
    """Fun√ß√£o esfera: f(x) = sum(x·µ¢¬≤)"""
    return np.sum(x**2)

# Configurar problema
bounds = [(-5.0, 5.0)] * 10  # 10 dimens√µes
de = DifferentialEvolution(
    objective_function=sphere_function,
    bounds=bounds,
    pop_size=50,
    F=0.8,
    CR=0.9,
    max_iter=500
)

# Executar otimiza√ß√£o
best_solution, best_fitness, history = de.optimize()

print(f"Melhor solu√ß√£o encontrada: {best_solution}")
print(f"Melhor fitness: {best_fitness}")
```

### **3.2 Implementa√ß√£o com Estrat√©gias M√∫ltiplas**

```python
class AdaptiveDifferentialEvolution(DifferentialEvolution):
    """
    DE com m√∫ltiplas estrat√©gias de muta√ß√£o
    """
    
    def __init__(self, *args, strategy='rand/1', **kwargs):
        super().__init__(*args, **kwargs)
        self.strategy = strategy
    
    def mutate(self, population, current_idx, fitness=None):
        """Aplica estrat√©gia de muta√ß√£o selecionada"""
        candidates = [idx for idx in range(self.NP) if idx != current_idx]
        
        if self.strategy == 'rand/1':
            r1, r2, r3 = np.random.choice(candidates, 3, replace=False)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            
        elif self.strategy == 'best/1':
            best_idx = np.argmin(fitness)
            r1, r2 = np.random.choice(candidates, 2, replace=False)
            mutant = population[best_idx] + self.F * (population[r1] - population[r2])
            
        elif self.strategy == 'current-to-best/1':
            best_idx = np.argmin(fitness)
            r1, r2 = np.random.choice(candidates, 2, replace=False)
            mutant = (population[current_idx] + 
                     self.F * (population[best_idx] - population[current_idx]) +
                     self.F * (population[r1] - population[r2]))
            
        elif self.strategy == 'rand/2':
            r1, r2, r3, r4, r5 = np.random.choice(candidates, 5, replace=False)
            mutant = (population[r1] + 
                     self.F * (population[r2] - population[r3]) +
                     self.F * (population[r4] - population[r5]))
        
        else:
            raise ValueError(f"Estrat√©gia desconhecida: {self.strategy}")
        
        return mutant
```

### **3.3 Visualiza√ß√£o da Converg√™ncia**

```python
import matplotlib.pyplot as plt

def plot_convergence(history):
    """Plota converg√™ncia do algoritmo DE"""
    plt.figure(figsize=(12, 4))
    
    # Fitness ao longo das gera√ß√µes
    plt.subplot(1, 2, 1)
    plt.plot(history['best_fitness'], 'b-', label='Melhor Fitness', linewidth=2)
    plt.plot(history['avg_fitness'], 'r--', label='Fitness M√©dio', linewidth=1)
    plt.xlabel('Gera√ß√£o')
    plt.ylabel('Fitness')
    plt.title('Converg√™ncia do DE')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    
    # Diversidade da popula√ß√£o
    plt.subplot(1, 2, 2)
    plt.plot(history['std_fitness'], 'g-', linewidth=2)
    plt.xlabel('Gera√ß√£o')
    plt.ylabel('Desvio Padr√£o do Fitness')
    plt.title('Diversidade da Popula√ß√£o')
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    
    plt.tight_layout()
    plt.show()

# Uso
plot_convergence(history)
```

---

## **4. üéØ Exemplos de Aplica√ß√£o**

### **4.1 Otimiza√ß√£o de Fun√ß√µes de Benchmark**

```python
# Fun√ß√£o de Rastrigin (multimodal)
def rastrigin(x):
    """
    Fun√ß√£o de Rastrigin: altamente multimodal
    M√≠nimo global: f(0,...,0) = 0
    """
    n = len(x)
    A = 10
    return A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x))

# Fun√ß√£o de Rosenbrock (vale)
def rosenbrock(x):
    """
    Fun√ß√£o de Rosenbrock: vale estreito
    M√≠nimo global: f(1,...,1) = 0
    """
    return np.sum(100 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)

# Fun√ß√£o de Ackley
def ackley(x):
    """
    Fun√ß√£o de Ackley: muitos √≥timos locais
    M√≠nimo global: f(0,...,0) = 0
    """
    n = len(x)
    sum1 = np.sum(x**2)
    sum2 = np.sum(np.cos(2 * np.pi * x))
    return -20 * np.exp(-0.2 * np.sqrt(sum1/n)) - np.exp(sum2/n) + 20 + np.e

# Otimizar com DE
bounds = [(-5.12, 5.12)] * 10
de = DifferentialEvolution(rastrigin, bounds, pop_size=100, F=0.8, CR=0.9)
solution, fitness, history = de.optimize()

print(f"Rastrigin - Melhor fitness: {fitness:.6f}")
```

### **4.2 Ajuste de Hiperpar√¢metros de ML**

```python
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.datasets import load_iris

def optimize_svm_hyperparameters(X, y):
    """
    Otimiza hiperpar√¢metros de SVM usando DE
    """
    def objective(params):
        C, gamma = 10**params[0], 10**params[1]
        svm = SVC(C=C, gamma=gamma, kernel='rbf')
        # Minimizar erro (1 - accuracy)
        score = cross_val_score(svm, X, y, cv=5, scoring='accuracy')
        return 1 - score.mean()
    
    # Limites: log10(C) e log10(gamma)
    bounds = [(-3, 3), (-3, 3)]
    
    de = DifferentialEvolution(
        objective_function=objective,
        bounds=bounds,
        pop_size=20,
        F=0.8,
        CR=0.7,
        max_iter=50
    )
    
    best_params, best_error, history = de.optimize()
    C_opt = 10**best_params[0]
    gamma_opt = 10**best_params[1]
    
    return C_opt, gamma_opt, 1 - best_error

# Exemplo
data = load_iris()
X, y = data.data, data.target

C_opt, gamma_opt, accuracy = optimize_svm_hyperparameters(X, y)
print(f"Melhores hiperpar√¢metros:")
print(f"  C = {C_opt:.4f}")
print(f"  gamma = {gamma_opt:.4f}")
print(f"  Acur√°cia = {accuracy:.4f}")
```

### **4.3 Treinamento de Redes Neurais**

```python
def train_neural_network_with_de():
    """
    Treina uma rede neural simples usando DE
    """
    import torch
    import torch.nn as nn
    
    # Dados de exemplo
    X_train = torch.randn(100, 10)
    y_train = torch.randn(100, 1)
    
    class SimpleNet(nn.Module):
        def __init__(self, weights):
            super().__init__()
            self.fc1 = nn.Linear(10, 5)
            self.fc2 = nn.Linear(5, 1)
            self.set_weights(weights)
        
        def set_weights(self, weights):
            # Dividir vetor de pesos em camadas
            idx = 0
            # fc1: 10*5 + 5 = 55 par√¢metros
            w1_size = 10 * 5
            self.fc1.weight.data = torch.tensor(
                weights[idx:idx+w1_size].reshape(5, 10), dtype=torch.float32
            )
            idx += w1_size
            self.fc1.bias.data = torch.tensor(
                weights[idx:idx+5], dtype=torch.float32
            )
            idx += 5
            # fc2: 5*1 + 1 = 6 par√¢metros
            w2_size = 5 * 1
            self.fc2.weight.data = torch.tensor(
                weights[idx:idx+w2_size].reshape(1, 5), dtype=torch.float32
            )
            idx += w2_size
            self.fc2.bias.data = torch.tensor(
                weights[idx:idx+1], dtype=torch.float32
            )
        
        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x
    
    def objective(weights):
        model = SimpleNet(weights)
        y_pred = model(X_train)
        loss = nn.MSELoss()(y_pred, y_train)
        return loss.item()
    
    # Total de par√¢metros: 55 + 5 + 6 = 66
    num_params = 10*5 + 5 + 5*1 + 1
    bounds = [(-1.0, 1.0)] * num_params
    
    de = DifferentialEvolution(
        objective_function=objective,
        bounds=bounds,
        pop_size=50,
        F=0.8,
        CR=0.9,
        max_iter=200
    )
    
    best_weights, best_loss, history = de.optimize()
    
    print(f"Melhor loss: {best_loss:.6f}")
    return best_weights, history
```

---

## **5. ‚öôÔ∏è Configura√ß√£o de Par√¢metros**

### **5.1 Par√¢metros Principais**

| Par√¢metro | S√≠mbolo | Faixa T√≠pica | Descri√ß√£o | Efeito |
|-----------|---------|--------------|-----------|--------|
| **Tamanho da Popula√ß√£o** | NP | 5D a 10D | N√∫mero de indiv√≠duos | Maior = mais explora√ß√£o |
| **Fator de Escala** | F | 0.5 a 1.0 | Controla magnitude da muta√ß√£o | Maior = mais explora√ß√£o |
| **Taxa de Crossover** | CR | 0.7 a 0.9 | Probabilidade de herdar gene do mutante | Maior = mais mudan√ßas |

**Legenda:** D = dimensionalidade do problema

### **5.2 Guia de Configura√ß√£o**

#### **üéØ Para Problemas Unimodais (Um √ìtimo)**
```python
NP = 5 * D        # Popula√ß√£o pequena
F = 0.5           # Converg√™ncia r√°pida
CR = 0.9          # Alta recombina√ß√£o
strategy = 'best/1'  # Explora√ß√£o direcionada
```

#### **üåã Para Problemas Multimodais (M√∫ltiplos √ìtimos)**
```python
NP = 10 * D       # Popula√ß√£o maior
F = 0.8           # Mais explora√ß√£o
CR = 0.9          # Alta recombina√ß√£o
strategy = 'rand/1' ou 'current-to-best/1'
```

#### **üìà Para Alta Dimensionalidade (D > 50)**
```python
NP = 10 * D       # Popula√ß√£o proporcional
F = 0.9           # Passos grandes
CR = 0.1 a 0.3    # Crossover baixo
strategy = 'rand/2'  # Mais diversidade
```

#### **üé≤ Para Fun√ß√µes Ruidosas**
```python
NP = 15 * D       # Popula√ß√£o muito grande
F = 0.5           # Muta√ß√µes moderadas
CR = 0.9          # Alta recombina√ß√£o
# Usar m√∫ltiplas avalia√ß√µes e m√©dia
```

### **5.3 Auto-adapta√ß√£o de Par√¢metros**

```python
class SelfAdaptiveDE(DifferentialEvolution):
    """DE com auto-adapta√ß√£o de F e CR"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Par√¢metros individuais para cada membro da popula√ß√£o
        self.F_values = np.random.uniform(0.5, 1.0, self.NP)
        self.CR_values = np.random.uniform(0.0, 1.0, self.NP)
    
    def adapt_parameters(self, i):
        """Auto-adapta F e CR com probabilidade œÑ"""
        tau1, tau2 = 0.1, 0.1
        
        if np.random.rand() < tau1:
            self.F_values[i] = 0.1 + 0.9 * np.random.rand()
        
        if np.random.rand() < tau2:
            self.CR_values[i] = np.random.rand()
    
    def optimize(self):
        """Otimiza√ß√£o com par√¢metros auto-adaptativos"""
        population = self.initialize_population()
        fitness = np.array([self.f(ind) for ind in population])
        
        best_idx = np.argmin(fitness)
        best_solution = population[best_idx].copy()
        best_fitness = fitness[best_idx]
        
        history = {'best_fitness': [best_fitness]}
        
        for generation in range(self.max_iter):
            for i in range(self.NP):
                # Adaptar par√¢metros
                self.adapt_parameters(i)
                
                # Usar par√¢metros espec√≠ficos do indiv√≠duo
                self.F = self.F_values[i]
                self.CR = self.CR_values[i]
                
                # Continuar com DE padr√£o
                mutant = self.mutate(population, i)
                mutant = self.clip_to_bounds(mutant)
                trial = self.crossover(population[i], mutant)
                
                trial_fitness = self.f(trial)
                if trial_fitness < fitness[i]:
                    population[i] = trial
                    fitness[i] = trial_fitness
                    
                    if trial_fitness < best_fitness:
                        best_solution = trial.copy()
                        best_fitness = trial_fitness
            
            history['best_fitness'].append(best_fitness)
        
        return best_solution, best_fitness, history
```

---

## **6. ‚úÖ Vantagens e ‚ùå Desvantagens**

### **6.1 ‚úÖ Vantagens**

| Vantagem | Descri√ß√£o | Impacto Pr√°tico |
|----------|-----------|-----------------|
| **Simplicidade** | Poucos par√¢metros para ajustar | F√°cil de implementar e usar |
| **Robustez** | Funciona bem em diversos problemas | N√£o requer conhecimento espec√≠fico |
| **Sem Gradientes** | N√£o precisa de derivadas | Funciona com fun√ß√µes n√£o-diferenci√°veis |
| **Paraleliz√°vel** | Avalia√ß√µes independentes | Escal√°vel para sistemas distribu√≠dos |
| **Auto-adapta√ß√£o** | Tamanho de passo ajusta-se automaticamente | Menos ajuste manual |
| **Multimodal** | Lida bem com m√∫ltiplos √≥timos | Evita √≥timos locais |
| **Alta Dimens√£o** | Eficiente em espa√ßos de alta dimens√£o | Escal√°vel para problemas complexos |

### **6.2 ‚ùå Desvantagens**

| Desvantagem | Descri√ß√£o | Mitiga√ß√£o |
|-------------|-----------|-----------|
| **Converg√™ncia Lenta** | Pode ser lento pr√≥ximo ao √≥timo | Usar hibridiza√ß√£o com busca local |
| **Sensibilidade a Par√¢metros** | Desempenho varia com F, CR, NP | Usar auto-adapta√ß√£o ou valores padr√£o |
| **Apenas Cont√≠nuo** | N√£o funciona diretamente em discreto | Adaptar com mapeamento ou arredondamento |
| **Sem Garantias** | N√£o garante √≥timo global | Executar m√∫ltiplas vezes |
| **Custo Computacional** | Muitas avalia√ß√µes de fun√ß√£o | Paralelizar ou usar surrogates |

### **6.3 üéØ Quando Usar DE**

#### **‚úÖ Cen√°rios Ideais:**
- ‚úÖ Otimiza√ß√£o cont√≠nua multidimensional
- ‚úÖ Fun√ß√µes multimodais complexas
- ‚úÖ N√£o h√° informa√ß√£o de gradiente
- ‚úÖ Fun√ß√£o objetivo √© ruidosa
- ‚úÖ Restri√ß√µes podem ser tratadas por penaliza√ß√£o
- ‚úÖ Calibra√ß√£o de modelos e hiperpar√¢metros
- ‚úÖ Problemas de engenharia e design

#### **‚ùå Evite DE quando:**
- ‚ùå Fun√ß√£o √© unimodal e suave (usar otimiza√ß√£o baseada em gradiente)
- ‚ùå Dimensionalidade √© muito baixa (< 3D)
- ‚ùå Avalia√ß√£o da fun√ß√£o √© extremamente custosa
- ‚ùå Precisa de solu√ß√£o √≥tima provada
- ‚ùå Problema √© puramente discreto (usar GA)

---

## **7. üî¨ Variantes Avan√ßadas**

### **7.1 jDE (Self-Adaptive DE)**

```python
class jDE(DifferentialEvolution):
    """
    jDE: DE com auto-adapta√ß√£o de F e CR
    Brest et al. (2006)
    """
    
    def __init__(self, *args, tau1=0.1, tau2=0.1, 
                 F_lower=0.1, F_upper=0.9, **kwargs):
        super().__init__(*args, **kwargs)
        self.tau1 = tau1
        self.tau2 = tau2
        self.F_lower = F_lower
        self.F_upper = F_upper
        
        # Par√¢metros por indiv√≠duo
        self.F_i = np.full(self.NP, self.F)
        self.CR_i = np.full(self.NP, self.CR)
    
    def adapt_control_parameters(self, i):
        """Adapta F e CR para indiv√≠duo i"""
        if np.random.rand() < self.tau1:
            self.F_i[i] = self.F_lower + np.random.rand() * (
                self.F_upper - self.F_lower
            )
        
        if np.random.rand() < self.tau2:
            self.CR_i[i] = np.random.rand()
        
        return self.F_i[i], self.CR_i[i]
```

### **7.2 SHADE (Success-History Adaptation)**

```python
class SHADE(DifferentialEvolution):
    """
    SHADE: Success-History based Adaptive DE
    Tanabe & Fukunaga (2013)
    """
    
    def __init__(self, *args, H=100, **kwargs):
        super().__init__(*args, **kwargs)
        self.H = H  # Tamanho da mem√≥ria
        
        # Mem√≥ria de par√¢metros bem-sucedidos
        self.M_F = [0.5] * H
        self.M_CR = [0.5] * H
        self.k = 0
    
    def get_parameters_from_memory(self):
        """Obt√©m F e CR da mem√≥ria"""
        r = np.random.randint(0, self.H)
        
        # F usando distribui√ß√£o Cauchy
        F = np.clip(np.random.standard_cauchy() * 0.1 + self.M_F[r], 0, 1)
        
        # CR usando distribui√ß√£o Normal
        CR = np.clip(np.random.normal(self.M_CR[r], 0.1), 0, 1)
        
        return F, CR
    
    def update_memory(self, successful_F, successful_CR):
        """Atualiza mem√≥ria com par√¢metros bem-sucedidos"""
        if len(successful_F) > 0:
            # M√©dia ponderada por melhoria de fitness
            mean_F = np.mean(successful_F)
            mean_CR = np.mean(successful_CR)
            
            self.M_F[self.k] = mean_F
            self.M_CR[self.k] = mean_CR
            
            self.k = (self.k + 1) % self.H
```

### **7.3 L-SHADE (Linear Population Size Reduction)**

Combina SHADE com redu√ß√£o linear do tamanho da popula√ß√£o:

```python
class LSHADE(SHADE):
    """
    L-SHADE: SHADE com redu√ß√£o linear de popula√ß√£o
    """
    
    def __init__(self, *args, N_init=None, N_min=4, **kwargs):
        super().__init__(*args, **kwargs)
        self.N_init = N_init or self.NP
        self.N_min = N_min
    
    def update_population_size(self, generation):
        """Reduz tamanho da popula√ß√£o linearmente"""
        new_size = round(
            self.N_min + (self.N_init - self.N_min) * 
            (1 - generation / self.max_iter)
        )
        return max(new_size, self.N_min)
```

### **7.4 JADE (Adaptive DE with Archive)**

```python
class JADE(DifferentialEvolution):
    """
    JADE: Adaptive DE with Optional External Archive
    Zhang & Sanderson (2009)
    """
    
    def __init__(self, *args, c=0.1, p=0.05, archive_size=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.c = c  # Taxa de aprendizado
        self.p = p  # Top-p% para current-to-pbest
        self.archive_size = archive_size or self.NP
        self.archive = []
        
        # Par√¢metros adaptativos
        self.mu_F = 0.5
        self.mu_CR = 0.5
    
    def mutate_jade(self, population, current_idx, fitness):
        """Muta√ß√£o current-to-pbest/1 com arquivo"""
        # Selecionar um dos top-p% melhores
        p_best_size = max(1, int(self.p * self.NP))
        top_indices = np.argsort(fitness)[:p_best_size]
        p_best_idx = np.random.choice(top_indices)
        
        # Selecionar r1 da popula√ß√£o e r2 da popula√ß√£o + arquivo
        candidates = [idx for idx in range(self.NP) if idx != current_idx]
        r1 = np.random.choice(candidates)
        
        combined = list(range(self.NP)) + list(range(len(self.archive)))
        r2 = np.random.choice([idx for idx in combined if idx != current_idx])
        
        if r2 < self.NP:
            x_r2 = population[r2]
        else:
            x_r2 = self.archive[r2 - self.NP]
        
        # Muta√ß√£o
        mutant = (population[current_idx] + 
                 self.F * (population[p_best_idx] - population[current_idx]) +
                 self.F * (population[r1] - x_r2))
        
        return mutant
    
    def update_archive(self, failed_individual):
        """Adiciona indiv√≠duo substitu√≠do ao arquivo"""
        self.archive.append(failed_individual)
        if len(self.archive) > self.archive_size:
            # Remover aleatoriamente
            self.archive.pop(np.random.randint(len(self.archive)))
```

---

## **8. üéì Compara√ß√µes e Benchmarks**

### **8.1 Compara√ß√£o com Outros Algoritmos**

```python
import numpy as np
from scipy.optimize import minimize

def benchmark_algorithms(func, bounds, dim=10):
    """
    Compara DE com outros m√©todos de otimiza√ß√£o
    """
    results = {}
    
    # 1. Differential Evolution
    de = DifferentialEvolution(func, bounds, pop_size=50, max_iter=100)
    x_de, f_de, _ = de.optimize()
    results['DE'] = {'solution': x_de, 'fitness': f_de}
    
    # 2. Scipy - Nelder-Mead
    x0 = np.random.uniform(bounds[0][0], bounds[0][1], dim)
    res_nm = minimize(func, x0, method='Nelder-Mead', 
                     options={'maxiter': 5000})
    results['Nelder-Mead'] = {'solution': res_nm.x, 'fitness': res_nm.fun}
    
    # 3. Scipy - L-BFGS-B (com gradiente)
    res_lbfgs = minimize(func, x0, method='L-BFGS-B', 
                        bounds=[bounds[0]]*dim, 
                        options={'maxiter': 5000})
    results['L-BFGS-B'] = {'solution': res_lbfgs.x, 'fitness': res_lbfgs.fun}
    
    # 4. Scipy - Differential Evolution
    from scipy.optimize import differential_evolution
    res_scipy_de = differential_evolution(func, [bounds[0]]*dim, 
                                         maxiter=100, popsize=5)
    results['Scipy-DE'] = {'solution': res_scipy_de.x, 'fitness': res_scipy_de.fun}
    
    return results

# Testar em fun√ß√£o de Rastrigin
bounds = [(-5.12, 5.12)]
results = benchmark_algorithms(rastrigin, bounds, dim=10)

print("Compara√ß√£o de Algoritmos na Fun√ß√£o de Rastrigin (10D):")
print("-" * 60)
for method, data in results.items():
    print(f"{method:15s}: f = {data['fitness']:.6f}")
```

### **8.2 An√°lise de Desempenho**

```python
def performance_analysis(func, bounds, dim=10, runs=30):
    """
    An√°lise estat√≠stica de desempenho do DE
    """
    results = []
    
    for run in range(runs):
        de = DifferentialEvolution(
            func, bounds, 
            pop_size=50, 
            F=0.8, 
            CR=0.9, 
            max_iter=200
        )
        _, fitness, _ = de.optimize()
        results.append(fitness)
    
    results = np.array(results)
    
    stats = {
        'mean': np.mean(results),
        'std': np.std(results),
        'median': np.median(results),
        'min': np.min(results),
        'max': np.max(results),
        'q25': np.percentile(results, 25),
        'q75': np.percentile(results, 75)
    }
    
    return stats, results

# Executar an√°lise
stats, results = performance_analysis(rastrigin, [(-5.12, 5.12)], dim=10, runs=30)

print("Estat√≠sticas de Desempenho (30 execu√ß√µes):")
print(f"M√©dia:    {stats['mean']:.6f}")
print(f"Desvio:   {stats['std']:.6f}")
print(f"Mediana:  {stats['median']:.6f}")
print(f"M√≠nimo:   {stats['min']:.6f}")
print(f"M√°ximo:   {stats['max']:.6f}")
print(f"Q25-Q75:  {stats['q25']:.6f} - {stats['q75']:.6f}")
```

---

## **9. üìö Fun√ß√µes de Benchmark**

### **9.1 Biblioteca de Fun√ß√µes de Teste**

```python
class BenchmarkFunctions:
    """Cole√ß√£o de fun√ß√µes de benchmark para otimiza√ß√£o"""
    
    @staticmethod
    def sphere(x):
        """
        Fun√ß√£o Esfera
        Unimodal, separ√°vel, convexa
        M√≠nimo: f(0,...,0) = 0
        """
        return np.sum(x**2)
    
    @staticmethod
    def rastrigin(x):
        """
        Fun√ß√£o Rastrigin
        Multimodal, separ√°vel
        M√≠nimo: f(0,...,0) = 0
        """
        n = len(x)
        return 10*n + np.sum(x**2 - 10*np.cos(2*np.pi*x))
    
    @staticmethod
    def rosenbrock(x):
        """
        Fun√ß√£o Rosenbrock
        Unimodal, n√£o-separ√°vel, vale estreito
        M√≠nimo: f(1,...,1) = 0
        """
        return np.sum(100*(x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)
    
    @staticmethod
    def ackley(x):
        """
        Fun√ß√£o Ackley
        Multimodal, n√£o-separ√°vel
        M√≠nimo: f(0,...,0) = 0
        """
        n = len(x)
        sum1 = np.sum(x**2)
        sum2 = np.sum(np.cos(2*np.pi*x))
        return (-20*np.exp(-0.2*np.sqrt(sum1/n)) - 
                np.exp(sum2/n) + 20 + np.e)
    
    @staticmethod
    def schwefel(x):
        """
        Fun√ß√£o Schwefel
        Multimodal, n√£o-separ√°vel
        M√≠nimo: f(420.9687,...,420.9687) = 0
        """
        n = len(x)
        return 418.9829*n - np.sum(x * np.sin(np.sqrt(np.abs(x))))
    
    @staticmethod
    def griewank(x):
        """
        Fun√ß√£o Griewank
        Multimodal, n√£o-separ√°vel
        M√≠nimo: f(0,...,0) = 0
        """
        sum_sq = np.sum(x**2) / 4000
        prod_cos = np.prod(np.cos(x / np.sqrt(np.arange(1, len(x)+1))))
        return sum_sq - prod_cos + 1
    
    @staticmethod
    def levy(x):
        """
        Fun√ß√£o Levy
        Multimodal, n√£o-separ√°vel
        M√≠nimo: f(1,...,1) = 0
        """
        w = 1 + (x - 1) / 4
        term1 = np.sin(np.pi * w[0])**2
        term2 = np.sum((w[:-1] - 1)**2 * (1 + 10*np.sin(np.pi*w[:-1] + 1)**2))
        term3 = (w[-1] - 1)**2 * (1 + np.sin(2*np.pi*w[-1])**2)
        return term1 + term2 + term3

# Uso
bench = BenchmarkFunctions()
x = np.zeros(10)
print(f"Sphere(0) = {bench.sphere(x)}")  # Deve ser 0
```

---

## **10. üîó Refer√™ncias e Recursos**

### **10.1 üìö Artigos Fundamentais**

1. **Storn, R., & Price, K. (1997).** *"Differential Evolution - A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces"*. Journal of Global Optimization, 11(4), 341-359.
   - üåü Artigo original que introduziu o DE
   - üìä Descri√ß√£o completa do algoritmo

2. **Price, K., Storn, R. M., & Lampinen, J. A. (2005).** *"Differential Evolution: A Practical Approach to Global Optimization"*. Springer.
   - üìñ Livro definitivo sobre DE
   - üéØ Teoria e aplica√ß√µes pr√°ticas

3. **Das, S., & Suganthan, P. N. (2011).** *"Differential Evolution: A Survey of the State-of-the-Art"*. IEEE Transactions on Evolutionary Computation, 15(1), 4-31.
   - üìä Survey abrangente sobre variantes
   - üî¨ An√°lise te√≥rica e experimental

### **10.2 üåê Recursos Online**

| Recurso | Tipo | Descri√ß√£o | URL |
|---------|------|-----------|-----|
| **DE Homepage** | Site Oficial | Site original dos criadores | www1.icsi.berkeley.edu/~storn/code.html |
| **scipy.optimize.differential_evolution** | Biblioteca | Implementa√ß√£o em SciPy | docs.scipy.org |
| **PyGMO** | Framework | Otimiza√ß√£o global multi-objetivo | esa.github.io/pygmo2 |
| **DEAP** | Biblioteca | Framework de algoritmos evolutivos | deap.readthedocs.io |

### **10.3 üõ†Ô∏è Implementa√ß√µes Dispon√≠veis**

```python
# 1. SciPy (mais comum)
from scipy.optimize import differential_evolution

# 2. PyGMO (otimiza√ß√£o espacial)
import pygmo as pg

# 3. DEAP (framework completo)
from deap import algorithms, base, creator, tools

# 4. Pymoo (multi-objetivo)
from pymoo.algorithms.soo.nonconvex.de import DE
from pymoo.optimize import minimize

# 5. NiaPy (natureza inspirada)
from niapy.algorithms.basic import DifferentialEvolution
```

### **10.4 üìù Artigos sobre Variantes Avan√ßadas**

1. **jDE**: Brest et al. (2006) - "Self-Adapting Control Parameters in Differential Evolution"
2. **JADE**: Zhang & Sanderson (2009) - "JADE: Adaptive Differential Evolution with Optional External Archive"
3. **SHADE**: Tanabe & Fukunaga (2013) - "Success-History Based Parameter Adaptation for DE"
4. **L-SHADE**: Tanabe & Fukunaga (2014) - "Improving the Search Performance of SHADE"
5. **CoBiDE**: Wang et al. (2011) - "Composite Differential Evolution for Constrained Evolutionary Optimization"

### **10.5 üéì Tutoriais e Cursos**

- **Coursera:** Evolutionary Computation
- **MIT OpenCourseWare:** Computational Evolutionary Biology
- **YouTube:** Lectures on Differential Evolution
- **Kaggle:** DE for Hyperparameter Tuning

---

## **11. üéØ Conclus√£o**

A Evolu√ß√£o Diferencial √© um dos algoritmos de otimiza√ß√£o mais **vers√°teis e eficientes** dispon√≠veis para problemas cont√≠nuos. Suas principais caracter√≠sticas s√£o:

### **üîë Principais Aprendizados**

1. **Simplicidade Elegante:** Poucos par√¢metros, implementa√ß√£o direta, resultados s√≥lidos
2. **Muta√ß√£o Diferencial:** Uso inteligente de diferen√ßas vetoriais para auto-adapta√ß√£o
3. **Robustez:** Funciona bem em diversos tipos de problemas sem ajuste fino
4. **Flexibilidade:** M√∫ltiplas variantes para diferentes cen√°rios

### **üí° Quando Usar DE**

| ‚úÖ **Use quando:** | ‚ùå **Evite quando:** |
|-------------------|---------------------|
| Otimiza√ß√£o cont√≠nua multimodal | Fun√ß√£o √© unimodal e diferenci√°vel |
| N√£o h√° gradiente dispon√≠vel | Avalia√ß√£o √© extremamente custosa |
| Fun√ß√£o √© ruidosa ou n√£o-suave | Precisa de garantias te√≥ricas |
| Alta dimensionalidade (< 100D) | Problema √© puramente discreto |
| Calibra√ß√£o de modelos | Baixa dimensionalidade (< 3D) |

### **üöÄ Pr√≥ximos Passos**

1. **Implemente** a vers√£o b√°sica do DE
2. **Experimente** diferentes estrat√©gias de muta√ß√£o
3. **Teste** em fun√ß√µes de benchmark
4. **Aplique** ao seu problema espec√≠fico
5. **Explore** variantes avan√ßadas (SHADE, L-SHADE)
6. **Compare** com outros m√©todos de otimiza√ß√£o
7. **Considere** hibridiza√ß√£o com busca local

### **üåü Reflex√£o Final**

A Evolu√ß√£o Diferencial demonstra que **simplicidade e efic√°cia** podem andar juntas. Ao usar diferen√ßas entre vetores da popula√ß√£o, o algoritmo captura implicitamente a geometria do espa√ßo de busca, criando um mecanismo de busca naturalmente adaptativo e robusto.

> *"A beleza da Evolu√ß√£o Diferencial est√° em usar a sabedoria coletiva da popula√ß√£o - as diferen√ßas entre indiv√≠duos guiam a busca de forma inteligente e auto-organizante."*

---

**üîó Continue sua jornada:**
- üìñ Explore [**Evolution Strategies**](evolution_strategies.md) para auto-adapta√ß√£o avan√ßada
- üß¨ Volte para [**Genetic Algorithms**](genetic_algorithms.md) para compara√ß√£o
- üéØ Veja [**Algoritmos Evolucion√°rios**](README.md) para vis√£o geral
- üîÑ Investigue hibridiza√ß√£o com busca local para melhor performance

**Voltar para:** [Documenta√ß√£o de Algoritmos](../README.md) | [Documenta√ß√£o Principal](../../README.md)
