# Simulated Annealing: Algoritmo de OtimizaÃ§Ã£o Inspirado na FÃ­sica

O **Simulated Annealing** (SA) Ã© um algoritmo de otimizaÃ§Ã£o estocÃ¡stica inspirado no processo fÃ­sico de **recozimento** (annealing) de metais. Este processo envolve o aquecimento de um material atÃ© uma temperatura elevada e, em seguida, o resfriamento gradual, o que permite que o material alcance um estado de menor energia, ou seja, uma configuraÃ§Ã£o estrutural mais estÃ¡vel. De forma anÃ¡loga, o Simulated Annealing tenta encontrar a melhor soluÃ§Ã£o para um problema de otimizaÃ§Ã£o, permitindo inicialmente movimentos em direÃ§Ã£o a soluÃ§Ãµes piores (aumentando a chance de escapar de Ã³timos locais) e, com o tempo, restringindo esses movimentos para se concentrar em melhorar a soluÃ§Ã£o de maneira mais controlada.

![SA vs HC Comparison](../../images/sa_vs_hc_comparison.png)

Este algoritmo Ã© amplamente utilizado em problemas de otimizaÃ§Ã£o combinatÃ³ria, como o **Problema do Caixeiro Viajante (TSP)**, **agendamento de tarefas**, **planejamento de rotas** e muitos outros problemas que envolvem a busca por uma soluÃ§Ã£o Ã³tima em um espaÃ§o de busca complexo e multidimensional.

---

## **1. ğŸŒ¡ï¸ MotivaÃ§Ã£o e Analogia com a FÃ­sica**

### **1.1 O Processo de Recozimento de Metais**

Imagine um ferreiro trabalhando com metal:

1. **ğŸ”¥ Aquecimento:** O metal Ã© aquecido a altas temperaturas, fazendo os Ã¡tomos vibrarem intensamente
2. **âš¡ Energia Alta:** Com muita energia, os Ã¡tomos podem se reorganizar livremente
3. **â„ï¸ Resfriamento Gradual:** A temperatura diminui lentamente, reduzindo a energia
4. **ğŸ”§ EstabilizaÃ§Ã£o:** Os Ã¡tomos se fixam em uma configuraÃ§Ã£o de baixa energia (estÃ¡vel)

### **1.2 Analogia Computacional**

| **FÃ­sica** | **ComputaÃ§Ã£o** | **Exemplo** |
|------------|----------------|-------------|
| ğŸŒ¡ï¸ **Temperatura** | Probabilidade de aceitar soluÃ§Ãµes piores | Alta T â†’ aceita soluÃ§Ãµes ruins |
| âš›ï¸ **Ãtomos** | VariÃ¡veis da soluÃ§Ã£o | Ordem das cidades no TSP |
| âš¡ **Energia** | Valor da funÃ§Ã£o objetivo | DistÃ¢ncia total do percurso |
| ğŸ¯ **Estado estÃ¡vel** | SoluÃ§Ã£o Ã³tima | Menor caminho encontrado |

### **1.3 Por que Simulated Annealing Funciona?**

**ğŸ” Problema com Hill Climbing:**
- Fica preso em Ã³timos locais
- NÃ£o consegue "descer" para explorar outras regiÃµes
- SoluÃ§Ã£o muito dependente do ponto inicial

**ğŸ’¡ SoluÃ§Ã£o do SA:**
- **Aceita soluÃ§Ãµes piores** com certa probabilidade
- **Probabilidade diminui** com o tempo (resfriamento)
- **Explora amplamente** no inÃ­cio, **refina** no final

---

## **2. ğŸ”§ Funcionamento do Algoritmo Simulated Annealing**

![Algorithm Flowcharts](../../images/algorithm_flowcharts.png)

### **2.1 Componentes Fundamentais**

O Simulated Annealing possui quatro componentes essenciais:

#### **ğŸŒ¡ï¸ 1. Temperatura (T)**
- **Controla** a probabilidade de aceitar soluÃ§Ãµes piores
- **Alta temperatura:** Maior exploraÃ§Ã£o, aceita soluÃ§Ãµes ruins
- **Baixa temperatura:** Menor exploraÃ§Ã£o, comportamento similar ao Hill Climbing

#### **â„ï¸ 2. Esquema de Resfriamento**
- **Define** como a temperatura diminui ao longo do tempo
- **Tipos comuns:** Linear, exponencial, logarÃ­tmico

#### **ğŸ² 3. CritÃ©rio de AceitaÃ§Ã£o (Metropolis)**
- **FÃ³rmula:** P(aceitar) = exp(-Î”E/T)
- **Î”E:** DiferenÃ§a de energia (valor da funÃ§Ã£o objetivo)
- **T:** Temperatura atual

#### **â±ï¸ 4. CritÃ©rio de Parada**
- **Temperatura mÃ­nima** atingida
- **NÃºmero mÃ¡ximo** de iteraÃ§Ãµes
- **Qualidade** da soluÃ§Ã£o aceitÃ¡vel

### **2.2 Passos do Algoritmo**

```
ğŸš€ 1. INICIALIZAÃ‡ÃƒO
   â”œâ”€â”€ Escolher soluÃ§Ã£o inicial Sâ‚€
   â”œâ”€â”€ Definir temperatura inicial Tâ‚€
   â””â”€â”€ Configurar parÃ¢metros de resfriamento

ğŸ”„ 2. LOOP PRINCIPAL (enquanto T > T_min):
   â”œâ”€â”€ ğŸ¯ Gerar vizinho S' de S
   â”œâ”€â”€ ğŸ“Š Calcular Î”E = f(S') - f(S)
   â”œâ”€â”€ ğŸ² SE Î”E â‰¤ 0: aceitar S' (melhoria)
   â”œâ”€â”€ ğŸ² SENÃƒO: aceitar S' com probabilidade exp(-Î”E/T)
   â””â”€â”€ â„ï¸ Resfriar: T â† Î±Ã—T

ğŸ 3. RETORNAR melhor soluÃ§Ã£o encontrada
```

### **2.3 Probabilidade de AceitaÃ§Ã£o Detalhada**

![Temperature Schedule](../../images/sa_temperature_schedule.png)

**InterpretaÃ§Ã£o da Curva de AceitaÃ§Ã£o:**
- **Î”E < 0:** Sempre aceita (melhoria)
- **Î”E > 0:** Aceita com probabilidade exp(-Î”E/T)
- **T alto:** Aceita quase tudo (exploraÃ§Ã£o)
- **T baixo:** Aceita apenas melhorias (refinamento)

---

## **3. ğŸ“Š Esquemas de Resfriamento (Cooling Schedules)**

A escolha do esquema de resfriamento Ã© **crucial** para o sucesso do Simulated Annealing. Diferentes esquemas produzem comportamentos diferentes.

### **3.1 Tipos de Resfriamento**

#### **ğŸ“‰ Linear**
```python
T(t) = Tâ‚€ - Î± Ã— t
```
**CaracterÃ­sticas:**
- âœ… Simples de implementar
- âš ï¸ Pode resfriar muito rÃ¡pido
- ğŸ¯ Bom para testes iniciais

#### **ğŸ“ˆ Exponencial**
```python
T(t) = Tâ‚€ Ã— Î±^t    (onde 0.8 â‰¤ Î± â‰¤ 0.99)
```
**CaracterÃ­sticas:**
- âœ… Mais usado na prÃ¡tica
- âœ… Resfriamento suave
- ğŸ¯ Boa exploraÃ§Ã£o inicial

#### **ğŸ“ LogarÃ­tmico**
```python
T(t) = Tâ‚€ / log(t + c)
```
**CaracterÃ­sticas:**
- âœ… Resfriamento muito lento
- âš ï¸ Pode ser computacionalmente caro
- ğŸ¯ Garantias teÃ³ricas de convergÃªncia

#### **âš¡ Adaptativo**
```python
# Ajusta Î± baseado na aceitaÃ§Ã£o de soluÃ§Ãµes
if taxa_aceitacao > 0.8:
    Î± = Î± Ã— 0.9  # Resfria mais rÃ¡pido
elif taxa_aceitacao < 0.2:
    Î± = Î± Ã— 1.1  # Resfria mais devagar
```

### **3.2 ComparaÃ§Ã£o PrÃ¡tica dos Esquemas**

| **Esquema** | **Velocidade** | **Qualidade** | **Uso Recomendado** |
|-------------|----------------|---------------|-------------------|
| **Linear** | ğŸš€ Muito rÃ¡pido | â­ Baixa | ProtÃ³tipos, testes |
| **Exponencial** | âš¡ RÃ¡pido | â­â­â­ Alta | Maioria dos problemas |
| **LogarÃ­tmico** | ğŸŒ Lento | â­â­â­â­ Muito alta | Problemas crÃ­ticos |
| **Adaptativo** | âš–ï¸ VariÃ¡vel | â­â­â­â­ Muito alta | Problemas complexos |

### **3.3 ConfiguraÃ§Ã£o de ParÃ¢metros**

#### **ğŸŒ¡ï¸ Temperatura Inicial (Tâ‚€)**
```python
def estimar_temperatura_inicial(problema, num_amostras=1000):
    """Estima Tâ‚€ baseado na variaÃ§Ã£o dos valores da funÃ§Ã£o objetivo"""
    valores = []
    
    for _ in range(num_amostras):
        sol1 = gerar_solucao_aleatoria(problema)
        sol2 = gerar_vizinho(sol1)
        valores.append(abs(funcao_objetivo(sol1) - funcao_objetivo(sol2)))
    
    # Tâ‚€ deve ser suficiente para aceitar 80-90% das soluÃ§Ãµes piores
    delta_medio = np.mean(valores)
    return -delta_medio / np.log(0.8)  # 80% de aceitaÃ§Ã£o inicial
```

#### **â„ï¸ Temperatura Final (T_min)**
```python
def calcular_temperatura_final(T0, precisao_desejada=0.001):
    """Calcula T_min baseado na precisÃ£o desejada"""
    return T0 * precisao_desejada
```

#### **ğŸ›ï¸ Taxa de Resfriamento (Î±)**
```python
def calcular_alpha(T0, Tf, num_iteracoes):
    """Calcula Î± para resfriamento exponencial"""
    return (Tf / T0) ** (1 / num_iteracoes)
```

---

## **4. ğŸ¯ AplicaÃ§Ãµes Detalhadas do Simulated Annealing**

### **4.1 ğŸ—ºï¸ Problema do Caixeiro Viajante (TSP)**

**Contexto:** O TSP Ã© um problema NP-difÃ­cil clÃ¡ssico onde Ã© necessÃ¡rio encontrar o menor caminho que visita todas as cidades exatamente uma vez.

**Por que SA Ã© eficaz para TSP:**
- Muitos Ã³timos locais no espaÃ§o de busca
- Operadores de vizinhanÃ§a bem definidos (2-opt, 3-opt)
- Aceita temporariamente tours piores para escapar de Ã³timos locais

**ImplementaÃ§Ã£o especÃ­fica:**
```python
def sa_tsp(cidades, T0=1000, Tf=1, alpha=0.995, max_iter=10000):
    # SoluÃ§Ã£o inicial: tour aleatÃ³rio
    tour_atual = list(range(len(cidades)))
    random.shuffle(tour_atual)
    
    custo_atual = calcular_distancia_total(tour_atual, cidades)
    melhor_tour, melhor_custo = tour_atual.copy(), custo_atual
    
    T = T0
    
    for iteracao in range(max_iter):
        # Gerar vizinho usando 2-opt
        novo_tour = aplicar_2opt(tour_atual)
        novo_custo = calcular_distancia_total(novo_tour, cidades)
        
        # CritÃ©rio de aceitaÃ§Ã£o
        delta = novo_custo - custo_atual
        
        if delta < 0 or random.random() < math.exp(-delta / T):
            tour_atual = novo_tour
            custo_atual = novo_custo
            
            # Atualizar melhor soluÃ§Ã£o
            if custo_atual < melhor_custo:
                melhor_tour = tour_atual.copy()
                melhor_custo = custo_atual
        
        # Resfriamento
        T *= alpha
        
        if T < Tf:
            break
    
    return melhor_tour, melhor_custo
```

### **4.2 ğŸ§  Ajuste de HiperparÃ¢metros em Machine Learning**

**AplicaÃ§Ã£o:** Otimizar hiperparÃ¢metros de modelos de ML para maximizar acurÃ¡cia.

**Vantagens do SA:**
- NÃ£o precisa de gradientes
- Lida bem com funÃ§Ãµes objetivo ruidosas
- Evita Ã³timos locais em espaÃ§os de hiperparÃ¢metros

**Exemplo prÃ¡tico:**
```python
def sa_hiperparametros(modelo, dados_treino, dados_val):
    # Definir espaÃ§o de busca
    espacos = {
        'learning_rate': (0.001, 0.1),
        'batch_size': (16, 128),
        'num_layers': (1, 5),
        'dropout': (0.1, 0.5)
    }
    
    def gerar_vizinho(params):
        novo_params = params.copy()
        # Escolher parÃ¢metro aleatÃ³rio para modificar
        param_nome = random.choice(list(espacos.keys()))
        
        if param_nome == 'batch_size' or param_nome == 'num_layers':
            # ParÃ¢metros inteiros
            novo_params[param_nome] += random.choice([-1, 1])
        else:
            # ParÃ¢metros contÃ­nuos
            ruido = random.gauss(0, 0.1)
            novo_params[param_nome] *= (1 + ruido)
        
        # Garantir que estÃ¡ dentro dos limites
        min_val, max_val = espacos[param_nome]
        novo_params[param_nome] = max(min_val, min(max_val, novo_params[param_nome]))
        
        return novo_params
    
    def avaliar_modelo(params):
        # Treinar modelo com hiperparÃ¢metros
        modelo_temp = treinar_modelo(modelo, dados_treino, params)
        acuracia = avaliar_modelo_temp(modelo_temp, dados_val)
        return -acuracia  # Negativar porque SA minimiza
    
    # Executar SA
    return simulated_annealing(avaliar_modelo, gerar_vizinho, espacos)
```

### **4.3 ğŸ“… Agendamento de Tarefas (Job Shop Scheduling)**

**Problema:** Agendar N trabalhos em M mÃ¡quinas minimizando o tempo total (makespan).

**Elementos do SA para agendamento:**
- **SoluÃ§Ã£o:** SequÃªncia de operaÃ§Ãµes
- **VizinhanÃ§a:** Trocar ordem de operaÃ§Ãµes
- **FunÃ§Ã£o objetivo:** Tempo de conclusÃ£o do Ãºltimo trabalho

```python
class AgendamentoSA:
    def __init__(self, trabalhos, maquinas):
        self.trabalhos = trabalhos  # Lista de (tempo, mÃ¡quina_requerida)
        self.maquinas = maquinas
        
    def calcular_makespan(self, sequencia):
        """Calcula tempo total do agendamento"""
        tempo_maquinas = [0] * len(self.maquinas)
        
        for job_id in sequencia:
            tempo_job, maquina_id = self.trabalhos[job_id]
            tempo_maquinas[maquina_id] += tempo_job
        
        return max(tempo_maquinas)
    
    def gerar_vizinho(self, sequencia):
        """Gera vizinho trocando dois trabalhos aleatÃ³rios"""
        nova_seq = sequencia.copy()
        i, j = random.sample(range(len(nova_seq)), 2)
        nova_seq[i], nova_seq[j] = nova_seq[j], nova_seq[i]
        return nova_seq
```

### **4.4 ğŸ¨ Processamento de Imagens (Image Segmentation)**

**AplicaÃ§Ã£o:** Segmentar imagens minimizando energia de Potts.

```python
def sa_segmentacao_imagem(imagem, num_segmentos, T0=10, alpha=0.99):
    """
    Segmenta imagem usando SA com modelo de energia
    """
    altura, largura = imagem.shape
    
    # Inicializar segmentaÃ§Ã£o aleatÃ³ria
    segmentacao = np.random.randint(0, num_segmentos, (altura, largura))
    
    def calcular_energia(seg):
        """Energia baseada em suavidade e similaridade"""
        energia = 0
        
        # Termo de suavidade (vizinhos devem ter mesmo rÃ³tulo)
        for i in range(altura-1):
            for j in range(largura-1):
                if seg[i,j] != seg[i+1,j]:
                    energia += 1
                if seg[i,j] != seg[i,j+1]:
                    energia += 1
        
        # Termo de dados (pixels similares devem ter mesmo rÃ³tulo)
        for s in range(num_segmentos):
            mask = (seg == s)
            if np.sum(mask) > 0:
                media = np.mean(imagem[mask])
                energia += np.sum((imagem[mask] - media)**2)
        
        return energia
    
    # Aplicar SA
    energia_atual = calcular_energia(segmentacao)
    T = T0
    
    while T > 0.1:
        # Modificar pixel aleatÃ³rio
        i, j = random.randint(0, altura-1), random.randint(0, largura-1)
        novo_rotulo = random.randint(0, num_segmentos-1)
        
        rotulo_original = segmentacao[i,j]
        segmentacao[i,j] = novo_rotulo
        
        nova_energia = calcular_energia(segmentacao)
        delta = nova_energia - energia_atual
        
        if delta > 0 and random.random() > math.exp(-delta / T):
            # Rejeitar mudanÃ§a
            segmentacao[i,j] = rotulo_original
        else:
            energia_atual = nova_energia
        
        T *= alpha
    
    return segmentacao
```

---

## **4. Vantagens e LimitaÃ§Ãµes**

### **4.1 Vantagens**
- **Capacidade de evitar Ã³timos locais**: Ao permitir a aceitaÃ§Ã£o de soluÃ§Ãµes piores no inÃ­cio, o algoritmo evita que ele se prenda em Ã³timos locais.
- **Versatilidade**: Pode ser aplicado em uma ampla gama de problemas de otimizaÃ§Ã£o.
- **Simplicidade**: A implementaÃ§Ã£o do Simulated Annealing Ã© relativamente simples e intuitiva.

### **4.2 LimitaÃ§Ãµes**
- **Sensibilidade Ã  escolha dos parÃ¢metros**: O desempenho do SA depende fortemente da escolha da temperatura inicial, da taxa de resfriamento e do nÃºmero de iteraÃ§Ãµes.
- **Custo computacional**: Embora o SA nÃ£o seja tÃ£o intensivo quanto outros mÃ©todos, ele ainda pode ser caro computacionalmente, especialmente em problemas de grande escala.
- **NÃ£o garante a soluÃ§Ã£o Ã³tima**: Assim como outros algoritmos heurÃ­sticos, o SA pode nÃ£o encontrar a soluÃ§Ã£o Ã³tima, mas apenas uma boa aproximaÃ§Ã£o.

---

## **5. ReferÃªncias BibliogrÃ¡ficas**

1. **Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983).** *Optimization by Simulated Annealing*. Science, 220(4598), 671-680.
2. **Aarts, E., & Korst, J. (1989).** *Simulated Annealing and Boltzmann Machines*. Wiley.
3. **Cerny, V. (1985).** *Thermodynamical Approach to the Traveling Salesman Problem: An Efficient Simulation Algorithm*. Journal of Optimization Theory and Applications, 45(1), 41-51.
4. **Cohn, D. (1993).** *Artificial Intelligence: A Modern Approach*. Pearson Education.

---

## **6. ConclusÃ£o**

Simulated Annealing Ã© uma tÃ©cnica poderosa para a otimizaÃ§Ã£o de problemas complexos, sendo Ãºtil principalmente quando a soluÃ§Ã£o Ã³tima Ã© difÃ­cil de encontrar devido ao tamanho ou complexidade do espaÃ§o de busca. Sua habilidade de escapar de Ã³timos locais e encontrar boas soluÃ§Ãµes aproximadas o torna uma escolha popular para muitos tipos de problemas, especialmente em Ã¡reas como otimizaÃ§Ã£o combinatÃ³ria e aprendizado de mÃ¡quina. No entanto, seu desempenho depende significativamente da escolha dos parÃ¢metros e do controle cuidadoso do processo de resfriamento, destacando a necessidade de uma adaptaÃ§Ã£o cuidadosa do algoritmo para problemas especÃ­ficos.