# Redes Bayesianas DinÃ¢micas (Dynamic Bayesian Networks - DBN)

**Redes Bayesianas DinÃ¢micas** (Dynamic Bayesian Networks - DBN) sÃ£o modelos probabilÃ­sticos grÃ¡ficos que representam processos estocÃ¡sticos temporais, estendendo as Redes Bayesianas clÃ¡ssicas para modelar sistemas que evoluem ao longo do tempo. DBNs sÃ£o ferramentas poderosas para modelagem, inferÃªncia e prediÃ§Ã£o em domÃ­nios onde a estrutura temporal e as dependÃªncias causais sÃ£o fundamentais.

![Dynamic Bayesian Network Concept](../../images/dbn_concept.png)

Amplamente utilizadas em reconhecimento de fala, bioinformÃ¡tica, robÃ³tica, finanÃ§as e diagnÃ³stico de falhas, DBNs oferecem uma framework principled para raciocÃ­nio probabilÃ­stico temporal, combinando teoria dos grafos, probabilidade e aprendizado de mÃ¡quina.

---

## **1. ğŸ¯ Fundamentos TeÃ³ricos**

### **1.1 O Que SÃ£o Redes Bayesianas?**

Antes de entender DBNs, precisamos compreender **Redes Bayesianas** (Bayesian Networks - BN):

**DefiniÃ§Ã£o:**
> Uma Rede Bayesiana Ã© um modelo grÃ¡fico probabilÃ­stico que representa um conjunto de variÃ¡veis aleatÃ³rias e suas dependÃªncias condicionais atravÃ©s de um grafo acÃ­clico dirigido (DAG - Directed Acyclic Graph).

**Componentes:**
1. **NÃ³s:** Representam variÃ¡veis aleatÃ³rias
2. **Arestas:** Representam dependÃªncias probabilÃ­sticas diretas
3. **Tabelas de Probabilidade Condicional (CPTs):** Quantificam as dependÃªncias

**Exemplo Simples:**
```
        Chuva
          â†“
      Sprinkler â†’ Grama Molhada
          â†“
```

Neste exemplo:
- Chuva influencia diretamente se a grama estÃ¡ molhada
- Sprinkler tambÃ©m influencia a grama
- Chuva influencia se o sprinkler estÃ¡ ligado

### **1.2 ExtensÃ£o para o DomÃ­nio Temporal: DBNs**

**Redes Bayesianas DinÃ¢micas** estendem BNs para modelar processos que evoluem no tempo:

```
t=0          t=1          t=2          t=3
â”Œâ”€â”€â”        â”Œâ”€â”€â”        â”Œâ”€â”€â”        â”Œâ”€â”€â”
â”‚Xâ‚€â”‚â”€â”€â”€â”€â”€â”€â”€â†’â”‚Xâ‚â”‚â”€â”€â”€â”€â”€â”€â”€â†’â”‚Xâ‚‚â”‚â”€â”€â”€â”€â”€â”€â”€â†’â”‚Xâ‚ƒâ”‚
â””â”€â”€â”˜        â””â”€â”€â”˜        â””â”€â”€â”˜        â””â”€â”€â”˜
 â†“           â†“           â†“           â†“
â”Œâ”€â”€â”        â”Œâ”€â”€â”        â”Œâ”€â”€â”        â”Œâ”€â”€â”
â”‚Yâ‚€â”‚        â”‚Yâ‚â”‚        â”‚Yâ‚‚â”‚        â”‚Yâ‚ƒâ”‚
â””â”€â”€â”˜        â””â”€â”€â”˜        â””â”€â”€â”˜        â””â”€â”€â”˜
```

**CaracterÃ­sticas:**
- **Estado Oculto (X):** VariÃ¡veis nÃ£o observadas que evoluem no tempo
- **ObservaÃ§Ãµes (Y):** MediÃ§Ãµes ou evidÃªncias em cada instante
- **TransiÃ§Ãµes:** Como o estado muda de t para t+1
- **EmissÃµes:** Como observaÃ§Ãµes sÃ£o geradas a partir do estado

### **1.3 Componentes de uma DBN**

#### **ğŸ“Š 1. Rede de Tempo Inicial (Time-Slice 0)**

Define a distribuiÃ§Ã£o inicial:
```
P(Xâ‚€)
```

#### **ğŸ”„ 2. Modelo de TransiÃ§Ã£o (2-Time-Slice BN)**

Define como o sistema evolui:
```
P(Xâ‚œâ‚Šâ‚ | Xâ‚œ, Uâ‚œ)
```
Onde:
- **Xâ‚œ:** Estado no tempo t
- **Uâ‚œ:** Entradas/aÃ§Ãµes no tempo t

#### **ğŸ“¡ 3. Modelo de ObservaÃ§Ã£o**

Define como observaÃ§Ãµes sÃ£o geradas:
```
P(Yâ‚œ | Xâ‚œ)
```

### **1.4 AssunÃ§Ã£o de Markov**

DBNs geralmente assumem a **Propriedade de Markov:**

```
P(Xâ‚œâ‚Šâ‚ | Xâ‚€, Xâ‚, ..., Xâ‚œ) = P(Xâ‚œâ‚Šâ‚ | Xâ‚œ)
```

**InterpretaÃ§Ã£o:**
> "O futuro Ã© independente do passado dado o presente."

Esta assunÃ§Ã£o simplifica significativamente a modelagem e inferÃªncia.

---

## **2. ğŸ”§ MatemÃ¡tica das DBNs**

### **2.1 FatorizaÃ§Ã£o da DistribuiÃ§Ã£o Conjunta**

Para uma sequÃªncia temporal de comprimento T, a distribuiÃ§Ã£o conjunta fatoriza como:

```
P(Xâ‚€, Xâ‚, ..., Xâ‚œ, Yâ‚€, Yâ‚, ..., Yâ‚œ) = 
    P(Xâ‚€) Ã— P(Yâ‚€|Xâ‚€) Ã— 
    âˆâ‚œâ‚Œâ‚áµ€ [P(Xâ‚œ|Xâ‚œâ‚‹â‚) Ã— P(Yâ‚œ|Xâ‚œ)]
```

**Componentes:**
1. **Prior:** P(Xâ‚€) - DistribuiÃ§Ã£o inicial
2. **TransiÃ§Ã£o:** P(Xâ‚œ|Xâ‚œâ‚‹â‚) - DinÃ¢mica temporal
3. **EmissÃ£o:** P(Yâ‚œ|Xâ‚œ) - GeraÃ§Ã£o de observaÃ§Ãµes

### **2.2 Modelos ClÃ¡ssicos como Casos Especiais**

#### **ğŸ¯ Hidden Markov Model (HMM)**

HMM Ã© um caso especial de DBN onde:
- Estado Ã© uma variÃ¡vel **discreta**
- ObservaÃ§Ãµes podem ser discretas ou contÃ­nuas
- Estrutura mais simples

```python
# Exemplo de HMM como DBN
class HiddenMarkovModel:
    def __init__(self, n_states, n_observations):
        # DistribuiÃ§Ã£o inicial
        self.pi = np.ones(n_states) / n_states
        
        # Matriz de transiÃ§Ã£o: P(Xâ‚œâ‚Šâ‚ | Xâ‚œ)
        self.A = np.ones((n_states, n_states)) / n_states
        
        # Matriz de emissÃ£o: P(Yâ‚œ | Xâ‚œ)
        self.B = np.ones((n_states, n_observations)) / n_observations
```

#### **ğŸ“ˆ Kalman Filter**

Kalman Filter Ã© uma DBN com:
- Estado **contÃ­nuo**
- TransiÃ§Ãµes e observaÃ§Ãµes **lineares**
- RuÃ­do **gaussiano**

```python
# Kalman Filter como DBN
class KalmanFilter:
    def __init__(self, dim_state, dim_obs):
        # Modelo de transiÃ§Ã£o: Xâ‚œâ‚Šâ‚ = FÂ·Xâ‚œ + w
        self.F = np.eye(dim_state)  # Matriz de transiÃ§Ã£o
        self.Q = np.eye(dim_state)  # CovariÃ¢ncia do ruÃ­do de processo
        
        # Modelo de observaÃ§Ã£o: Yâ‚œ = HÂ·Xâ‚œ + v
        self.H = np.eye(dim_obs, dim_state)  # Matriz de observaÃ§Ã£o
        self.R = np.eye(dim_obs)  # CovariÃ¢ncia do ruÃ­do de mediÃ§Ã£o
```

### **2.3 Tarefas de InferÃªncia em DBNs**

#### **ğŸ” 1. Filtragem (Filtering)**

Estimar estado atual dado observaÃ§Ãµes passadas:
```
P(Xâ‚œ | Yâ‚, Yâ‚‚, ..., Yâ‚œ)
```

**AplicaÃ§Ã£o:** Rastreamento em tempo real

#### **ğŸ”® 2. PrediÃ§Ã£o (Prediction)**

Prever estados futuros:
```
P(Xâ‚œâ‚Šâ‚– | Yâ‚, Yâ‚‚, ..., Yâ‚œ)  onde k > 0
```

**AplicaÃ§Ã£o:** PrevisÃ£o de sÃ©ries temporais

#### **ğŸ”„ 3. SuavizaÃ§Ã£o (Smoothing)**

Estimar estados passados com todas as observaÃ§Ãµes:
```
P(Xâ‚œ | Yâ‚, Yâ‚‚, ..., Yâ‚œ)  para todo t â‰¤ T
```

**AplicaÃ§Ã£o:** AnÃ¡lise retrospectiva, pÃ³s-processamento

#### **ğŸ“Š 4. VerossimilhanÃ§a (Likelihood)**

Calcular probabilidade das observaÃ§Ãµes:
```
P(Yâ‚, Yâ‚‚, ..., Yâ‚œ)
```

**AplicaÃ§Ã£o:** ComparaÃ§Ã£o de modelos, detecÃ§Ã£o de anomalias

#### **ğŸ¯ 5. Viterbi (Most Likely Explanation)**

Encontrar sequÃªncia de estados mais provÃ¡vel:
```
argmax P(Xâ‚, Xâ‚‚, ..., Xâ‚œ | Yâ‚, Yâ‚‚, ..., Yâ‚œ)
  Xâ‚,...,Xâ‚œ
```

**AplicaÃ§Ã£o:** Reconhecimento de padrÃµes, diagnÃ³stico

---

## **3. ğŸ’» ImplementaÃ§Ã£o de DBNs**

### **3.1 ğŸ”§ Hidden Markov Model (HMM)**

```python
import numpy as np
from scipy.special import logsumexp

class HMM:
    """
    Hidden Markov Model - caso especial de DBN
    """
    
    def __init__(self, n_states, n_observations):
        """
        Args:
            n_states: NÃºmero de estados ocultos
            n_observations: NÃºmero de sÃ­mbolos de observaÃ§Ã£o
        """
        self.n_states = n_states
        self.n_observations = n_observations
        
        # ParÃ¢metros do modelo
        self.start_prob = np.ones(n_states) / n_states  # Ï€
        self.trans_prob = np.ones((n_states, n_states)) / n_states  # A
        self.emiss_prob = np.ones((n_states, n_observations)) / n_observations  # B
    
    def forward(self, observations):
        """
        Algoritmo Forward para calcular P(Yâ‚, ..., Yâ‚œ, Xâ‚œ)
        
        Returns:
            alpha: Matriz forward (T, n_states)
            log_likelihood: log P(Yâ‚, ..., Yâ‚œ)
        """
        T = len(observations)
        alpha = np.zeros((T, self.n_states))
        
        # InicializaÃ§Ã£o: t = 0
        alpha[0] = self.start_prob * self.emiss_prob[:, observations[0]]
        
        # RecursÃ£o: t = 1, ..., T-1
        for t in range(1, T):
            for j in range(self.n_states):
                alpha[t, j] = (alpha[t-1] @ self.trans_prob[:, j]) * \
                             self.emiss_prob[j, observations[t]]
        
        # VerossimilhanÃ§a
        log_likelihood = np.log(alpha[-1].sum())
        
        return alpha, log_likelihood
    
    def backward(self, observations):
        """
        Algoritmo Backward para calcular P(Yâ‚œâ‚Šâ‚, ..., Yâ‚œ | Xâ‚œ)
        
        Returns:
            beta: Matriz backward (T, n_states)
        """
        T = len(observations)
        beta = np.zeros((T, self.n_states))
        
        # InicializaÃ§Ã£o: t = T-1
        beta[-1] = 1.0
        
        # RecursÃ£o: t = T-2, ..., 0
        for t in range(T-2, -1, -1):
            for i in range(self.n_states):
                beta[t, i] = np.sum(
                    self.trans_prob[i, :] * 
                    self.emiss_prob[:, observations[t+1]] * 
                    beta[t+1]
                )
        
        return beta
    
    def viterbi(self, observations):
        """
        Algoritmo de Viterbi - sequÃªncia de estados mais provÃ¡vel
        
        Returns:
            best_path: SequÃªncia de estados mais provÃ¡vel
            best_prob: Probabilidade dessa sequÃªncia
        """
        T = len(observations)
        
        # Matriz para armazenar probabilidades mÃ¡ximas
        delta = np.zeros((T, self.n_states))
        
        # Matriz para rastreamento (backpointer)
        psi = np.zeros((T, self.n_states), dtype=int)
        
        # InicializaÃ§Ã£o
        delta[0] = self.start_prob * self.emiss_prob[:, observations[0]]
        
        # RecursÃ£o
        for t in range(1, T):
            for j in range(self.n_states):
                # Calcular max sobre estados anteriores
                prob = delta[t-1] * self.trans_prob[:, j]
                psi[t, j] = np.argmax(prob)
                delta[t, j] = np.max(prob) * self.emiss_prob[j, observations[t]]
        
        # TerminaÃ§Ã£o
        best_path = np.zeros(T, dtype=int)
        best_path[-1] = np.argmax(delta[-1])
        best_prob = np.max(delta[-1])
        
        # Backtracking
        for t in range(T-2, -1, -1):
            best_path[t] = psi[t+1, best_path[t+1]]
        
        return best_path, best_prob
    
    def baum_welch(self, observations, max_iter=100, tol=1e-6):
        """
        Algoritmo Baum-Welch (EM) para aprendizado de parÃ¢metros
        
        Args:
            observations: SequÃªncia de observaÃ§Ãµes
            max_iter: NÃºmero mÃ¡ximo de iteraÃ§Ãµes
            tol: TolerÃ¢ncia para convergÃªncia
        """
        T = len(observations)
        prev_likelihood = float('-inf')
        
        for iteration in range(max_iter):
            # E-Step: Forward-Backward
            alpha, log_likelihood = self.forward(observations)
            beta = self.backward(observations)
            
            # Calcular gamma: P(Xâ‚œ = i | Yâ‚, ..., Yâ‚œ)
            gamma = alpha * beta
            gamma = gamma / gamma.sum(axis=1, keepdims=True)
            
            # Calcular xi: P(Xâ‚œ = i, Xâ‚œâ‚Šâ‚ = j | Yâ‚, ..., Yâ‚œ)
            xi = np.zeros((T-1, self.n_states, self.n_states))
            for t in range(T-1):
                for i in range(self.n_states):
                    for j in range(self.n_states):
                        xi[t, i, j] = (alpha[t, i] * 
                                      self.trans_prob[i, j] * 
                                      self.emiss_prob[j, observations[t+1]] * 
                                      beta[t+1, j])
                
                xi[t] /= xi[t].sum()
            
            # M-Step: Atualizar parÃ¢metros
            # Atualizar start_prob
            self.start_prob = gamma[0]
            
            # Atualizar trans_prob
            self.trans_prob = xi.sum(axis=0) / gamma[:-1].sum(axis=0, keepdims=True).T
            
            # Atualizar emiss_prob
            for k in range(self.n_observations):
                mask = (observations == k)
                self.emiss_prob[:, k] = gamma[mask].sum(axis=0)
            
            self.emiss_prob /= gamma.sum(axis=0, keepdims=True).T
            
            # Verificar convergÃªncia
            if iteration > 0 and abs(log_likelihood - prev_likelihood) < tol:
                print(f"Convergiu na iteraÃ§Ã£o {iteration}")
                break
            
            prev_likelihood = log_likelihood
            
            if iteration % 10 == 0:
                print(f"IteraÃ§Ã£o {iteration}: log-likelihood = {log_likelihood:.4f}")
        
        return log_likelihood
    
    def generate(self, length):
        """
        Gerar sequÃªncia de observaÃ§Ãµes do modelo
        
        Args:
            length: Comprimento da sequÃªncia
        
        Returns:
            states: SequÃªncia de estados
            observations: SequÃªncia de observaÃ§Ãµes
        """
        states = np.zeros(length, dtype=int)
        observations = np.zeros(length, dtype=int)
        
        # Estado inicial
        states[0] = np.random.choice(self.n_states, p=self.start_prob)
        observations[0] = np.random.choice(
            self.n_observations, 
            p=self.emiss_prob[states[0]]
        )
        
        # Gerar sequÃªncia
        for t in range(1, length):
            states[t] = np.random.choice(
                self.n_states, 
                p=self.trans_prob[states[t-1]]
            )
            observations[t] = np.random.choice(
                self.n_observations, 
                p=self.emiss_prob[states[t]]
            )
        
        return states, observations

# Exemplo de uso: Modelo de clima
if __name__ == "__main__":
    # Definir modelo
    # Estados: 0=Ensolarado, 1=Nublado, 2=Chuvoso
    # ObservaÃ§Ãµes: 0=Seco, 1=Ãšmido, 2=Molhado
    
    hmm = HMM(n_states=3, n_observations=3)
    
    # Definir parÃ¢metros manualmente
    hmm.start_prob = np.array([0.6, 0.3, 0.1])
    
    hmm.trans_prob = np.array([
        [0.7, 0.2, 0.1],  # Ensolarado -> ...
        [0.3, 0.4, 0.3],  # Nublado -> ...
        [0.2, 0.3, 0.5]   # Chuvoso -> ...
    ])
    
    hmm.emiss_prob = np.array([
        [0.7, 0.25, 0.05],  # Ensolarado emite ...
        [0.2, 0.5, 0.3],    # Nublado emite ...
        [0.05, 0.25, 0.7]   # Chuvoso emite ...
    ])
    
    # Gerar dados
    print("Gerando sequÃªncia...")
    true_states, observations = hmm.generate(50)
    
    print(f"ObservaÃ§Ãµes: {observations[:20]}")
    print(f"Estados verdadeiros: {true_states[:20]}")
    
    # InferÃªncia: Viterbi
    print("\nInferÃªncia com Viterbi...")
    predicted_states, prob = hmm.viterbi(observations)
    
    print(f"Estados preditos: {predicted_states[:20]}")
    print(f"Probabilidade: {prob:.6f}")
    
    # AcurÃ¡cia
    accuracy = (predicted_states == true_states).mean()
    print(f"AcurÃ¡cia: {accuracy:.2%}")
    
    # Aprendizado: Baum-Welch
    print("\nAprendendo parÃ¢metros com Baum-Welch...")
    hmm_learn = HMM(n_states=3, n_observations=3)
    hmm_learn.baum_welch(observations, max_iter=50)
```

### **3.2 ğŸ¯ Kalman Filter**

```python
class KalmanFilter:
    """
    Kalman Filter - DBN com estados contÃ­nuos e modelo linear gaussiano
    """
    
    def __init__(self, dim_state, dim_obs):
        """
        Args:
            dim_state: DimensÃ£o do vetor de estado
            dim_obs: DimensÃ£o do vetor de observaÃ§Ã£o
        """
        self.dim_x = dim_state
        self.dim_z = dim_obs
        
        # Modelo de transiÃ§Ã£o: xâ‚œâ‚Šâ‚ = FÂ·xâ‚œ + w, w ~ N(0, Q)
        self.F = np.eye(dim_state)  # Matriz de transiÃ§Ã£o de estado
        self.Q = np.eye(dim_state)  # CovariÃ¢ncia do ruÃ­do de processo
        
        # Modelo de observaÃ§Ã£o: zâ‚œ = HÂ·xâ‚œ + v, v ~ N(0, R)
        self.H = np.eye(dim_obs, dim_state)  # Matriz de observaÃ§Ã£o
        self.R = np.eye(dim_obs)  # CovariÃ¢ncia do ruÃ­do de mediÃ§Ã£o
        
        # Estado e covariÃ¢ncia
        self.x = np.zeros(dim_state)  # Estimativa do estado
        self.P = np.eye(dim_state)    # CovariÃ¢ncia do estado
    
    def predict(self, u=None):
        """
        Etapa de PrediÃ§Ã£o (Time Update)
        
        Args:
            u: Vetor de controle/entrada (opcional)
        """
        # Predizer estado: xÌ‚â‚œâ‚Šâ‚|â‚œ = FÂ·xÌ‚â‚œ|â‚œ
        self.x = self.F @ self.x
        if u is not None:
            self.x += u
        
        # Predizer covariÃ¢ncia: Pâ‚œâ‚Šâ‚|â‚œ = FÂ·Pâ‚œ|â‚œÂ·Fáµ€ + Q
        self.P = self.F @ self.P @ self.F.T + self.Q
    
    def update(self, z):
        """
        Etapa de AtualizaÃ§Ã£o (Measurement Update)
        
        Args:
            z: Vetor de observaÃ§Ã£o/mediÃ§Ã£o
        """
        # InovaÃ§Ã£o: y = zâ‚œ - HÂ·xÌ‚â‚œ|â‚œâ‚‹â‚
        y = z - self.H @ self.x
        
        # CovariÃ¢ncia da inovaÃ§Ã£o: S = HÂ·Pâ‚œ|â‚œâ‚‹â‚Â·Háµ€ + R
        S = self.H @ self.P @ self.H.T + self.R
        
        # Ganho de Kalman: K = Pâ‚œ|â‚œâ‚‹â‚Â·Háµ€Â·Sâ»Â¹
        K = self.P @ self.H.T @ np.linalg.inv(S)
        
        # Atualizar estado: xÌ‚â‚œ|â‚œ = xÌ‚â‚œ|â‚œâ‚‹â‚ + KÂ·y
        self.x = self.x + K @ y
        
        # Atualizar covariÃ¢ncia: Pâ‚œ|â‚œ = (I - KÂ·H)Â·Pâ‚œ|â‚œâ‚‹â‚
        I = np.eye(self.dim_x)
        self.P = (I - K @ self.H) @ self.P
    
    def filter(self, observations, controls=None):
        """
        Filtragem completa de uma sequÃªncia
        
        Args:
            observations: Lista de vetores de observaÃ§Ã£o
            controls: Lista de vetores de controle (opcional)
        
        Returns:
            states: Estimativas do estado em cada instante
            covariances: CovariÃ¢ncias em cada instante
        """
        T = len(observations)
        states = np.zeros((T, self.dim_x))
        covariances = np.zeros((T, self.dim_x, self.dim_x))
        
        for t in range(T):
            # PrediÃ§Ã£o
            u = controls[t] if controls is not None else None
            self.predict(u)
            
            # AtualizaÃ§Ã£o
            self.update(observations[t])
            
            # Armazenar
            states[t] = self.x.copy()
            covariances[t] = self.P.copy()
        
        return states, covariances
    
    def smooth(self, observations):
        """
        SuavizaÃ§Ã£o RTS (Rauch-Tung-Striebel)
        
        Estima estados passados usando todas as observaÃ§Ãµes
        """
        T = len(observations)
        
        # Forward pass (filtragem)
        filtered_states = np.zeros((T, self.dim_x))
        filtered_covs = np.zeros((T, self.dim_x, self.dim_x))
        predicted_covs = np.zeros((T, self.dim_x, self.dim_x))
        
        for t in range(T):
            self.predict()
            predicted_covs[t] = self.P.copy()
            
            self.update(observations[t])
            filtered_states[t] = self.x.copy()
            filtered_covs[t] = self.P.copy()
        
        # Backward pass (suavizaÃ§Ã£o)
        smoothed_states = filtered_states.copy()
        smoothed_covs = filtered_covs.copy()
        
        for t in range(T-2, -1, -1):
            # Ganho de suavizaÃ§Ã£o
            C = filtered_covs[t] @ self.F.T @ np.linalg.inv(predicted_covs[t+1])
            
            # Suavizar estado
            smoothed_states[t] = (filtered_states[t] + 
                                 C @ (smoothed_states[t+1] - self.F @ filtered_states[t]))
            
            # Suavizar covariÃ¢ncia
            smoothed_covs[t] = (filtered_covs[t] + 
                               C @ (smoothed_covs[t+1] - predicted_covs[t+1]) @ C.T)
        
        return smoothed_states, smoothed_covs

# Exemplo: Rastreamento de posiÃ§Ã£o
if __name__ == "__main__":
    import matplotlib.pyplot as plt
    
    # Modelo: posiÃ§Ã£o em 2D com velocidade
    # Estado: [x, y, vx, vy]
    # ObservaÃ§Ã£o: [x, y]
    
    dt = 0.1  # Intervalo de tempo
    
    kf = KalmanFilter(dim_state=4, dim_obs=2)
    
    # Matriz de transiÃ§Ã£o (movimento uniforme)
    kf.F = np.array([
        [1, 0, dt, 0],
        [0, 1, 0, dt],
        [0, 0, 1, 0],
        [0, 0, 0, 1]
    ])
    
    # Matriz de observaÃ§Ã£o (observar apenas posiÃ§Ã£o)
    kf.H = np.array([
        [1, 0, 0, 0],
        [0, 1, 0, 0]
    ])
    
    # RuÃ­do de processo
    kf.Q = np.eye(4) * 0.1
    
    # RuÃ­do de mediÃ§Ã£o
    kf.R = np.eye(2) * 1.0
    
    # Estado inicial
    kf.x = np.array([0, 0, 1, 0.5])
    kf.P = np.eye(4) * 1.0
    
    # Simular trajetÃ³ria
    T = 100
    true_states = np.zeros((T, 4))
    observations = np.zeros((T, 2))
    
    true_states[0] = kf.x.copy()
    
    for t in range(1, T):
        # EvoluÃ§Ã£o verdadeira
        true_states[t] = kf.F @ true_states[t-1] + np.random.multivariate_normal(
            np.zeros(4), kf.Q
        )
        
        # ObservaÃ§Ã£o ruidosa
        observations[t] = kf.H @ true_states[t] + np.random.multivariate_normal(
            np.zeros(2), kf.R
        )
    
    # Resetar filtro
    kf.x = np.array([0, 0, 0, 0])
    kf.P = np.eye(4) * 5.0
    
    # Filtrar
    print("Filtrando...")
    filtered_states, _ = kf.filter(observations)
    
    # Suavizar
    print("Suavizando...")
    kf.x = np.array([0, 0, 0, 0])
    kf.P = np.eye(4) * 5.0
    smoothed_states, _ = kf.smooth(observations)
    
    # Visualizar
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(true_states[:, 0], true_states[:, 1], 'g-', 
            label='TrajetÃ³ria Verdadeira', linewidth=2)
    plt.scatter(observations[:, 0], observations[:, 1], 
               c='red', s=20, alpha=0.5, label='ObservaÃ§Ãµes Ruidosas')
    plt.plot(filtered_states[:, 0], filtered_states[:, 1], 'b--', 
            label='Filtrado (Kalman)', linewidth=2)
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Filtragem de Kalman')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    
    plt.subplot(1, 2, 2)
    plt.plot(true_states[:, 0], true_states[:, 1], 'g-', 
            label='TrajetÃ³ria Verdadeira', linewidth=2)
    plt.scatter(observations[:, 0], observations[:, 1], 
               c='red', s=20, alpha=0.5, label='ObservaÃ§Ãµes Ruidosas')
    plt.plot(smoothed_states[:, 0], smoothed_states[:, 1], 'm-', 
            label='Suavizado (RTS)', linewidth=2)
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('SuavizaÃ§Ã£o RTS')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    
    plt.tight_layout()
    plt.show()
    
    # Calcular erros
    mse_filtered = np.mean((filtered_states[:, :2] - true_states[:, :2])**2)
    mse_smoothed = np.mean((smoothed_states[:, :2] - true_states[:, :2])**2)
    
    print(f"\nMSE Filtrado: {mse_filtered:.4f}")
    print(f"MSE Suavizado: {mse_smoothed:.4f}")
```

---

## **4. ğŸ“Š AplicaÃ§Ãµes de DBNs**

### **4.1 ğŸ—£ï¸ Reconhecimento de Fala**

HMMs sÃ£o amplamente usados em reconhecimento automÃ¡tico de fala (ASR):

**Estrutura:**
- **Estados:** Fonemas ou sub-unidades fonÃ©ticas
- **ObservaÃ§Ãµes:** Vetores de caracterÃ­sticas acÃºsticas (MFCCs)

```python
class SpeechRecognitionHMM:
    """
    Sistema simplificado de reconhecimento de fala usando HMMs
    """
    
    def __init__(self, vocabulary):
        """
        Args:
            vocabulary: Lista de palavras a reconhecer
        """
        self.vocabulary = vocabulary
        self.word_models = {}
        
        # Criar um HMM para cada palavra
        for word in vocabulary:
            # NÃºmero de estados baseado no comprimento da palavra
            n_states = max(3, len(word))
            n_observations = 64  # DimensÃ£o do vetor de caracterÃ­sticas
            
            self.word_models[word] = HMM(n_states, n_observations)
    
    def train(self, word, speech_features_list):
        """
        Treinar modelo de uma palavra
        
        Args:
            word: Palavra a treinar
            speech_features_list: Lista de sequÃªncias de caracterÃ­sticas
        """
        # Treinar HMM com mÃºltiplas gravaÃ§Ãµes da palavra
        for features in speech_features_list:
            self.word_models[word].baum_welch(features, max_iter=20)
    
    def recognize(self, speech_features):
        """
        Reconhecer palavra falada
        
        Args:
            speech_features: SequÃªncia de caracterÃ­sticas acÃºsticas
        
        Returns:
            Palavra reconhecida e pontuaÃ§Ã£o de confianÃ§a
        """
        best_word = None
        best_likelihood = float('-inf')
        
        for word in self.vocabulary:
            _, log_likelihood = self.word_models[word].forward(speech_features)
            
            if log_likelihood > best_likelihood:
                best_likelihood = log_likelihood
                best_word = word
        
        return best_word, best_likelihood
```

### **4.2 ğŸ§¬ BioinformÃ¡tica: PrediÃ§Ã£o de Estrutura de ProteÃ­nas**

DBNs modelam a estrutura secundÃ¡ria de proteÃ­nas:

```python
class ProteinStructurePredictor:
    """
    PrediÃ§Ã£o de estrutura secundÃ¡ria de proteÃ­nas usando DBN
    """
    
    def __init__(self):
        # Estados: HÃ©lice (H), Folha (E), Loop (C)
        # ObservaÃ§Ãµes: 20 aminoÃ¡cidos
        self.hmm = HMM(n_states=3, n_observations=20)
        
        # Mapear aminoÃ¡cidos para Ã­ndices
        self.aa_to_idx = {aa: i for i, aa in enumerate('ACDEFGHIKLMNPQRSTVWY')}
    
    def sequence_to_indices(self, sequence):
        """
        Converter sequÃªncia de aminoÃ¡cidos em Ã­ndices
        """
        return np.array([self.aa_to_idx[aa] for aa in sequence])
    
    def predict_structure(self, protein_sequence):
        """
        Predizer estrutura secundÃ¡ria
        
        Args:
            protein_sequence: String com sequÃªncia de aminoÃ¡cidos
        
        Returns:
            structure: 'H' (hÃ©lice), 'E' (folha), ou 'C' (loop) para cada resÃ­duo
        """
        indices = self.sequence_to_indices(protein_sequence)
        states, _ = self.hmm.viterbi(indices)
        
        # Mapear estados para estruturas
        state_to_structure = {0: 'H', 1: 'E', 2: 'C'}
        structure = ''.join([state_to_structure[s] for s in states])
        
        return structure
```

### **4.3 ğŸ’° FinanÃ§as: DetecÃ§Ã£o de Regimes de Mercado**

DBNs identificam regimes de mercado (bull, bear, neutro):

```python
class MarketRegimeDetector:
    """
    Detector de regimes de mercado usando HMM
    """
    
    def __init__(self, n_regimes=3):
        """
        Args:
            n_regimes: NÃºmero de regimes (tipicamente 3: bull, bear, neutro)
        """
        self.n_regimes = n_regimes
        
        # Quantizar retornos em bins
        self.n_return_bins = 10
        
        self.hmm = HMM(n_states=n_regimes, n_observations=self.n_return_bins)
    
    def discretize_returns(self, returns):
        """
        Discretizar retornos contÃ­nuos em bins
        """
        # Usar quantis para criar bins
        quantiles = np.linspace(0, 1, self.n_return_bins + 1)
        bins = np.quantile(returns, quantiles)
        
        # Discretizar
        return np.digitize(returns, bins[1:-1])
    
    def fit(self, returns):
        """
        Treinar detector com dados histÃ³ricos
        
        Args:
            returns: SÃ©rie temporal de retornos
        """
        # Discretizar retornos
        discrete_returns = self.discretize_returns(returns)
        
        # Treinar HMM
        self.hmm.baum_welch(discrete_returns, max_iter=50)
    
    def detect_regime(self, returns):
        """
        Detectar regime atual
        
        Returns:
            regimes: SequÃªncia de regimes detectados
            probabilities: Probabilidades filtradas P(regime_t | returns_{1:t})
        """
        discrete_returns = self.discretize_returns(returns)
        
        # Forward para obter probabilidades filtradas
        alpha, _ = self.hmm.forward(discrete_returns)
        
        # Normalizar para obter probabilidades
        probabilities = alpha / alpha.sum(axis=1, keepdims=True)
        
        # Regime mais provÃ¡vel em cada instante
        regimes = np.argmax(probabilities, axis=1)
        
        return regimes, probabilities

# Exemplo de uso
if __name__ == "__main__":
    import matplotlib.pyplot as plt
    
    # Simular retornos de mercado com mudanÃ§a de regime
    np.random.seed(42)
    T = 500
    
    # Simular 3 regimes
    regime_returns = {
        0: (0.001, 0.01),   # Bull: alta mÃ©dia, baixa volatilidade
        1: (-0.002, 0.02),  # Bear: baixa mÃ©dia, alta volatilidade
        2: (0.0, 0.005)     # Neutro: mÃ©dia zero, baixa volatilidade
    }
    
    true_regimes = np.concatenate([
        np.zeros(150, dtype=int),
        np.ones(200, dtype=int),
        np.full(150, 2, dtype=int)
    ])
    
    returns = np.zeros(T)
    for t in range(T):
        regime = true_regimes[t]
        mean, std = regime_returns[regime]
        returns[t] = np.random.normal(mean, std)
    
    # Detectar regimes
    detector = MarketRegimeDetector(n_regimes=3)
    detector.fit(returns)
    detected_regimes, probs = detector.detect_regime(returns)
    
    # Visualizar
    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 10))
    
    # Retornos
    ax1.plot(returns, 'b-', alpha=0.7)
    ax1.set_ylabel('Retornos')
    ax1.set_title('Retornos do Mercado')
    ax1.grid(True, alpha=0.3)
    
    # Regimes verdadeiros
    ax2.plot(true_regimes, 'g-', linewidth=2, label='Regime Verdadeiro')
    ax2.set_ylabel('Regime')
    ax2.set_title('Regimes Verdadeiros')
    ax2.set_yticks([0, 1, 2])
    ax2.set_yticklabels(['Bull', 'Bear', 'Neutro'])
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    
    # Regimes detectados
    ax3.plot(detected_regimes, 'r-', linewidth=2, label='Regime Detectado')
    ax3.set_xlabel('Tempo')
    ax3.set_ylabel('Regime')
    ax3.set_title('Regimes Detectados pelo HMM')
    ax3.set_yticks([0, 1, 2])
    ax3.set_yticklabels(['Regime 0', 'Regime 1', 'Regime 2'])
    ax3.grid(True, alpha=0.3)
    ax3.legend()
    
    plt.tight_layout()
    plt.show()
    
    # AcurÃ¡cia
    accuracy = (detected_regimes == true_regimes).mean()
    print(f"AcurÃ¡cia na detecÃ§Ã£o de regimes: {accuracy:.2%}")
```

---

## **5. âš–ï¸ Vantagens e LimitaÃ§Ãµes**

### **5.1 âœ… Vantagens**

| **Vantagem** | **DescriÃ§Ã£o** |
|--------------|---------------|
| **ğŸ“Š Modelagem Temporal** | Captura dependÃªncias temporais naturalmente |
| **ğŸ¯ InferÃªncia Rigorosa** | FundamentaÃ§Ã£o probabilÃ­stica para raciocÃ­nio |
| **ğŸ”§ Flexibilidade** | Modela diversos tipos de processos temporais |
| **ğŸ“ˆ Interpretabilidade** | Estrutura de grafo facilita compreensÃ£o |
| **ğŸ² Lida com Incerteza** | Quantifica incerteza em prediÃ§Ãµes |
| **ğŸ§© Modularity** | FÃ¡cil adicionar/remover variÃ¡veis |

### **5.2 âŒ LimitaÃ§Ãµes**

| **LimitaÃ§Ã£o** | **DescriÃ§Ã£o** | **MitigaÃ§Ã£o** |
|---------------|---------------|---------------|
| **ğŸ’» Custo Computacional** | InferÃªncia exata pode ser cara | AproximaÃ§Ãµes (Particle Filter, Variational) |
| **ğŸ“Š AssunÃ§Ã£o de Markov** | Pode ser restritiva | Usar ordem superior ou modelo mais complexo |
| **ğŸ›ï¸ SeleÃ§Ã£o de Estrutura** | DifÃ­cil escolher estrutura Ã³tima | Aprendizado de estrutura, validaÃ§Ã£o cruzada |
| **ğŸ“ˆ Escalabilidade** | Problemas com muitas variÃ¡veis | AproximaÃ§Ãµes, paralelizaÃ§Ã£o |
| **ğŸ”§ Aprendizado** | Requer dados suficientes | RegularizaÃ§Ã£o, priors informativos |

---

## **6. ğŸ“š ReferÃªncias e Recursos**

### **6.1 ğŸ“– Literatura Fundamental**

1. **Murphy, K. P. (2012).** *Machine Learning: A Probabilistic Perspective*. MIT Press.
   - CapÃ­tulos 17-18: DBNs e inferÃªncia temporal

2. **Koller, D., & Friedman, N. (2009).** *Probabilistic Graphical Models*. MIT Press.
   - Tratamento completo de modelos grÃ¡ficos

3. **Rabiner, L. R. (1989).** *"A tutorial on hidden Markov models"*. Proceedings of the IEEE.
   - Tutorial clÃ¡ssico sobre HMMs

4. **Kalman, R. E. (1960).** *"A new approach to linear filtering and prediction problems"*. 
   - Artigo original do filtro de Kalman

### **6.2 ğŸŒ Recursos PrÃ¡ticos**

```python
# Bibliotecas Python
import hmmlearn  # Hidden Markov Models
from filterpy.kalman import KalmanFilter  # ImplementaÃ§Ã£o Kalman
import pyro  # ProgramaÃ§Ã£o probabilÃ­stica (inclui DBNs)
import pomegranate  # Modelos grÃ¡ficos probabilÃ­sticos
```

### **6.3 ğŸ”— Links Ãšteis**

- **hmmlearn:** https://hmmlearn.readthedocs.io
- **Pyro:** https://pyro.ai
- **PGM Course:** https://www.coursera.org/learn/probabilistic-graphical-models

---

## **7. ğŸ¯ ConclusÃ£o**

### **7.1 ğŸ’¡ Principais Aprendizados**

DBNs fornecem uma framework poderosa para modelagem temporal:

1. **UnificaÃ§Ã£o:** Integra modelos clÃ¡ssicos (HMM, Kalman) em framework comum
2. **ProbabilÃ­stico:** RaciocÃ­nio rigoroso sob incerteza
3. **Modular:** Estrutura permite fÃ¡cil modificaÃ§Ã£o e extensÃ£o
4. **VersÃ¡til:** AplicÃ¡vel a diversos domÃ­nios

### **7.2 ğŸ”‘ Quando Usar DBNs**

**âœ… CenÃ¡rios Ideais:**
- Dados sequenciais/temporais
- Necessidade de quantificar incerteza
- Estrutura causal conhecida ou deve ser descoberta
- IntegraÃ§Ã£o de mÃºltiplas fontes de informaÃ§Ã£o

**âŒ CenÃ¡rios ProblemÃ¡ticos:**
- Dados estÃ¡ticos sem estrutura temporal
- Quando velocidade de inferÃªncia Ã© crÃ­tica
- RelaÃ§Ãµes nÃ£o-estacionÃ¡rias complexas
- Dados extremamente grandes sem estrutura

### **7.3 ğŸŒŸ Mensagem Final**

> **"DBNs nos ensinam que modelar COMO o mundo evolui no tempo Ã© tÃ£o importante quanto modelar o que observamos agora."**

A capacidade de raciocinar sobre processos temporais de forma probabilÃ­stica torna DBNs indispensÃ¡veis em aplicaÃ§Ãµes onde o tempo e a incerteza sÃ£o fundamentais.

---

**ğŸ”— Continue Explorando:**
- ğŸ“– Relacionado: [**Gaussian Process Regression**](../statistical_learning/gaussian_process_regression.md)
- ğŸ¯ PrÃ³ximo: [**BUS with Subset Simulation**](../reliability_analysis/bus_subset_simulation.md)
- ğŸ”„ Veja tambÃ©m: [**Hidden Markov Models**](../probabilistic_models/hidden_markov_models.md)

**ğŸ“ Obrigado por explorar Redes Bayesianas DinÃ¢micas!**
