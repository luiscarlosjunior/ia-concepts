# BUS com Subset Simulation (SUS)

O **BUS com Subset Simulation** (Bayesian Updating with Structural reliability methods combined with Subset Simulation) Ã© um mÃ©todo avanÃ§ado de anÃ¡lise de confiabilidade estrutural e estimaÃ§Ã£o de probabilidades de eventos raros que combina tÃ©cnicas de atualizaÃ§Ã£o bayesiana com simulaÃ§Ã£o de subconjuntos. Este mÃ©todo Ã© especialmente eficaz para estimar probabilidades muito pequenas que seriam impraticÃ¡veis de calcular por Monte Carlo simples.

![Subset Simulation Concept](../../images/sus_concept.png)

Desenvolvido para engenharia estrutural e anÃ¡lise de risco, o mÃ©todo permite calcular probabilidades de falha da ordem de 10â»â¶ ou menores com eficiÃªncia computacional, sendo amplamente utilizado em anÃ¡lise de confiabilidade de estruturas, avaliaÃ§Ã£o de riscos sÃ­smicos, engenharia nuclear e sistemas complexos.

---

## **1. ğŸ¯ Fundamentos TeÃ³ricos**

### **1.1 O Problema de Eventos Raros**

Em anÃ¡lise de confiabilidade estrutural, frequentemente precisamos estimar:

```
Pf = P(g(X) â‰¤ 0)
```

Onde:
- **X:** Vetor de variÃ¡veis aleatÃ³rias (carregamentos, propriedades dos materiais, etc.)
- **g(X):** FunÃ§Ã£o de desempenho ou funÃ§Ã£o limite de estado
- **g(X) > 0:** Estado seguro
- **g(X) â‰¤ 0:** Estado de falha
- **Pf:** Probabilidade de falha

**Desafio:**
> Em estruturas bem projetadas, Pf Ã© tipicamente muito pequeno (10â»Â³ a 10â»â·), tornando a estimaÃ§Ã£o por Monte Carlo simples extremamente ineficiente.

#### **ğŸ² Problema com Monte Carlo Simples**

```python
# Monte Carlo Simples
N = 1_000_000  # NÃºmero de amostras
samples = generate_random_samples(N)
failures = sum(g(x) <= 0 for x in samples)
Pf_estimate = failures / N

# Para Pf = 10â»â¶:
# - PrecisarÃ­amos N â‰ˆ 10â¹ amostras
# - Se cada avaliaÃ§Ã£o leva 1ms, total = ~11 dias!
# âŒ ImpraticÃ¡vel
```

**Coeficiente de VariaÃ§Ã£o:**
```
COV = âˆš((1-Pf)/(NÂ·Pf))

Para Pf = 10â»â¶ e COV = 10%:
N â‰ˆ 10â¹ amostras necessÃ¡rias!
```

### **1.2 Conceito de Subset Simulation**

A **Subset Simulation** (SUS) resolve este problema decompondo o evento raro em uma sequÃªncia de eventos intermediÃ¡rios mais provÃ¡veis:

```
F = Fâ‚ âŠƒ Fâ‚‚ âŠƒ ... âŠƒ Fâ‚˜

Onde:
- F: Evento de falha original
- Fáµ¢: Eventos intermediÃ¡rios
- P(Fáµ¢â‚Šâ‚|Fáµ¢) â‰ˆ pâ‚€ (probabilidade condicional constante, ex: 0.1)
```

**FatorizaÃ§Ã£o:**
```
P(F) = P(Fâ‚) Ã— P(Fâ‚‚|Fâ‚) Ã— ... Ã— P(Fâ‚˜|Fâ‚˜â‚‹â‚)
```

**Vantagem:**
> Cada probabilidade condicional P(Fáµ¢â‚Šâ‚|Fáµ¢) Ã© maior (~0.1), permitindo estimaÃ§Ã£o eficiente!

#### **ğŸ“Š IlustraÃ§Ã£o Visual**

```
        EspaÃ§o Amostral Completo
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ Fâ‚: RegiÃ£o mais ampla
    â”‚  â”‚                     â”‚    â”‚ P(Fâ‚) â‰ˆ 0.1
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
    â”‚  â”‚  â”‚             â”‚    â”‚    â”‚ Fâ‚‚: RegiÃ£o intermediÃ¡ria
    â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”    â”‚    â”‚    â”‚ P(Fâ‚‚|Fâ‚) â‰ˆ 0.1
    â”‚  â”‚  â”‚  â”‚  F  â”‚    â”‚    â”‚    â”‚
    â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜    â”‚    â”‚    â”‚ F: Evento raro
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚ P(F|Fâ‚‚) â‰ˆ 0.1
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

P(F) = 0.1 Ã— 0.1 Ã— 0.1 = 10â»Â³
```

### **1.3 BUS: Bayesian Updating with Subset Simulation**

O **BUS** integra Subset Simulation com inferÃªncia bayesiana para atualizaÃ§Ã£o de modelos:

**Teorema de Bayes:**
```
P(Î¸|D) = P(D|Î¸) Ã— P(Î¸) / P(D)

Onde:
- Î¸: ParÃ¢metros do modelo (incertos)
- D: Dados observados
- P(Î¸): Prior (conhecimento inicial)
- P(D|Î¸): VerossimilhanÃ§a (compatibilidade com dados)
- P(Î¸|D): Posterior (conhecimento atualizado)
```

**Desafio no BUS:**
```
P(D) = âˆ« P(D|Î¸) P(Î¸) dÎ¸

Geralmente intratÃ¡vel analiticamente!
```

**SoluÃ§Ã£o BUS:**
> Usar Subset Simulation para amostrar eficientemente do posterior, especialmente quando P(D|Î¸) Ã© pequeno (dados raros ou extremos).

---

## **2. ğŸ”§ Algoritmo Subset Simulation**

### **2.1 Algoritmo Completo**

```
ğŸš€ 1. INICIALIZAÃ‡ÃƒO
   â”œâ”€â”€ Definir funÃ§Ã£o de desempenho g(X)
   â”œâ”€â”€ Definir N (tamanho da populaÃ§Ã£o, tipicamente 1000-5000)
   â”œâ”€â”€ Definir pâ‚€ (probabilidade condicional alvo, tipicamente 0.1-0.2)
   â””â”€â”€ m â† 0 (nÃ­vel atual)

ğŸ“Š 2. NÃVEL 0: Monte Carlo Simples
   â”œâ”€â”€ Gerar N amostras de X ~ fâ‚“(x)
   â”œâ”€â”€ Avaliar g(X) para todas as amostras
   â”œâ”€â”€ Ordenar amostras por g(X)
   â””â”€â”€ Estimar P(Fâ‚) = #{g(X) â‰¤ gâ‚} / N
       onde gâ‚ Ã© o (pâ‚€Ã—N)-Ã©simo menor valor

ğŸ”„ 3. NÃVEIS INTERMEDIÃRIOS (m = 1, 2, ...)
   â”œâ”€â”€ Para cada amostra que satisfaz g(X) â‰¤ gâ‚˜:
   â”‚   â””â”€â”€ Gerar 1/pâ‚€ novas amostras usando MCMC
   â”‚       (condicionado a g(X) â‰¤ gâ‚˜)
   â”‚
   â”œâ”€â”€ Avaliar g(X) para novas amostras
   â”œâ”€â”€ Ordenar por g(X)
   â””â”€â”€ Se g_{(pâ‚€Ã—N)} > 0:
       â”‚   â””â”€â”€ gâ‚˜â‚Šâ‚ = g_{(pâ‚€Ã—N)} (continuar)
       â””â”€â”€ SenÃ£o:
           â””â”€â”€ Ãšltimo nÃ­vel alcanÃ§ado

ğŸ 4. ÃšLTIMO NÃVEL
   â”œâ”€â”€ Calcular #{g(X) â‰¤ 0} / N no Ãºltimo nÃ­vel
   â””â”€â”€ Pf = P(Fâ‚) Ã— âˆâ‚˜â‚Œâ‚á´¹â»Â¹ pâ‚€ Ã— P(Fâ‚˜|Fâ‚˜â‚‹â‚)

ğŸ“ˆ 5. RETORNAR
   â””â”€â”€ Probabilidade de falha Pf e amostras de falha
```

### **2.2 Componente MCMC: Modified Metropolis-Hastings**

O componente crucial Ã© gerar novas amostras condicionadas a g(X) â‰¤ gâ‚˜:

```python
def modified_metropolis_hastings(x_current, g_threshold, g_function, 
                                 proposal_std, max_iterations=1):
    """
    Modified Metropolis-Hastings para SUS
    
    Args:
        x_current: Amostra atual (jÃ¡ satisfaz g(x) â‰¤ g_threshold)
        g_threshold: Limiar atual
        g_function: FunÃ§Ã£o de desempenho
        proposal_std: Desvio padrÃ£o da proposta
        max_iterations: NÃºmero de passos MCMC
    
    Returns:
        Nova amostra que satisfaz g(x) â‰¤ g_threshold
    """
    x = x_current.copy()
    
    for _ in range(max_iterations):
        # Propor nova amostra (caminhada aleatÃ³ria gaussiana)
        x_proposed = x + np.random.normal(0, proposal_std, size=len(x))
        
        # Avaliar funÃ§Ã£o de desempenho
        g_proposed = g_function(x_proposed)
        g_current = g_function(x)
        
        # CritÃ©rio de aceitaÃ§Ã£o modificado
        if g_proposed <= g_threshold:
            # Dentro da regiÃ£o: aceitar com probabilidade Metropolis
            # Para distribuiÃ§Ãµes simÃ©tricas no espaÃ§o padrÃ£o:
            accept_prob = min(1.0, 
                             pdf_prior(x_proposed) / pdf_prior(x))
            
            if np.random.rand() < accept_prob:
                x = x_proposed
        
        # Se g_proposed > g_threshold: rejeitar automaticamente
    
    return x
```

---

## **3. ğŸ’» ImplementaÃ§Ã£o Completa de Subset Simulation**

### **3.1 ğŸ”§ ImplementaÃ§Ã£o BÃ¡sica**

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import norm

class SubsetSimulation:
    """
    ImplementaÃ§Ã£o de Subset Simulation para anÃ¡lise de confiabilidade
    """
    
    def __init__(self, performance_function, dim, p0=0.1, N=1000):
        """
        Args:
            performance_function: FunÃ§Ã£o g(X), falha quando g(X) â‰¤ 0
            dim: DimensÃ£o do vetor de variÃ¡veis aleatÃ³rias
            p0: Probabilidade condicional alvo para cada nÃ­vel
            N: Tamanho da populaÃ§Ã£o em cada nÃ­vel
        """
        self.g = performance_function
        self.dim = dim
        self.p0 = p0
        self.N = N
        
        # NÃºmero de sementes em cada nÃ­vel
        self.n_seeds = int(p0 * N)
        
        # NÃºmero de cadeias por semente
        self.n_chains = int(1 / p0)
        
        # HistÃ³rico
        self.levels = []
        self.thresholds = []
        self.samples_per_level = []
    
    def sample_prior(self, n_samples):
        """
        Gerar amostras da distribuiÃ§Ã£o prior
        
        Por padrÃ£o, assume distribuiÃ§Ã£o gaussiana padrÃ£o multivariada
        Sobrescrever para outras distribuiÃ§Ãµes
        """
        return np.random.randn(n_samples, self.dim)
    
    def prior_pdf(self, x):
        """
        PDF da distribuiÃ§Ã£o prior
        """
        # Gaussiana padrÃ£o multivariada
        return np.prod(norm.pdf(x))
    
    def mcmc_step(self, x_current, g_threshold, proposal_std=1.0):
        """
        Um passo de MCMC condicionado a g(X) â‰¤ g_threshold
        """
        # Proposta: caminhada aleatÃ³ria gaussiana
        x_proposed = x_current + np.random.normal(0, proposal_std, size=self.dim)
        
        # Avaliar proposta
        g_proposed = self.g(x_proposed)
        
        # CritÃ©rio de aceitaÃ§Ã£o modificado
        if g_proposed <= g_threshold:
            # Calcular razÃ£o de aceitaÃ§Ã£o
            accept_ratio = self.prior_pdf(x_proposed) / self.prior_pdf(x_current)
            
            if np.random.rand() < min(1.0, accept_ratio):
                return x_proposed, g_proposed
        
        # Manter amostra atual
        g_current = self.g(x_current)
        return x_current, g_current
    
    def run(self, max_levels=20, verbose=True):
        """
        Executar Subset Simulation
        
        Returns:
            Pf: Probabilidade de falha estimada
            COV: Coeficiente de variaÃ§Ã£o
            samples: Amostras do Ãºltimo nÃ­vel (regiÃ£o de falha)
        """
        if verbose:
            print("="*60)
            print("SUBSET SIMULATION")
            print("="*60)
        
        # ===== NÃVEL 0: Monte Carlo Simples =====
        if verbose:
            print(f"\nğŸ“Š NÃVEL 0: Monte Carlo Simples")
            print(f"   Gerando {self.N} amostras...")
        
        samples = self.sample_prior(self.N)
        g_values = np.array([self.g(x) for x in samples])
        
        # Ordenar por valor de g
        sorted_indices = np.argsort(g_values)
        samples = samples[sorted_indices]
        g_values = g_values[sorted_indices]
        
        # Determinar limiar do primeiro nÃ­vel
        threshold_idx = self.n_seeds
        g_threshold = g_values[threshold_idx]
        
        # Probabilidade do primeiro nÃ­vel
        if g_threshold > 0:
            p_level = self.p0
        else:
            # JÃ¡ alcanÃ§amos regiÃ£o de falha no primeiro nÃ­vel
            p_level = np.sum(g_values <= 0) / self.N
            
            if verbose:
                print(f"   âœ… RegiÃ£o de falha alcanÃ§ada no primeiro nÃ­vel!")
                print(f"   Pf = {p_level:.6e}")
            
            self.levels.append(0)
            self.thresholds.append(0.0)
            self.samples_per_level.append(samples)
            
            return p_level, 0.0, samples[g_values <= 0]
        
        if verbose:
            print(f"   Limiar: gâ‚ = {g_threshold:.4f}")
            print(f"   P(Fâ‚) = {p_level:.4f}")
        
        self.levels.append(0)
        self.thresholds.append(g_threshold)
        self.samples_per_level.append(samples.copy())
        
        # Produto acumulado de probabilidades
        prob_product = p_level
        
        # ===== NÃVEIS INTERMEDIÃRIOS =====
        level = 1
        
        while level < max_levels:
            if verbose:
                print(f"\nğŸ”„ NÃVEL {level}")
            
            # Sementes: top p0*N amostras do nÃ­vel anterior
            seeds = samples[:self.n_seeds]
            
            # Gerar novas amostras via MCMC
            new_samples = []
            new_g_values = []
            
            for seed in seeds:
                # Para cada semente, gerar n_chains amostras
                x = seed.copy()
                g_val = self.g(x)
                
                new_samples.append(x)
                new_g_values.append(g_val)
                
                # Gerar cadeias
                for _ in range(self.n_chains - 1):
                    x, g_val = self.mcmc_step(x, g_threshold)
                    new_samples.append(x.copy())
                    new_g_values.append(g_val)
            
            samples = np.array(new_samples)
            g_values = np.array(new_g_values)
            
            # Ordenar
            sorted_indices = np.argsort(g_values)
            samples = samples[sorted_indices]
            g_values = g_values[sorted_indices]
            
            # Novo limiar
            threshold_idx = self.n_seeds
            g_threshold_new = g_values[threshold_idx]
            
            if g_threshold_new > 0:
                # Continuar para prÃ³ximo nÃ­vel
                g_threshold = g_threshold_new
                p_level = self.p0
                prob_product *= p_level
                
                if verbose:
                    print(f"   Limiar: g_{level+1} = {g_threshold:.4f}")
                    print(f"   P(F_{level+1}|F_{level}) = {p_level:.4f}")
                    print(f"   P acumulada = {prob_product:.6e}")
                
                self.levels.append(level)
                self.thresholds.append(g_threshold)
                self.samples_per_level.append(samples.copy())
                
                level += 1
            else:
                # Ãšltimo nÃ­vel alcanÃ§ado
                p_level = np.sum(g_values <= 0) / self.N
                prob_product *= p_level
                
                if verbose:
                    print(f"   âœ… Ãšltimo nÃ­vel alcanÃ§ado!")
                    print(f"   P(Falha|F_{level}) = {p_level:.4f}")
                    print(f"   Pf = {prob_product:.6e}")
                
                self.levels.append(level)
                self.thresholds.append(0.0)
                self.samples_per_level.append(samples.copy())
                
                break
        
        # Calcular coeficiente de variaÃ§Ã£o
        # Para SUS: COV â‰ˆ âˆš[(1-p0)/(p0*N*m)]
        m = len(self.levels)
        cov = np.sqrt((1 - self.p0) / (self.p0 * self.N * m))
        
        if verbose:
            print(f"\n{'='*60}")
            print(f"RESULTADO FINAL:")
            print(f"  Pf = {prob_product:.6e}")
            print(f"  COV = {cov:.4f} ({cov*100:.2f}%)")
            print(f"  NÃºmero de nÃ­veis: {m}")
            print(f"  Total de avaliaÃ§Ãµes: {self.N + (m-1)*self.N}")
            print(f"{'='*60}")
        
        # Retornar amostras de falha
        failure_samples = samples[g_values <= 0]
        
        return prob_product, cov, failure_samples
    
    def plot_levels(self, figsize=(14, 8)):
        """
        Visualizar evoluÃ§Ã£o dos nÃ­veis (apenas para 2D)
        """
        if self.dim != 2:
            print("VisualizaÃ§Ã£o disponÃ­vel apenas para problemas 2D")
            return
        
        n_levels = len(self.levels)
        
        fig, axes = plt.subplots(2, (n_levels + 1) // 2, 
                                figsize=figsize, squeeze=False)
        axes = axes.flatten()
        
        for i, level in enumerate(self.levels):
            ax = axes[i]
            
            samples = self.samples_per_level[i]
            g_vals = np.array([self.g(x) for x in samples])
            
            # Plotar amostras
            scatter = ax.scatter(samples[:, 0], samples[:, 1], 
                               c=g_vals, cmap='RdYlGn_r', 
                               s=30, alpha=0.6, edgecolors='black', linewidth=0.5)
            
            # Linha g(X) = 0 (regiÃ£o de falha)
            x_range = np.linspace(samples[:, 0].min(), samples[:, 0].max(), 100)
            # Esta visualizaÃ§Ã£o assume conhecimento da forma de g
            # Em geral, seria necessÃ¡rio contour plot
            
            ax.set_xlabel('Xâ‚')
            ax.set_ylabel('Xâ‚‚')
            ax.set_title(f'NÃ­vel {level}: g â‰¤ {self.thresholds[i]:.2f}')
            ax.grid(True, alpha=0.3)
            
            plt.colorbar(scatter, ax=ax, label='g(X)')
        
        # Ocultar eixos nÃ£o usados
        for i in range(n_levels, len(axes)):
            axes[i].axis('off')
        
        plt.tight_layout()
        plt.show()

# Exemplo: Problema de confiabilidade estrutural simples
def example_linear_performance():
    """
    Exemplo com funÃ§Ã£o de desempenho linear
    g(X) = 3 - Xâ‚ - Xâ‚‚
    """
    
    def performance_function(x):
        return 3.0 - x[0] - x[1]
    
    # Executar SUS
    sus = SubsetSimulation(
        performance_function=performance_function,
        dim=2,
        p0=0.1,
        N=1000
    )
    
    Pf, COV, failure_samples = sus.run(verbose=True)
    
    # Calcular soluÃ§Ã£o analÃ­tica (para validaÃ§Ã£o)
    # P(Xâ‚ + Xâ‚‚ > 3) onde Xâ‚, Xâ‚‚ ~ N(0,1)
    # Xâ‚ + Xâ‚‚ ~ N(0, 2), entÃ£o P(Xâ‚ + Xâ‚‚ > 3) = P(Z > 3/âˆš2)
    from scipy.stats import norm
    Pf_exact = 1 - norm.cdf(3 / np.sqrt(2))
    
    print(f"\n{'='*60}")
    print(f"VALIDAÃ‡ÃƒO:")
    print(f"  Pf (SUS):   {Pf:.6e}")
    print(f"  Pf (Exato): {Pf_exact:.6e}")
    print(f"  Erro:       {abs(Pf - Pf_exact)/Pf_exact * 100:.2f}%")
    print(f"{'='*60}")
    
    # Visualizar
    sus.plot_levels()
    
    return Pf, COV

if __name__ == "__main__":
    example_linear_performance()
```

### **3.2 ğŸ¯ Exemplo: FunÃ§Ã£o de Desempenho NÃ£o-Linear**

```python
def example_nonlinear_performance():
    """
    Exemplo mais complexo: funÃ§Ã£o de desempenho nÃ£o-linear
    g(X) = 5 - Xâ‚Â² - Xâ‚‚Â²  (cÃ­rculo)
    """
    
    def performance_function(x):
        return 5.0 - x[0]**2 - x[1]**2
    
    # Executar SUS
    sus = SubsetSimulation(
        performance_function=performance_function,
        dim=2,
        p0=0.1,
        N=2000
    )
    
    Pf, COV, failure_samples = sus.run(verbose=True)
    
    # Visualizar espaÃ§o de falha
    plt.figure(figsize=(10, 8))
    
    # Gerar grid para contour
    x1 = np.linspace(-4, 4, 200)
    x2 = np.linspace(-4, 4, 200)
    X1, X2 = np.meshgrid(x1, x2)
    
    # Calcular g em todo o grid
    G = np.zeros_like(X1)
    for i in range(len(x1)):
        for j in range(len(x2)):
            G[j, i] = performance_function(np.array([X1[j, i], X2[j, i]]))
    
    # Plot contour
    plt.contour(X1, X2, G, levels=[0], colors='red', linewidths=3, 
               label='RegiÃ£o de Falha (g=0)')
    plt.contourf(X1, X2, G, levels=[-100, 0], colors='red', alpha=0.2)
    
    # Plot amostras de falha
    if len(failure_samples) > 0:
        plt.scatter(failure_samples[:, 0], failure_samples[:, 1], 
                   c='darkred', s=50, marker='x', label='Amostras de Falha')
    
    # Plot Ãºltimas amostras de nÃ­vel intermediÃ¡rio
    last_samples = sus.samples_per_level[-1]
    plt.scatter(last_samples[:, 0], last_samples[:, 1], 
               c='blue', s=20, alpha=0.5, label='Ãšltimo NÃ­vel SUS')
    
    plt.xlabel('Xâ‚')
    plt.ylabel('Xâ‚‚')
    plt.title(f'Subset Simulation - Pf = {Pf:.6e}')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    plt.tight_layout()
    plt.show()
    
    # Calcular soluÃ§Ã£o semi-analÃ­tica
    # P(Xâ‚Â² + Xâ‚‚Â² > 5) onde Xâ‚, Xâ‚‚ ~ N(0,1)
    # Xâ‚Â² + Xâ‚‚Â² ~ Ï‡Â²(2)
    from scipy.stats import chi2
    Pf_exact = 1 - chi2.cdf(5, df=2)
    
    print(f"\n{'='*60}")
    print(f"VALIDAÃ‡ÃƒO:")
    print(f"  Pf (SUS):   {Pf:.6e}")
    print(f"  Pf (Exato): {Pf_exact:.6e}")
    print(f"  Erro:       {abs(Pf - Pf_exact)/Pf_exact * 100:.2f}%")
    print(f"{'='*60}")

if __name__ == "__main__":
    example_nonlinear_performance()
```

---

## **4. ğŸ“Š BUS: Bayesian Updating with Subset Simulation**

### **4.1 ğŸ”§ ImplementaÃ§Ã£o do BUS**

```python
class BayesianUpdatingSubsetSimulation:
    """
    BUS - Bayesian Updating com Subset Simulation
    
    Para atualizar distribuiÃ§Ã£o de parÃ¢metros Î¸ dado dados D
    usando Subset Simulation para amostrar do posterior
    """
    
    def __init__(self, prior_sampler, likelihood_function, dim_theta, 
                 p0=0.1, N=1000):
        """
        Args:
            prior_sampler: FunÃ§Ã£o para amostrar do prior P(Î¸)
            likelihood_function: FunÃ§Ã£o L(D|Î¸)
            dim_theta: DimensÃ£o do vetor de parÃ¢metros
            p0: Probabilidade condicional alvo
            N: Tamanho da populaÃ§Ã£o
        """
        self.sample_prior = prior_sampler
        self.likelihood = likelihood_function
        self.dim = dim_theta
        self.p0 = p0
        self.N = N
        
        self.n_seeds = int(p0 * N)
        self.n_chains = int(1 / p0)
        
        # HistÃ³rico
        self.levels = []
        self.thresholds = []
        self.samples_per_level = []
    
    def log_likelihood(self, theta):
        """
        Calcular log-verossimilhanÃ§a
        """
        return np.log(self.likelihood(theta) + 1e-300)  # Evitar log(0)
    
    def mcmc_step(self, theta_current, log_L_threshold, proposal_std=0.5):
        """
        Passo MCMC para BUS
        """
        # Proposta
        theta_proposed = theta_current + np.random.normal(
            0, proposal_std, size=self.dim
        )
        
        # Log-verossimilhanÃ§a da proposta
        log_L_proposed = self.log_likelihood(theta_proposed)
        
        # CritÃ©rio de aceitaÃ§Ã£o
        if log_L_proposed >= log_L_threshold:
            # Dentro da regiÃ£o: aceitar com probabilidade MH
            # Para prior uniforme ou simÃ©trico, aceitar sempre
            return theta_proposed, log_L_proposed
        
        # Fora da regiÃ£o: rejeitar
        log_L_current = self.log_likelihood(theta_current)
        return theta_current, log_L_current
    
    def run(self, max_levels=20, target_log_L=None, verbose=True):
        """
        Executar BUS para amostrar do posterior
        
        Args:
            max_levels: NÃºmero mÃ¡ximo de nÃ­veis
            target_log_L: Log-verossimilhanÃ§a alvo (opcional)
            verbose: Imprimir progresso
        
        Returns:
            posterior_samples: Amostras do posterior
            evidence: Estimativa da evidÃªncia P(D)
        """
        if verbose:
            print("="*60)
            print("BAYESIAN UPDATING WITH SUBSET SIMULATION")
            print("="*60)
        
        # ===== NÃVEL 0 =====
        if verbose:
            print(f"\nğŸ“Š NÃVEL 0: Amostragem do Prior")
        
        samples = np.array([self.sample_prior() for _ in range(self.N)])
        log_L_values = np.array([self.log_likelihood(theta) 
                                 for theta in samples])
        
        # Ordenar por log-verossimilhanÃ§a (maior = melhor)
        sorted_indices = np.argsort(log_L_values)[::-1]
        samples = samples[sorted_indices]
        log_L_values = log_L_values[sorted_indices]
        
        # Limiar do primeiro nÃ­vel
        threshold_idx = self.n_seeds
        log_L_threshold = log_L_values[threshold_idx]
        
        # Verificar se jÃ¡ atingimos alvo
        if target_log_L is not None and log_L_threshold >= target_log_L:
            if verbose:
                print(f"   âœ… Alvo alcanÃ§ado no primeiro nÃ­vel!")
            
            posterior_samples = samples[log_L_values >= target_log_L]
            evidence = len(posterior_samples) / self.N
            
            return posterior_samples, evidence
        
        if verbose:
            print(f"   Limiar: log L â‰¥ {log_L_threshold:.4f}")
            print(f"   P(L â‰¥ Lâ‚) = {self.p0:.4f}")
        
        self.levels.append(0)
        self.thresholds.append(log_L_threshold)
        self.samples_per_level.append(samples.copy())
        
        # Produto de probabilidades
        prob_product = self.p0
        
        # ===== NÃVEIS INTERMEDIÃRIOS =====
        level = 1
        
        while level < max_levels:
            if verbose:
                print(f"\nğŸ”„ NÃVEL {level}")
            
            # Sementes
            seeds = samples[:self.n_seeds]
            
            # MCMC para gerar novas amostras
            new_samples = []
            new_log_L = []
            
            for seed in seeds:
                theta = seed.copy()
                log_L = self.log_likelihood(theta)
                
                new_samples.append(theta)
                new_log_L.append(log_L)
                
                for _ in range(self.n_chains - 1):
                    theta, log_L = self.mcmc_step(theta, log_L_threshold)
                    new_samples.append(theta.copy())
                    new_log_L.append(log_L)
            
            samples = np.array(new_samples)
            log_L_values = np.array(new_log_L)
            
            # Ordenar
            sorted_indices = np.argsort(log_L_values)[::-1]
            samples = samples[sorted_indices]
            log_L_values = log_L_values[sorted_indices]
            
            # Novo limiar
            log_L_threshold_new = log_L_values[self.n_seeds]
            
            # Verificar se atingimos alvo
            if target_log_L is not None and log_L_threshold_new >= target_log_L:
                p_level = np.sum(log_L_values >= target_log_L) / self.N
                prob_product *= p_level
                
                if verbose:
                    print(f"   âœ… Alvo alcanÃ§ado!")
                    print(f"   P(L â‰¥ Lalvo|F_{level}) = {p_level:.4f}")
                    print(f"   Evidence P(D) â‰ˆ {prob_product:.6e}")
                
                posterior_samples = samples[log_L_values >= target_log_L]
                
                return posterior_samples, prob_product
            
            # Continuar
            log_L_threshold = log_L_threshold_new
            prob_product *= self.p0
            
            if verbose:
                print(f"   Limiar: log L â‰¥ {log_L_threshold:.4f}")
                print(f"   P acumulada = {prob_product:.6e}")
            
            self.levels.append(level)
            self.thresholds.append(log_L_threshold)
            self.samples_per_level.append(samples.copy())
            
            level += 1
        
        # Se nÃ£o especificou alvo, retornar amostras do Ãºltimo nÃ­vel
        if verbose:
            print(f"\n{'='*60}")
            print(f"AlcanÃ§ado nÃºmero mÃ¡ximo de nÃ­veis")
            print(f"Evidence (aproximada) â‰ˆ {prob_product:.6e}")
            print(f"{'='*60}")
        
        return samples, prob_product

# Exemplo: AtualizaÃ§Ã£o bayesiana de parÃ¢metro de modelo
def example_bus_parameter_estimation():
    """
    Exemplo: Estimar mÃ©dia Î¼ de distribuiÃ§Ã£o normal 
    dado observaÃ§Ãµes
    """
    # Dados observados
    np.random.seed(42)
    true_mu = 2.0
    true_sigma = 1.0
    n_obs = 10
    observations = np.random.normal(true_mu, true_sigma, n_obs)
    
    print(f"Dados observados: mÃ©dia = {observations.mean():.4f}")
    
    # Prior: Î¼ ~ N(0, 5Â²)
    def prior_sampler():
        return np.array([np.random.normal(0, 5)])
    
    # Likelihood: P(D|Î¼) assumindo Ïƒ conhecido
    def likelihood_function(theta):
        mu = theta[0]
        # Produto de normais
        log_L = -0.5 * np.sum((observations - mu)**2) / (true_sigma**2)
        log_L -= 0.5 * n_obs * np.log(2 * np.pi * true_sigma**2)
        return np.exp(log_L)
    
    # Executar BUS
    bus = BayesianUpdatingSubsetSimulation(
        prior_sampler=prior_sampler,
        likelihood_function=likelihood_function,
        dim_theta=1,
        p0=0.1,
        N=1000
    )
    
    posterior_samples, evidence = bus.run(
        max_levels=10,
        target_log_L=None,  # Amostrar de todo o posterior
        verbose=True
    )
    
    # Comparar com soluÃ§Ã£o analÃ­tica
    # Posterior: Î¼ ~ N(Î¼_post, Ïƒ_postÂ²)
    sigma_prior = 5.0
    mu_post = (observations.sum() / true_sigma**2) / \
              (n_obs / true_sigma**2 + 1 / sigma_prior**2)
    sigma_post = 1 / np.sqrt(n_obs / true_sigma**2 + 1 / sigma_prior**2)
    
    print(f"\n{'='*60}")
    print(f"COMPARAÃ‡ÃƒO COM SOLUÃ‡ÃƒO ANALÃTICA:")
    print(f"  Î¼ verdadeiro: {true_mu:.4f}")
    print(f"  BUS - Î¼ posterior: {posterior_samples[:, 0].mean():.4f} Â± "
          f"{posterior_samples[:, 0].std():.4f}")
    print(f"  AnalÃ­tico - Î¼ posterior: {mu_post:.4f} Â± {sigma_post:.4f}")
    print(f"{'='*60}")
    
    # Visualizar posterior
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.hist(posterior_samples[:, 0], bins=50, density=True, 
            alpha=0.7, label='BUS')
    
    # Posterior analÃ­tico
    x = np.linspace(posterior_samples[:, 0].min(), 
                   posterior_samples[:, 0].max(), 200)
    plt.plot(x, norm.pdf(x, mu_post, sigma_post), 
            'r-', linewidth=2, label='AnalÃ­tico')
    
    plt.axvline(true_mu, color='green', linestyle='--', 
               linewidth=2, label='Verdadeiro')
    plt.xlabel('Î¼')
    plt.ylabel('Densidade')
    plt.title('DistribuiÃ§Ã£o Posterior de Î¼')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    # Trace plot
    plt.plot(posterior_samples[:, 0], 'b-', alpha=0.5)
    plt.axhline(true_mu, color='green', linestyle='--', 
               linewidth=2, label='Verdadeiro')
    plt.xlabel('Ãndice da Amostra')
    plt.ylabel('Î¼')
    plt.title('Trace Plot - Amostras do Posterior')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    example_bus_parameter_estimation()
```

---

## **5. âš–ï¸ Vantagens e LimitaÃ§Ãµes**

### **5.1 âœ… Vantagens**

| **Vantagem** | **DescriÃ§Ã£o** |
|--------------|---------------|
| **âš¡ EficiÃªncia** | Estima eventos raros com ~10â´ avaliaÃ§Ãµes vs ~10â¹ em MC |
| **ğŸ¯ Robustez** | COV nÃ£o depende fortemente de Pf |
| **ğŸ”§ Simples** | Algoritmo relativamente fÃ¡cil de implementar |
| **ğŸŒ Generalidade** | AplicÃ¡vel a funÃ§Ãµes de desempenho gerais |
| **ğŸ“Š Amostras de Falha** | Fornece amostras da regiÃ£o de falha |
| **ğŸ§® IntegraÃ§Ã£o Bayesiana** | BUS permite atualizaÃ§Ã£o eficiente |

### **5.2 âŒ LimitaÃ§Ãµes**

| **LimitaÃ§Ã£o** | **DescriÃ§Ã£o** | **MitigaÃ§Ã£o** |
|---------------|---------------|---------------|
| **ğŸ›ï¸ ParÃ¢metro p0** | SensÃ­vel Ã  escolha de p0 | Usar p0 = 0.1 a 0.2 |
| **ğŸ”— CorrelaÃ§Ã£o MCMC** | Cadeias MCMC podem ser correlacionadas | Aumentar comprimento das cadeias |
| **ğŸ“Š RegiÃµes Desconexas** | Dificuldade com mÃºltiplas regiÃµes de falha | Algoritmos adaptativos |
| **ğŸ”„ ConvergÃªncia MCMC** | MCMC pode nÃ£o convergir adequadamente | DiagnÃ³sticos de convergÃªncia |
| **ğŸ’» Custo por AvaliaÃ§Ã£o** | Ainda requer muitas avaliaÃ§Ãµes de g(X) | Usar modelos substitutos |

---

## **6. ğŸ“š ReferÃªncias e Recursos**

### **6.1 ğŸ“– Literatura Fundamental**

1. **Au, S. K., & Beck, J. L. (2001).** *"Estimation of small failure probabilities in high dimensions by subset simulation"*. Probabilistic Engineering Mechanics, 16(4), 263-277.
   - ğŸ“˜ **Artigo original:** IntroduÃ§Ã£o do Subset Simulation

2. **Straub, D., & Papaioannou, I. (2015).** *"Bayesian updating with structural reliability methods"*. Journal of Engineering Mechanics, 141(3).
   - ğŸ¯ **BUS:** MÃ©todo BUS completo

3. **Au, S. K., & Beck, J. L. (2003).** *"Subset simulation and its application to seismic risk based on dynamic analysis"*. Journal of Engineering Mechanics, 129(8), 901-917.
   - ğŸ—ï¸ **AplicaÃ§Ã£o:** Engenharia sÃ­smica

4. **Papaioannou, I., et al. (2015).** *"MCMC algorithms for subset simulation"*. Probabilistic Engineering Mechanics, 41, 89-103.
   - ğŸ”„ **MCMC:** ComparaÃ§Ã£o de algoritmos MCMC

### **6.2 ğŸŒ Recursos PrÃ¡ticos**

```python
# Bibliotecas Python para anÃ¡lise de confiabilidade

# UQpy: Uncertainty Quantification with Python
from UQpy import SubsetSimulation

# OpenCOSSAN: Open-source COmputational platform for 
# Safety, Reliability ANalysis
import opencossan

# PyRe: Python Reliability
from pyre import subset_simulation
```

### **6.3 ğŸ”— Links Ãšteis**

- **ERA Group (TU MÃ¼nchen):** https://www.cee.ed.tum.de/era/software/
- **UQpy:** https://github.com/SURGroup/UQpy
- **Tutorial Subset Simulation:** https://arxiv.org/abs/1505.03506

---

## **7. ğŸ¯ ConclusÃ£o**

### **7.1 ğŸ’¡ Principais Aprendizados**

Subset Simulation e BUS representam avanÃ§os fundamentais em anÃ¡lise de confiabilidade:

1. **DecomposiÃ§Ã£o Inteligente:** Quebrar problema difÃ­cil em subproblemas tratÃ¡veis
2. **MCMC Condicional:** Amostrar eficientemente de regiÃµes raras
3. **IntegraÃ§Ã£o Bayesiana:** Combinar com inferÃªncia bayesiana para atualizaÃ§Ã£o de modelos
4. **EficiÃªncia:** Ordens de magnitude mais eficiente que Monte Carlo

### **7.2 ğŸ”‘ Quando Usar SUS/BUS**

**âœ… CenÃ¡rios Ideais:**
- AnÃ¡lise de confiabilidade estrutural
- Eventos raros (Pf < 10â»Â³)
- FunÃ§Ã£o de desempenho cara de avaliar
- AtualizaÃ§Ã£o bayesiana com dados limitados
- Necessidade de amostras da regiÃ£o de falha

**âŒ CenÃ¡rios ProblemÃ¡ticos:**
- Probabilidades nÃ£o muito pequenas (usar MC direto)
- Quando gradientes estÃ£o disponÃ­veis (usar FORM/SORM)
- RegiÃµes de falha extremamente desconexas
- Dimensionalidade muito alta (>100)

### **7.3 ğŸŒŸ Mensagem Final**

> **"Subset Simulation nos ensina que problemas aparentemente intratÃ¡veis podem se tornar tratÃ¡veis atravÃ©s de decomposiÃ§Ã£o inteligente e amostragem adaptativa."**

A combinaÃ§Ã£o de Subset Simulation com inferÃªncia bayesiana (BUS) representa uma ferramenta poderosa para anÃ¡lise de confiabilidade e atualizaÃ§Ã£o de modelos em face de incerteza e dados limitados.

---

**ğŸ”— Continue Explorando:**
- ğŸ“– Veja tambÃ©m: [**Cross-Entropy Method**](../optimization/cross_entropy_method.md)
- ğŸ¯ Relacionado: [**Dynamic Bayesian Networks**](../probabilistic_models/dynamic_bayesian_networks.md)
- ğŸ”¬ AplicaÃ§Ãµes: [**Structural Reliability Analysis**](../applications/structural_reliability.md)

**ğŸ“ Obrigado por explorar BUS com Subset Simulation!**
