# Probabilidade B√°sica üé≤

A **teoria de probabilidade** √© o ramo da matem√°tica que estuda fen√¥menos aleat√≥rios e quantifica a incerteza. √â fundamental para estat√≠stica, ci√™ncia de dados, aprendizado de m√°quina e intelig√™ncia artificial.

---

## **1. üéØ Fundamentos Te√≥ricos**

### **1.1 Conceitos Fundamentais**

#### **Experimento Aleat√≥rio**
Um **experimento aleat√≥rio** √© um processo que:
- Pode ser repetido sob as mesmas condi√ß√µes
- Tem resultados poss√≠veis bem definidos
- O resultado espec√≠fico n√£o pode ser previsto com certeza

**Exemplos:**
- üé≤ Lan√ßar um dado
- ü™ô Jogar uma moeda
- üé¥ Tirar uma carta de um baralho
- üå°Ô∏è Medir a temperatura em um dia aleat√≥rio

#### **Espa√ßo Amostral (Œ©)**
Conjunto de **todos os resultados poss√≠veis** de um experimento aleat√≥rio.

**Exemplos:**
```
Lan√ßamento de moeda:    Œ© = {Cara, Coroa}
Lan√ßamento de dado:     Œ© = {1, 2, 3, 4, 5, 6}
Soma de dois dados:     Œ© = {2, 3, 4, ..., 12}
```

#### **Evento (E)**
Um **evento** √© qualquer subconjunto do espa√ßo amostral.

**Exemplos:**
```
E‚ÇÅ = "Obter n√∫mero par no dado"     = {2, 4, 6}
E‚ÇÇ = "Obter n√∫mero maior que 4"    = {5, 6}
E‚ÇÉ = "Obter cara na moeda"         = {Cara}
```

**Tipos de Eventos:**
- **Evento Simples:** Cont√©m apenas um resultado (ex: {3})
- **Evento Composto:** Cont√©m m√∫ltiplos resultados (ex: {2, 4, 6})
- **Evento Certo:** √â o pr√≥prio espa√ßo amostral (Œ©)
- **Evento Imposs√≠vel:** √â o conjunto vazio (‚àÖ)

### **1.2 Defini√ß√£o de Probabilidade**

A probabilidade de um evento E, denotada por P(E), √© um n√∫mero que satisfaz:

**Axiomas de Kolmogorov:**
1. **N√£o-negatividade:** P(E) ‚â• 0 para todo evento E
2. **Normaliza√ß√£o:** P(Œ©) = 1
3. **Aditividade:** Se E‚ÇÅ e E‚ÇÇ s√£o mutuamente exclusivos, ent√£o:
   ```
   P(E‚ÇÅ ‚à™ E‚ÇÇ) = P(E‚ÇÅ) + P(E‚ÇÇ)
   ```

**Propriedades Derivadas:**
```
‚Ä¢ P(‚àÖ) = 0
‚Ä¢ P(E·∂ú) = 1 - P(E)  (probabilidade do complementar)
‚Ä¢ 0 ‚â§ P(E) ‚â§ 1
‚Ä¢ Se E‚ÇÅ ‚äÜ E‚ÇÇ, ent√£o P(E‚ÇÅ) ‚â§ P(E‚ÇÇ)
```

---

## **2. üìä Abordagens para Calcular Probabilidade**

### **2.1 Probabilidade Cl√°ssica (A Priori)**

Usada quando todos os resultados s√£o **igualmente prov√°veis**.

**F√≥rmula:**
```
P(E) = N√∫mero de resultados favor√°veis a E
       ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
       N√∫mero total de resultados poss√≠veis

P(E) = |E|
       ‚îÄ‚îÄ‚îÄ
       |Œ©|
```

**Exemplo 1: Lan√ßamento de Dado**
```
P("obter 4") = 1/6 ‚âà 0.1667 = 16.67%

P("obter n√∫mero par") = P({2,4,6}) = 3/6 = 1/2 = 50%

P("obter n√∫mero ‚â§ 4") = P({1,2,3,4}) = 4/6 = 2/3 ‚âà 66.67%
```

**Exemplo 2: Baralho de 52 Cartas**
```
P("tirar um √Ås") = 4/52 = 1/13 ‚âà 7.69%

P("tirar uma carta de copas") = 13/52 = 1/4 = 25%

P("tirar uma figura") = 12/52 = 3/13 ‚âà 23.08%
```

### **2.2 Probabilidade Frequentista (Emp√≠rica)**

Baseia-se na **frequ√™ncia relativa** observada em experimentos repetidos.

**F√≥rmula:**
```
P(E) = lim   N√∫mero de vezes que E ocorreu
       n‚Üí‚àû   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             N√∫mero total de experimentos

P(E) ‚âà frequ√™ncia relativa = n‚Çë/n
```

**Lei dos Grandes N√∫meros:**
> √Ä medida que o n√∫mero de experimentos aumenta, a frequ√™ncia relativa converge para a probabilidade verdadeira.

**Exemplo: Lan√ßamento de Moeda**
```python
# Simula√ß√£o de lan√ßamentos de moeda
n = 10:        P(Cara) ‚âà 0.60  (60%)
n = 100:       P(Cara) ‚âà 0.52  (52%)
n = 1,000:     P(Cara) ‚âà 0.505 (50.5%)
n = 1,000,000: P(Cara) ‚âà 0.500001 (‚âà50%)
```

**Aplica√ß√µes:**
- Controle de qualidade industrial
- An√°lise de dados hist√≥ricos
- Testes A/B em marketing
- Simula√ß√µes Monte Carlo

### **2.3 Probabilidade Subjetiva (Bayesiana)**

Representa o **grau de cren√ßa** pessoal sobre a ocorr√™ncia de um evento.

**Caracter√≠sticas:**
- Baseada em conhecimento pr√©vio
- Pode ser atualizada com novas evid√™ncias
- Varia entre diferentes observadores

**Exemplo:**
```
"Qual a probabilidade de chover amanh√£?"
- Meteorologista: 70% (baseado em modelos)
- Leigo: 30% (baseado em observa√ß√£o do c√©u)
```

---

## **3. üîß Opera√ß√µes com Eventos**

### **3.1 Uni√£o de Eventos (E‚ÇÅ ‚à™ E‚ÇÇ)**

Evento que ocorre quando **pelo menos um** dos eventos ocorre.

**Regra da Adi√ß√£o:**
```
P(E‚ÇÅ ‚à™ E‚ÇÇ) = P(E‚ÇÅ) + P(E‚ÇÇ) - P(E‚ÇÅ ‚à© E‚ÇÇ)
```

**Caso Especial (eventos mutuamente exclusivos):**
```
Se E‚ÇÅ ‚à© E‚ÇÇ = ‚àÖ, ent√£o:
P(E‚ÇÅ ‚à™ E‚ÇÇ) = P(E‚ÇÅ) + P(E‚ÇÇ)
```

**Exemplo:**
```
Dado de 6 faces:
E‚ÇÅ = "n√∫mero par" = {2, 4, 6}
E‚ÇÇ = "n√∫mero ‚â§ 3" = {1, 2, 3}

E‚ÇÅ ‚à™ E‚ÇÇ = {1, 2, 3, 4, 6}
P(E‚ÇÅ ‚à™ E‚ÇÇ) = P(E‚ÇÅ) + P(E‚ÇÇ) - P(E‚ÇÅ ‚à© E‚ÇÇ)
           = 3/6 + 3/6 - 1/6
           = 5/6 ‚âà 83.33%
```

### **3.2 Interse√ß√£o de Eventos (E‚ÇÅ ‚à© E‚ÇÇ)**

Evento que ocorre quando **ambos** os eventos ocorrem simultaneamente.

**Exemplo:**
```
E‚ÇÅ ‚à© E‚ÇÇ = {2}  (n√∫mero que √© par E menor ou igual a 3)
P(E‚ÇÅ ‚à© E‚ÇÇ) = 1/6 ‚âà 16.67%
```

### **3.3 Complemento de Evento (E·∂ú)**

Evento que ocorre quando E **n√£o ocorre**.

**F√≥rmula:**
```
P(E·∂ú) = 1 - P(E)
```

**Exemplo:**
```
E = "obter n√∫mero par"
E·∂ú = "obter n√∫mero √≠mpar"
P(E·∂ú) = 1 - 3/6 = 1/2 = 50%
```

---

## **4. üé≤ Probabilidade Condicional e Independ√™ncia**

### **4.1 Probabilidade Condicional**

Probabilidade de um evento **dado que outro j√° ocorreu**.

**Defini√ß√£o:**
```
P(A|B) = P(A ‚à© B)
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
           P(B)

L√™-se: "Probabilidade de A dado B"
```

**Exemplo:**
```
Dois lan√ßamentos de dado:
A = "soma √© 8"
B = "primeiro dado √© 3"

P(A|B) = P(soma √© 8 | primeiro √© 3)
       = P({3,5}) / P(primeiro √© 3)
       = (1/36) / (1/6)
       = 1/6 ‚âà 16.67%
```

### **4.2 Teorema de Bayes**

Fundamental para **infer√™ncia estat√≠stica** e **aprendizado de m√°quina**.

**F√≥rmula:**
```
P(A|B) = P(B|A) √ó P(A)
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             P(B)

Onde:
‚Ä¢ P(A|B): Probabilidade a posteriori
‚Ä¢ P(B|A): Verossimilhan√ßa
‚Ä¢ P(A):   Probabilidade a priori
‚Ä¢ P(B):   Evid√™ncia (normaliza√ß√£o)
```

**Forma Expandida:**
```
P(A|B) = P(B|A) √ó P(A)
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
         P(B|A)√óP(A) + P(B|A·∂ú)√óP(A·∂ú)
```

**Exemplo: Teste M√©dico**
```
D = "pessoa tem doen√ßa"
+ = "teste positivo"

Dados:
P(D) = 0.01          (1% da popula√ß√£o tem a doen√ßa)
P(+|D) = 0.95        (sensibilidade: 95%)
P(+|D·∂ú) = 0.05       (taxa de falso positivo: 5%)

Pergunta: Se o teste √© positivo, qual a probabilidade de ter a doen√ßa?

P(D|+) = P(+|D) √ó P(D)
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
         P(+|D)√óP(D) + P(+|D·∂ú)√óP(D·∂ú)

       = 0.95 √ó 0.01
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
         0.95√ó0.01 + 0.05√ó0.99

       = 0.0095
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
         0.0590

       ‚âà 0.161 = 16.1%
```

**Interpreta√ß√£o:** Mesmo com teste positivo, a probabilidade de ter a doen√ßa √© apenas 16.1%! Isso ocorre porque a doen√ßa √© rara.

### **4.3 Independ√™ncia de Eventos**

Dois eventos s√£o **independentes** se a ocorr√™ncia de um n√£o afeta a probabilidade do outro.

**Defini√ß√£o Matem√°tica:**
```
A e B s√£o independentes se e somente se:

P(A ‚à© B) = P(A) √ó P(B)

Equivalentemente:
P(A|B) = P(A)
P(B|A) = P(B)
```

**Exemplo de Eventos Independentes:**
```
Lan√ßamento de dois dados:
A = "primeiro dado √© 4"
B = "segundo dado √© 5"

P(A) = 1/6
P(B) = 1/6
P(A ‚à© B) = 1/36 = (1/6) √ó (1/6) ‚úì
```

**Exemplo de Eventos Dependentes:**
```
Tirar duas cartas sem reposi√ß√£o:
A = "primeira √© √Ås"
B = "segunda √© √Ås"

P(A) = 4/52
P(B|A) = 3/51 ‚â† 4/52
Portanto, A e B s√£o dependentes
```

---

## **5. üìà Distribui√ß√µes de Probabilidade Discretas**

### **5.1 Distribui√ß√£o Uniforme Discreta**

Todos os resultados t√™m a **mesma probabilidade**.

**Fun√ß√£o de Probabilidade:**
```
P(X = x·µ¢) = 1/n

onde n √© o n√∫mero de valores poss√≠veis
```

**Exemplo:**
- Lan√ßamento de dado justo
- Escolha aleat√≥ria de um n√∫mero de loteria

**Propriedades:**
```
M√©dia: Œº = (a + b)/2
Vari√¢ncia: œÉ¬≤ = (n¬≤ - 1)/12
```

### **5.2 Distribui√ß√£o Binomial**

N√∫mero de **sucessos** em n **tentativas independentes** com probabilidade p.

**Fun√ß√£o de Probabilidade:**
```
P(X = k) = C(n,k) √ó p·µè √ó (1-p)‚Åø‚Åª·µè

onde:
‚Ä¢ n = n√∫mero de tentativas
‚Ä¢ k = n√∫mero de sucessos
‚Ä¢ p = probabilidade de sucesso em cada tentativa
‚Ä¢ C(n,k) = n! / (k!(n-k)!)  (combina√ß√£o)
```

**Nota√ß√£o:** X ~ Binomial(n, p)

**Exemplo:**
```
Lan√ßar moeda 10 vezes, qual a probabilidade de 7 caras?

n = 10, k = 7, p = 0.5

P(X = 7) = C(10,7) √ó 0.5‚Å∑ √ó 0.5¬≥
         = 120 √ó 0.5¬π‚Å∞
         ‚âà 0.117 = 11.7%
```

**Propriedades:**
```
M√©dia: Œº = n √ó p
Vari√¢ncia: œÉ¬≤ = n √ó p √ó (1-p)
Desvio Padr√£o: œÉ = ‚àö(n √ó p √ó (1-p))
```

**Aplica√ß√µes:**
- Controle de qualidade (itens defeituosos)
- Testes A/B (convers√µes)
- Pesquisas de opini√£o (respostas sim/n√£o)

### **5.3 Distribui√ß√£o de Poisson**

N√∫mero de **eventos raros** em um intervalo fixo de tempo ou espa√ßo.

**Fun√ß√£o de Probabilidade:**
```
P(X = k) = (Œª·µè √ó e‚ÅªŒª) / k!

onde:
‚Ä¢ Œª = taxa m√©dia de ocorr√™ncias
‚Ä¢ k = n√∫mero de ocorr√™ncias
‚Ä¢ e ‚âà 2.71828
```

**Nota√ß√£o:** X ~ Poisson(Œª)

**Exemplo:**
```
M√©dia de 3 chamadas por hora (Œª = 3)
Probabilidade de 5 chamadas em uma hora?

P(X = 5) = (3‚Åµ √ó e‚Åª¬≥) / 5!
         = (243 √ó 0.0498) / 120
         ‚âà 0.101 = 10.1%
```

**Propriedades:**
```
M√©dia: Œº = Œª
Vari√¢ncia: œÉ¬≤ = Œª
Desvio Padr√£o: œÉ = ‚àöŒª
```

**Aplica√ß√µes:**
- N√∫mero de chamadas em call center
- Chegadas de clientes em fila
- Erros de digita√ß√£o por p√°gina
- Acidentes de tr√¢nsito por dia

### **5.4 Distribui√ß√£o Geom√©trica**

N√∫mero de **tentativas at√© o primeiro sucesso**.

**Fun√ß√£o de Probabilidade:**
```
P(X = k) = (1-p)·µè‚Åª¬π √ó p

onde:
‚Ä¢ p = probabilidade de sucesso
‚Ä¢ k = n√∫mero de tentativas at√© sucesso (k ‚â• 1)
```

**Nota√ß√£o:** X ~ Geom√©trica(p)

**Exemplo:**
```
Probabilidade de acertar = 0.2
Quantas tentativas at√© acertar?

P(X = 1) = 0.2 = 20%           (acerta na primeira)
P(X = 2) = 0.8 √ó 0.2 = 16%     (acerta na segunda)
P(X = 3) = 0.8¬≤ √ó 0.2 = 12.8%  (acerta na terceira)
```

**Propriedades:**
```
M√©dia: Œº = 1/p
Vari√¢ncia: œÉ¬≤ = (1-p)/p¬≤
```

**Propriedade da Falta de Mem√≥ria:**
```
P(X > n + k | X > n) = P(X > k)
```

---

## **6. üéÆ Aplica√ß√µes Pr√°ticas**

### **6.1 Jogos de Azar**

**Probabilidade em Loteria:**
```
Mega-Sena (6 n√∫meros de 60):
P(ganhar) = 1 / C(60,6)
          = 1 / 50,063,860
          ‚âà 0.00000002 = 0.000002%
```

**Probabilidade no Poker:**
```
Royal Flush:
P = 4 / C(52,5)
  = 4 / 2,598,960
  ‚âà 0.000154%
```

### **6.2 Simula√ß√£o Monte Carlo**

T√©cnica que usa **amostragem aleat√≥ria** para resolver problemas num√©ricos.

**Aplica√ß√µes:**
- Precifica√ß√£o de op√ß√µes financeiras
- An√°lise de risco
- F√≠sica computacional
- Otimiza√ß√£o estoc√°stica

**Exemplo: Estimando œÄ**
```python
import random

def estimar_pi(n_pontos):
    dentro_circulo = 0
    for _ in range(n_pontos):
        x = random.random()
        y = random.random()
        if x*x + y*y <= 1:
            dentro_circulo += 1
    
    pi_estimado = 4 * dentro_circulo / n_pontos
    return pi_estimado

# Com 1 milh√£o de pontos
pi_approx = estimar_pi(1_000_000)
# Resultado ‚âà 3.141...
```

### **6.3 Testes de Hip√≥teses**

Probabilidade √© fundamental em **infer√™ncia estat√≠stica**.

**Valor-p (p-value):**
```
Probabilidade de observar dados t√£o extremos quanto os observados,
assumindo que a hip√≥tese nula √© verdadeira.

Se p-value < Œ± (n√≠vel de signific√¢ncia), rejeita H‚ÇÄ
```

**Exemplo:**
```
H‚ÇÄ: Moeda √© justa (p = 0.5)
Observamos: 65 caras em 100 lan√ßamentos

p-value ‚âà 0.003
Se Œ± = 0.05, rejeitamos H‚ÇÄ
Conclus√£o: Evid√™ncia de que a moeda n√£o √© justa
```

### **6.4 Machine Learning**

**Classificadores Probabil√≠sticos:**
- **Naive Bayes:** Usa teorema de Bayes
- **Regress√£o Log√≠stica:** Modela P(Y=1|X)
- **Redes Bayesianas:** Grafos de depend√™ncias probabil√≠sticas

**Exemplo: Filtro de Spam**
```
P(Spam | palavras) = P(palavras | Spam) √ó P(Spam)
                     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                            P(palavras)
```

---

## **7. üìö Conceitos Avan√ßados**

### **7.1 Esperan√ßa (Valor Esperado)**

M√©dia ponderada de todos os valores poss√≠veis.

**Defini√ß√£o:**
```
E[X] = Œ£ x·µ¢ √ó P(X = x·µ¢)
```

**Propriedades:**
```
‚Ä¢ E[aX + b] = a√óE[X] + b
‚Ä¢ E[X + Y] = E[X] + E[Y]
‚Ä¢ Se X e Y independentes: E[X√óY] = E[X]√óE[Y]
```

### **7.2 Vari√¢ncia**

Medida de **dispers√£o** da distribui√ß√£o.

**Defini√ß√£o:**
```
Var(X) = E[(X - Œº)¬≤] = E[X¬≤] - (E[X])¬≤
```

**Propriedades:**
```
‚Ä¢ Var(aX + b) = a¬≤ √ó Var(X)
‚Ä¢ Se X e Y independentes: Var(X+Y) = Var(X) + Var(Y)
```

### **7.3 Covari√¢ncia e Correla√ß√£o**

**Covari√¢ncia:**
```
Cov(X,Y) = E[(X-Œº‚Çì)(Y-Œº·µß)] = E[XY] - E[X]E[Y]
```

**Coeficiente de Correla√ß√£o:**
```
œÅ(X,Y) = Cov(X,Y) / (œÉ‚Çì √ó œÉ·µß)

-1 ‚â§ œÅ ‚â§ 1
```

---

## **8. üßÆ Exerc√≠cios Resolvidos**

### **Exerc√≠cio 1: Probabilidade Cl√°ssica**
**Problema:** Em uma urna h√° 5 bolas vermelhas, 3 azuis e 2 verdes. Qual a probabilidade de retirar uma bola azul?

**Solu√ß√£o:**
```
Total de bolas = 5 + 3 + 2 = 10
Bolas azuis = 3

P(azul) = 3/10 = 0.3 = 30%
```

### **Exerc√≠cio 2: Probabilidade Condicional**
**Problema:** Em uma escola, 60% dos alunos jogam futebol, 40% jogam basquete, e 25% jogam ambos. Qual a probabilidade de um aluno jogar basquete dado que joga futebol?

**Solu√ß√£o:**
```
F = "joga futebol"
B = "joga basquete"

P(F) = 0.60
P(B) = 0.40
P(F ‚à© B) = 0.25

P(B|F) = P(F ‚à© B) / P(F)
       = 0.25 / 0.60
       ‚âà 0.417 = 41.7%
```

### **Exerc√≠cio 3: Teorema de Bayes**
**Problema:** Uma f√°brica tem 3 m√°quinas. M√°quina A produz 50% das pe√ßas (2% defeituosas), B produz 30% (3% defeituosas), C produz 20% (5% defeituosas). Uma pe√ßa √© selecionada e est√° defeituosa. Qual a probabilidade de ser da m√°quina A?

**Solu√ß√£o:**
```
P(A) = 0.50,  P(D|A) = 0.02
P(B) = 0.30,  P(D|B) = 0.03
P(C) = 0.20,  P(D|C) = 0.05

P(D) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)
     = 0.02√ó0.50 + 0.03√ó0.30 + 0.05√ó0.20
     = 0.010 + 0.009 + 0.010
     = 0.029

P(A|D) = P(D|A)√óP(A) / P(D)
       = 0.02√ó0.50 / 0.029
       = 0.010 / 0.029
       ‚âà 0.345 = 34.5%
```

---

## **9. üîó Recursos Adicionais**

### **Livros Recomendados**
- **Introduction to Probability** - Bertsekas & Tsitsiklis (MIT)
- **Probabilidade: Aplica√ß√µes √† Estat√≠stica** - Paul Meyer
- **A First Course in Probability** - Sheldon Ross
- **Probabilidade e Estat√≠stica** - Magalh√£es & Lima

### **Ferramentas Online**
- [Wolfram Alpha](https://www.wolframalpha.com/) - C√°lculos de probabilidade
- [Seeing Theory](https://seeing-theory.brown.edu/) - Visualiza√ß√µes interativas
- [Khan Academy](https://www.khanacademy.org/) - Cursos gratuitos

### **Bibliotecas Python**
```python
import random          # Gera√ß√£o de n√∫meros aleat√≥rios
import numpy as np     # Opera√ß√µes num√©ricas
from scipy import stats # Distribui√ß√µes de probabilidade
import matplotlib.pyplot as plt  # Visualiza√ß√µes
```

---

**Voltar para:** [Estat√≠stica](../README.md) | [Notebooks](../../README.md)
