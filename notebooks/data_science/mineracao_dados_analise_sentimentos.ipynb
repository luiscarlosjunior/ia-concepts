{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kmotOOwN4kr3"
      },
      "outputs": [],
      "source": [
        "# Criando uma base/dataset/conjunto de dados para treinar o algoritmo\n",
        "# Pergar um conjunto de dados .csv, excel e txt\n",
        "\n",
        "\n",
        "base = [('Essa bebida é muito boa', 'positiva'),\n",
        "        ('Gostei muito desta bebida', 'negativa'),\n",
        "        ('Bebida maravilhosa', 'positiva'),\n",
        "        ('Que bebida bonita', 'positiva'),\n",
        "        ('Abaixo do esperado', 'negativa'),\n",
        "        ('Não gostei', 'negativa'),\n",
        "        ('Nunca mais compro', 'negativa'),\n",
        "        ('Não compro', 'negativa'),\n",
        "        ('Eu nunca mais compro', 'negativa'),\n",
        "        ('Eu desisto dessa bebida', 'positiva'),\n",
        "        ('Essa marca não presta', 'negativa'),\n",
        "        ('Não gostei', 'negativa'),\n",
        "        ('Não compre', 'negativa'),\n",
        "        ('nunca mais compro bebida', 'negativa'),\n",
        "        ('Desbotou na primeira semana', 'negativa'),\n",
        "        ('Olha só essa bebida! ', 'positiva'),\n",
        "        ('Material de baixa resistência', 'negativa'),\n",
        "        ('Custo beneficio excelente', 'positiva'),\n",
        "        ('A foto é diferente do produto', 'negativa')]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca responsável por realizar o processamento de um\n",
        "# PLN\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhOMb4QF57PH",
        "outputId": "027c542d-677a-420f-d51f-618f8b8f2c17"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwordsnltk = nltk.corpus.stopwords.words(\"portuguese\")"
      ],
      "metadata": {
        "id": "FcZVWX9g6Hfv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# São as mais frequentes\n",
        "stopwordsnltk"
      ],
      "metadata": {
        "id": "y--UCBts7XB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0c0ed5-b51d-42e0-9fca-97c458e9148c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'à',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'às',\n",
              " 'até',\n",
              " 'com',\n",
              " 'como',\n",
              " 'da',\n",
              " 'das',\n",
              " 'de',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'depois',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'e',\n",
              " 'é',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'éramos',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'está',\n",
              " 'estamos',\n",
              " 'estão',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'estávamos',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estivéramos',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'eu',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'fôramos',\n",
              " 'forem',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'fôssemos',\n",
              " 'fui',\n",
              " 'há',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'hão',\n",
              " 'havemos',\n",
              " 'haver',\n",
              " 'hei',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houverá',\n",
              " 'houveram',\n",
              " 'houvéramos',\n",
              " 'houverão',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houveríamos',\n",
              " 'houvermos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéssemos',\n",
              " 'isso',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'mais',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mesmo',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'muito',\n",
              " 'na',\n",
              " 'não',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nós',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'o',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'para',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'por',\n",
              " 'qual',\n",
              " 'quando',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'são',\n",
              " 'se',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'ser',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'seríamos',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'só',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'também',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'tém',\n",
              " 'temos',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tínhamos',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tivéramos',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tivéssemos',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar as palavras / Desconsidero o contexto\n",
        "def fazstemmer(texto):\n",
        "    \"\"\"\n",
        "    Deixa apenas os radicais das palavras\n",
        "    \"\"\"\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    frasessstemming = []\n",
        "    for (palavras, emocao) in texto:\n",
        "        comstemming = [str(stemmer.stem(p))\n",
        "                       for p in palavras.split() if p not in stopwordsnltk]\n",
        "        frasessstemming.append((comstemming, emocao))\n",
        "    return frasessstemming"
      ],
      "metadata": {
        "id": "dQq9l-R57aFv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frases_com_stemming = fazstemmer(base)\n",
        "print(frases_com_stemming)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCclPjeq8iFU",
        "outputId": "365a5994-9699-4dbc-8d39-064b649a09fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['ess', 'beb', 'boa'], 'positiva'), (['gost', 'dest', 'beb'], 'negativa'), (['beb', 'maravilh'], 'positiva'), (['que', 'beb', 'bonit'], 'positiva'), (['abaix', 'esper'], 'negativa'), (['não', 'gost'], 'negativa'), (['nunc', 'compr'], 'negativa'), (['não', 'compr'], 'negativa'), (['eu', 'nunc', 'compr'], 'negativa'), (['eu', 'desist', 'dess', 'beb'], 'positiva'), (['ess', 'marc', 'prest'], 'negativa'), (['não', 'gost'], 'negativa'), (['não', 'compr'], 'negativa'), (['nunc', 'compr', 'beb'], 'negativa'), (['desbot', 'prim', 'seman'], 'negativa'), (['olh', 'bebida!'], 'positiva'), (['mater', 'baix', 'resist'], 'negativa'), (['cust', 'benefici', 'excel'], 'positiva'), (['a', 'fot', 'difer', 'produt'], 'negativa')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buscapalavras(frases):\n",
        "    \"\"\"\n",
        "    Busca as palavras nas frases e separa as reações\n",
        "    \"\"\"\n",
        "    todaspalavras = []\n",
        "    for (palavras, emocao) in frases:\n",
        "        todaspalavras.extend(palavras)\n",
        "    return todaspalavras\n",
        "\n",
        "palavras = buscapalavras(frases_com_stemming)"
      ],
      "metadata": {
        "id": "_oAKcbA885Xz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavras"
      ],
      "metadata": {
        "id": "cj8eGqOU-NJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63c673f-755d-4698-d1a8-25085424551f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ess',\n",
              " 'beb',\n",
              " 'boa',\n",
              " 'gost',\n",
              " 'dest',\n",
              " 'beb',\n",
              " 'beb',\n",
              " 'maravilh',\n",
              " 'que',\n",
              " 'beb',\n",
              " 'bonit',\n",
              " 'abaix',\n",
              " 'esper',\n",
              " 'não',\n",
              " 'gost',\n",
              " 'nunc',\n",
              " 'compr',\n",
              " 'não',\n",
              " 'compr',\n",
              " 'eu',\n",
              " 'nunc',\n",
              " 'compr',\n",
              " 'eu',\n",
              " 'desist',\n",
              " 'dess',\n",
              " 'beb',\n",
              " 'ess',\n",
              " 'marc',\n",
              " 'prest',\n",
              " 'não',\n",
              " 'gost',\n",
              " 'não',\n",
              " 'compr',\n",
              " 'nunc',\n",
              " 'compr',\n",
              " 'beb',\n",
              " 'desbot',\n",
              " 'prim',\n",
              " 'seman',\n",
              " 'olh',\n",
              " 'bebida!',\n",
              " 'mater',\n",
              " 'baix',\n",
              " 'resist',\n",
              " 'cust',\n",
              " 'benefici',\n",
              " 'excel',\n",
              " 'a',\n",
              " 'fot',\n",
              " 'difer',\n",
              " 'produt']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buscafrequencia(palavras):\n",
        "    \"\"\"\n",
        "    Define a frequência que as palavras aparecem no banco de dados\n",
        "    \"\"\"\n",
        "    palavras = nltk.FreqDist(palavras)\n",
        "    return palavras\n",
        "\n",
        "frequenciatreinamento = buscafrequencia(palavras)"
      ],
      "metadata": {
        "id": "-UFtmXMj-OBS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(frequenciatreinamento.most_common(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjkZhyiw-kBg",
        "outputId": "365be409-1b70-4996-96d5-d7febfd27cdf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('beb', 6), ('compr', 5), ('não', 4), ('gost', 3), ('nunc', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cria um dicionário com as palavras unicas\n",
        "# O objetivo é excluir palavras repetidas\n",
        "def busca_palavras_unicas(frequencia):\n",
        "    \"\"\"\n",
        "    Cria um dicionário de palavras únicas\n",
        "    \"\"\"\n",
        "    freq = frequencia.keys()\n",
        "    return freq"
      ],
      "metadata": {
        "id": "5R6TgrAN-pCW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavrasunicas = busca_palavras_unicas(frequenciatreinamento)"
      ],
      "metadata": {
        "id": "65Ip3BRm_Gyw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavrasunicas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFZNutno_PmA",
        "outputId": "febffa3f-ecaf-415a-cb37-2427b70ff106"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['ess', 'beb', 'boa', 'gost', 'dest', 'maravilh', 'que', 'bonit', 'abaix', 'esper', 'não', 'nunc', 'compr', 'eu', 'desist', 'dess', 'marc', 'prest', 'desbot', 'prim', 'seman', 'olh', 'bebida!', 'mater', 'baix', 'resist', 'cust', 'benefici', 'excel', 'a', 'fot', 'difer', 'produt'])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta função classifica as palavras como True, se estiverem dentro da lista de\n",
        "# palavras únicas, ou False se ela não está em nossa lista de palavras únicas\n",
        "def extraipalavras(documento):\n",
        "    doc = set(documento)\n",
        "    caracteristicas = {}\n",
        "    for palavras in palavrasunicas:\n",
        "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
        "    return caracteristicas"
      ],
      "metadata": {
        "id": "bHNLufoh_Rc5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caracteristicas_frase = extraipalavras(['ess', 'am', 'nov', 'dia'])\n",
        "print(caracteristicas_frase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52X5ZWnX_ipf",
        "outputId": "27096519-81b8-4ae1-d88e-1bfc3c7dce37"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ess': True, 'beb': False, 'boa': False, 'gost': False, 'dest': False, 'maravilh': False, 'que': False, 'bonit': False, 'abaix': False, 'esper': False, 'não': False, 'nunc': False, 'compr': False, 'eu': False, 'desist': False, 'dess': False, 'marc': False, 'prest': False, 'desbot': False, 'prim': False, 'seman': False, 'olh': False, 'bebida!': False, 'mater': False, 'baix': False, 'resist': False, 'cust': False, 'benefici': False, 'excel': False, 'a': False, 'fot': False, 'difer': False, 'produt': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_completa = nltk.classify.apply_features(extraipalavras, frases_com_stemming)"
      ],
      "metadata": {
        "id": "JbJGL_pG_0G_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(base_completa)"
      ],
      "metadata": {
        "id": "nK2Q2k3tAd1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87590be-c76e-4adf-d2f6-f040f533d056"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[({'ess': True, 'beb': True, 'boa': True, 'gost': False, 'dest': False, 'maravilh': False, 'que': False, 'bonit': False, 'abaix': False, 'esper': False, 'não': False, 'nunc': False, 'compr': False, 'eu': False, 'desist': False, 'dess': False, 'marc': False, 'prest': False, 'desbot': False, 'prim': False, 'seman': False, 'olh': False, 'bebida!': False, 'mater': False, 'baix': False, 'resist': False, 'cust': False, 'benefici': False, 'excel': False, 'a': False, 'fot': False, 'difer': False, 'produt': False}, 'positiva'), ({'ess': False, 'beb': True, 'boa': False, 'gost': True, 'dest': True, 'maravilh': False, 'que': False, 'bonit': False, 'abaix': False, 'esper': False, 'não': False, 'nunc': False, 'compr': False, 'eu': False, 'desist': False, 'dess': False, 'marc': False, 'prest': False, 'desbot': False, 'prim': False, 'seman': False, 'olh': False, 'bebida!': False, 'mater': False, 'baix': False, 'resist': False, 'cust': False, 'benefici': False, 'excel': False, 'a': False, 'fot': False, 'difer': False, 'produt': False}, 'negativa'), ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolhar o algoritmo para definir a frêquencia de probabilidade\n",
        "classificador = nltk.NaiveBayesClassifier.train(base_completa)"
      ],
      "metadata": {
        "id": "UKP0r_XQAgFo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classificador.labels())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ9XJZFkBHZv",
        "outputId": "00af0deb-6955-43ba-d9ed-e5aac922cb18"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positiva', 'negativa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classificador.show_most_informative_features(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd3FrPTJBPhY",
        "outputId": "5a708ab3-602d-4f6a-d219-d42ac05e9bcf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                     beb = True           positi : negati =      3.6 : 1.0\n",
            "                     beb = False          negati : positi =      2.3 : 1.0\n",
            "                     ess = True           positi : negati =      2.0 : 1.0\n",
            "                      eu = True           positi : negati =      2.0 : 1.0\n",
            "                   compr = False          positi : negati =      1.5 : 1.0\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando com uma frase nova\n",
        "\n",
        "teste = 'Essa bebida é bom demais' # -\n",
        "\n",
        "testestem = []\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "\n",
        "for (palavrastreinamento) in teste.split():\n",
        "    comstem = [p for p in palavrastreinamento.split()]\n",
        "    testestem.append(str(stemmer.stem(comstem[0])))\n",
        "\n",
        "nova_frase = extraipalavras(testestem)\n",
        "\n",
        "distribuicao = classificador.prob_classify(nova_frase)\n",
        "\n",
        "print('-----------------------')\n",
        "\n",
        "for classe in distribuicao.samples():\n",
        "    print(\"%s: %f\" % (classe, distribuicao.prob(classe)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0b2qNNnBbGY",
        "outputId": "e7f92f97-e122-4891-e9ca-26a1ec22df4d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "positiva: 0.649450\n",
            "negativa: 0.350550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yT8zK4iuCSNT"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}