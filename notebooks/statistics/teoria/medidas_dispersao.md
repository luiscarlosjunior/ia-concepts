# Medidas de DispersÃ£o ğŸ“

As **medidas de dispersÃ£o** (ou variabilidade) quantificam o quanto os dados estÃ£o espalhados em relaÃ§Ã£o Ã  medida de tendÃªncia central. Enquanto mÃ©dia, mediana e moda nos dizem "onde" os dados estÃ£o, as medidas de dispersÃ£o nos dizem "quÃ£o espalhados" eles estÃ£o.

---

## **1. ğŸ¯ Fundamentos TeÃ³ricos**

### **1.1 Por Que Medir DispersÃ£o?**

Considere dois conjuntos de dados com a **mesma mÃ©dia** (50):

```
Grupo A: [48, 49, 50, 51, 52]     â†’ Baixa dispersÃ£o
Grupo B: [10, 30, 50, 70, 90]     â†’ Alta dispersÃ£o

Ambos: MÃ©dia = 50
```

**ImportÃ¢ncia:**
- âœ… Complementa medidas de tendÃªncia central
- âœ… Indica confiabilidade da mÃ©dia
- âœ… Fundamental para inferÃªncia estatÃ­stica
- âœ… Crucial para anÃ¡lise de risco e controle de qualidade
- âœ… Base para muitos algoritmos de ML

---

## **2. ğŸ“Š Amplitude (Range)**

### **2.1 DefiniÃ§Ã£o**

A **amplitude** Ã© a diferenÃ§a entre o maior e o menor valor.

**FÃ³rmula:**
```
R = Xâ‚˜â‚â‚“ - Xâ‚˜áµ¢â‚™
```

**Exemplo:**
```
Temperaturas: [15, 18, 20, 22, 25]

R = 25 - 15 = 10Â°C
```

### **2.2 Vantagens e Desvantagens**

**âœ… Vantagens:**
- Extremamente fÃ¡cil de calcular
- Intuitiva e compreensÃ­vel
- Ãštil para controle de qualidade rÃ¡pido

**âŒ Desvantagens:**
- **Extremamente sensÃ­vel a outliers**
- Usa apenas 2 valores (ignora todos os outros)
- Aumenta com tamanho da amostra
- NÃ£o tem boas propriedades estatÃ­sticas

**Exemplo de Problema:**
```
Dados originais: [10, 11, 12, 13, 14]
R = 14 - 10 = 4

Com outlier: [10, 11, 12, 13, 100]
R = 100 - 10 = 90  â† MudanÃ§a drÃ¡stica!
```

### **2.3 AplicaÃ§Ãµes**

- **Meteorologia:** VariaÃ§Ã£o de temperatura diÃ¡ria
- **FinanÃ§as:** PreÃ§o mÃ¡ximo e mÃ­nimo de aÃ§Ã£o
- **Controle de Qualidade:** TolerÃ¢ncia de mediÃ§Ãµes
- **EstatÃ­stica Descritiva:** VisÃ£o inicial rÃ¡pida

---

## **3. ğŸ“ˆ VariÃ¢ncia**

### **3.1 DefiniÃ§Ã£o**

A **variÃ¢ncia** mede a dispersÃ£o mÃ©dia dos dados em relaÃ§Ã£o Ã  mÃ©dia, usando o quadrado das distÃ¢ncias.

**VariÃ¢ncia Populacional (ÏƒÂ²):**
```
ÏƒÂ² = Î£(xáµ¢ - Î¼)Â² / N

onde:
â€¢ ÏƒÂ² (sigma ao quadrado): variÃ¢ncia populacional
â€¢ Î¼: mÃ©dia populacional
â€¢ N: tamanho da populaÃ§Ã£o
```

**VariÃ¢ncia Amostral (sÂ²):**
```
sÂ² = Î£(xáµ¢ - xÌ„)Â² / (n-1)

onde:
â€¢ sÂ²: variÃ¢ncia amostral
â€¢ xÌ„: mÃ©dia amostral
â€¢ n: tamanho da amostra
â€¢ (n-1): correÃ§Ã£o de Bessel (graus de liberdade)
```

**Por que (n-1)?**
> A correÃ§Ã£o de Bessel torna sÂ² um **estimador nÃ£o-viesado** de ÏƒÂ². Usando n subestimaria a variÃ¢ncia populacional.

### **3.2 CÃ¡lculo Passo a Passo**

**Dados:** [2, 4, 6, 8, 10]

```
Passo 1: Calcular a mÃ©dia
xÌ„ = (2 + 4 + 6 + 8 + 10) / 5 = 30/5 = 6

Passo 2: Calcular desvios
(2-6) = -4
(4-6) = -2
(6-6) = 0
(8-6) = 2
(10-6) = 4

Passo 3: Elevar ao quadrado
(-4)Â² = 16
(-2)Â² = 4
(0)Â² = 0
(2)Â² = 4
(4)Â² = 16

Passo 4: Somar
Î£(xáµ¢ - xÌ„)Â² = 16 + 4 + 0 + 4 + 16 = 40

Passo 5: Dividir por (n-1)
sÂ² = 40 / (5-1) = 40/4 = 10
```

### **3.3 Propriedades MatemÃ¡ticas**

#### **Propriedade 1: FÃ³rmula Alternativa**
```
ÏƒÂ² = E[XÂ²] - (E[X])Â²
   = MÃ©dia dos quadrados - Quadrado da mÃ©dia
```

**Exemplo:**
```
Dados: [2, 4, 6, 8, 10]

E[X] = 6
E[XÂ²] = (4 + 16 + 36 + 64 + 100)/5 = 44

ÏƒÂ² = 44 - 6Â² = 44 - 36 = 8  (para populaÃ§Ã£o)
```

#### **Propriedade 2: TransformaÃ§Ãµes Lineares**
```
Se Y = aX + b, entÃ£o:
Var(Y) = aÂ² Ã— Var(X)

Nota: o termo constante b nÃ£o afeta a variÃ¢ncia!
```

**Exemplo:**
```
Converter Celsius para Fahrenheit: F = 1.8C + 32

Se Var(C) = 25:
Var(F) = 1.8Â² Ã— 25 = 3.24 Ã— 25 = 81
```

#### **Propriedade 3: VariÃ¢ncia de Soma**
```
Para variÃ¡veis independentes:
Var(X + Y) = Var(X) + Var(Y)
Var(X - Y) = Var(X) + Var(Y)  (note que Ã© soma!)
```

### **3.4 InterpretaÃ§Ã£o**

**Unidades:**
- VariÃ¢ncia estÃ¡ em **unidades ao quadrado**
- Se dados em metros, variÃ¢ncia em metrosÂ²
- Dificulta interpretaÃ§Ã£o direta

**Exemplo:**
```
Alturas (cm): [160, 165, 170, 175, 180]
VariÃ¢ncia â‰ˆ 62.5 cmÂ²  â† O que significa 62.5 cmÂ²?
```

### **3.5 AplicaÃ§Ãµes**

- **EstatÃ­stica:** Base para testes de hipÃ³teses
- **FinanÃ§as:** Medida de risco (volatilidade)
- **Machine Learning:** RegularizaÃ§Ã£o, feature selection
- **Controle de Qualidade:** AnÃ¡lise de processo

---

## **4. ğŸ“ Desvio PadrÃ£o**

### **4.1 DefiniÃ§Ã£o**

O **desvio padrÃ£o** Ã© a raiz quadrada da variÃ¢ncia, trazendo a medida de volta Ã s unidades originais.

**FÃ³rmula:**
```
Ïƒ = âˆšÏƒÂ²     (populacional)
s = âˆšsÂ²     (amostral)
```

**Exemplo:**
```
Alturas (cm): [160, 165, 170, 175, 180]
VariÃ¢ncia = 62.5 cmÂ²
Desvio PadrÃ£o = âˆš62.5 â‰ˆ 7.9 cm  â† InterpretÃ¡vel!

InterpretaÃ§Ã£o: Em mÃ©dia, as alturas desviam 7.9 cm da mÃ©dia.
```

### **4.2 InterpretaÃ§Ã£o com Regra EmpÃ­rica**

Para distribuiÃ§Ãµes **aproximadamente normais**:

**Regra 68-95-99.7:**
```
â€¢ Î¼ Â± 1Ïƒ contÃ©m aproximadamente 68% dos dados
â€¢ Î¼ Â± 2Ïƒ contÃ©m aproximadamente 95% dos dados
â€¢ Î¼ Â± 3Ïƒ contÃ©m aproximadamente 99.7% dos dados
```

**VisualizaÃ§Ã£o:**
```
        â”‚       68%
        â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚     95%
        â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚      99.7%
        â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Î¼-3Ïƒ  Î¼-2Ïƒ  Î¼-Ïƒ  Î¼  Î¼+Ïƒ  Î¼+2Ïƒ  Î¼+3Ïƒ
```

**Exemplo:**
```
Altura mÃ©dia = 170 cm, Ïƒ = 8 cm

â€¢ 68% das pessoas: entre 162 cm e 178 cm
â€¢ 95% das pessoas: entre 154 cm e 186 cm
â€¢ 99.7% das pessoas: entre 146 cm e 194 cm
```

### **4.3 Vantagens e Desvantagens**

**âœ… Vantagens:**
- **Mesma unidade dos dados**
- InterpretaÃ§Ã£o intuitiva
- Propriedades matemÃ¡ticas bem definidas
- Amplamente usado em estatÃ­stica

**âŒ Desvantagens:**
- SensÃ­vel a outliers
- NÃ£o adequado para distribuiÃ§Ãµes assimÃ©tricas
- Pode ser influenciado por valores extremos

### **4.4 AplicaÃ§Ãµes**

- **FinanÃ§as:** Volatilidade de ativos
- **Controle de Qualidade:** Six Sigma (6Ïƒ)
- **PadronizaÃ§Ã£o:** Z-scores
- **Machine Learning:** NormalizaÃ§Ã£o de features

---

## **5. ğŸ¯ Coeficiente de VariaÃ§Ã£o**

### **5.1 DefiniÃ§Ã£o**

O **coeficiente de variaÃ§Ã£o (CV)** Ã© a razÃ£o entre desvio padrÃ£o e mÃ©dia, expressa em porcentagem.

**FÃ³rmula:**
```
CV = (Ïƒ / Î¼) Ã— 100%    (populacional)
CV = (s / xÌ„) Ã— 100%    (amostral)
```

### **5.2 Por Que Usar CV?**

**Problema:** Comparar dispersÃµes em escalas diferentes

```
Grupo A (pesos em kg): xÌ„ = 70, s = 5
Grupo B (alturas em cm): xÌ„ = 170, s = 8

QuestÃ£o: Qual grupo Ã© mais disperso?
s nÃ£o permite comparaÃ§Ã£o direta (unidades diferentes)!
```

**SoluÃ§Ã£o:** Coeficiente de VariaÃ§Ã£o
```
CV_A = (5/70) Ã— 100% = 7.14%
CV_B = (8/170) Ã— 100% = 4.71%

ConclusÃ£o: Pesos sÃ£o mais dispersos relativamente!
```

### **5.3 InterpretaÃ§Ã£o**

**ClassificaÃ§Ã£o Geral:**
```
CV < 10%:    Baixa dispersÃ£o (dados homogÃªneos)
10% â‰¤ CV < 20%: DispersÃ£o mÃ©dia
20% â‰¤ CV < 30%: DispersÃ£o alta
CV â‰¥ 30%:    DispersÃ£o muito alta (dados heterogÃªneos)
```

**Vantagens:**
- âœ… **Adimensional** (sem unidades)
- âœ… Permite comparaÃ§Ã£o entre diferentes escalas
- âœ… Ãštil para avaliar precisÃ£o relativa

**LimitaÃ§Ãµes:**
- âŒ NÃ£o definido quando mÃ©dia = 0
- âŒ ProblemÃ¡tico para dados com valores negativos
- âŒ SensÃ­vel a outliers

### **5.4 Exemplo PrÃ¡tico**

**Comparando PrecisÃ£o de MediÃ§Ãµes:**
```
Equipamento A:
â€¢ Mede distÃ¢ncias curtas: Î¼ = 10 cm, Ïƒ = 0.5 cm
â€¢ CV = (0.5/10) Ã— 100% = 5%

Equipamento B:
â€¢ Mede distÃ¢ncias longas: Î¼ = 1000 cm, Ïƒ = 20 cm
â€¢ CV = (20/1000) Ã— 100% = 2%

ConclusÃ£o: Equipamento B Ã© mais preciso relativamente!
```

### **5.5 AplicaÃ§Ãµes**

- **Controle de Qualidade:** Comparar processos
- **FinanÃ§as:** Comparar risco de diferentes ativos
- **Medicina:** Variabilidade de mediÃ§Ãµes clÃ­nicas
- **Pesquisa:** Avaliar consistÃªncia de experimentos

---

## **6. ğŸ“Š Quartis e Amplitude Interquartil (IQR)**

### **6.1 Quartis**

**DefiniÃ§Ã£o:**
Quartis dividem dados ordenados em **quatro partes iguais**.

```
Qâ‚ (1Âº Quartil): 25% dos dados
Qâ‚‚ (2Âº Quartil): 50% dos dados (= Mediana)
Qâ‚ƒ (3Âº Quartil): 75% dos dados
```

**CÃ¡lculo:**
```
Dados ordenados: [1, 2, 3, 4, 5, 6, 7, 8, 9]

PosiÃ§Ã£o Qâ‚ = 0.25 Ã— (n+1) = 0.25 Ã— 10 = 2.5
â†’ Qâ‚ = (2 + 3) / 2 = 2.5

Qâ‚‚ = 5  (mediana)

PosiÃ§Ã£o Qâ‚ƒ = 0.75 Ã— (n+1) = 0.75 Ã— 10 = 7.5
â†’ Qâ‚ƒ = (7 + 8) / 2 = 7.5
```

### **6.2 Amplitude Interquartil (IQR)**

**DefiniÃ§Ã£o:**
```
IQR = Qâ‚ƒ - Qâ‚
```

**InterpretaÃ§Ã£o:**
- ContÃ©m os **50% centrais** dos dados
- **Robusta a outliers** (nÃ£o afetada por valores extremos)

**Exemplo:**
```
Dados: [1, 2, 3, 4, 5, 6, 7, 8, 100]

Qâ‚ = 2.5
Qâ‚ƒ = 7.5
IQR = 7.5 - 2.5 = 5

Nota: O outlier 100 nÃ£o afeta o IQR!

ComparaÃ§Ã£o:
â€¢ Desvio PadrÃ£o â‰ˆ 31.8 (fortemente afetado por 100)
â€¢ IQR = 5 (robusto)
```

### **6.3 Boxplot (Diagrama de Caixa)**

RepresentaÃ§Ã£o visual usando quartis:

```
        outlier
           â—‹
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
     â”‚           â”‚
â”€â”€â”€â”€â”€â”¤     â”‚     â”œâ”€â”€â”€â”€â”€
  mÃ­nâ”‚  Qâ‚ Qâ‚‚ Qâ‚ƒ â”‚mÃ¡x
     â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     
Elementos:
â€¢ Caixa: Qâ‚ a Qâ‚ƒ (IQR)
â€¢ Linha central: Mediana (Qâ‚‚)
â€¢ Whiskers (bigodes): 1.5Ã—IQR de Qâ‚ e Qâ‚ƒ
â€¢ Pontos fora: Outliers
```

### **6.4 DetecÃ§Ã£o de Outliers com IQR**

**MÃ©todo de Tukey:**
```
Lower Fence = Qâ‚ - 1.5 Ã— IQR
Upper Fence = Qâ‚ƒ + 1.5 Ã— IQR

Outliers: valores fora de [Lower Fence, Upper Fence]
```

**Exemplo:**
```
Qâ‚ = 25, Qâ‚ƒ = 75, IQR = 50

Lower Fence = 25 - 1.5Ã—50 = 25 - 75 = -50
Upper Fence = 75 + 1.5Ã—50 = 75 + 75 = 150

Outliers: valores < -50 ou > 150
```

### **6.5 Vantagens do IQR**

**âœ… Comparado ao Desvio PadrÃ£o:**
- Robusto a outliers
- Apropriado para distribuiÃ§Ãµes assimÃ©tricas
- NÃ£o assume normalidade

**AplicaÃ§Ãµes:**
- AnÃ¡lise exploratÃ³ria de dados
- DetecÃ§Ã£o de outliers
- Dados com distribuiÃ§Ãµes nÃ£o-normais
- Controle de qualidade robusto

---

## **7. ğŸŒ Medidas Multivariadas**

### **7.1 CovariÃ¢ncia**

Mede como duas variÃ¡veis **variam juntas**.

**FÃ³rmula:**
```
Cov(X,Y) = Î£(xáµ¢ - xÌ„)(yáµ¢ - È³) / (n-1)
```

**InterpretaÃ§Ã£o:**
```
Cov(X,Y) > 0:  X e Y tendem a aumentar juntas
Cov(X,Y) = 0:  Sem relaÃ§Ã£o linear
Cov(X,Y) < 0:  Quando X aumenta, Y diminui
```

**Problema:** Unidades da covariÃ¢ncia dependem das unidades de X e Y.

**Exemplo:**
```
X = Horas de estudo: [1, 2, 3, 4, 5]
Y = Nota: [50, 60, 70, 80, 90]

Cov(X,Y) = 25 "horasÃ—pontos"  â† DifÃ­cil interpretar!
```

### **7.2 CorrelaÃ§Ã£o de Pearson**

VersÃ£o **normalizada** da covariÃ¢ncia.

**FÃ³rmula:**
```
Ï(X,Y) = Cov(X,Y) / (Ïƒâ‚“ Ã— Ïƒáµ§)

-1 â‰¤ Ï â‰¤ 1
```

**InterpretaÃ§Ã£o:**
```
Ï = +1:  CorrelaÃ§Ã£o linear positiva perfeita
Ï = 0:   Sem correlaÃ§Ã£o linear
Ï = -1:  CorrelaÃ§Ã£o linear negativa perfeita
```

**ClassificaÃ§Ã£o:**
```
|Ï| < 0.3:    CorrelaÃ§Ã£o fraca
0.3 â‰¤ |Ï| < 0.7: CorrelaÃ§Ã£o moderada
|Ï| â‰¥ 0.7:    CorrelaÃ§Ã£o forte
```

**Exemplo:**
```
Continuando exemplo anterior:

Ïƒâ‚“ = 1.58
Ïƒáµ§ = 15.81

Ï = 25 / (1.58 Ã— 15.81) = 25 / 25 = 1.0

ConclusÃ£o: CorrelaÃ§Ã£o perfeita!
```

### **7.3 DistÃ¢ncia de Mahalanobis**

Medida de distÃ¢ncia que considera **covariÃ¢ncia** entre variÃ¡veis.

**FÃ³rmula:**
```
D = âˆš((x - Î¼)áµ€ Î£â»Â¹ (x - Î¼))

onde:
â€¢ x: vetor de observaÃ§Ã£o
â€¢ Î¼: vetor de mÃ©dias
â€¢ Î£: matriz de covariÃ¢ncia
```

**Por que usar?**
- Considera correlaÃ§Ãµes entre variÃ¡veis
- Unidades independentes
- Ãštil para detecÃ§Ã£o de outliers multivariados

**AplicaÃ§Ãµes:**
- DetecÃ§Ã£o de anomalias multivariadas
- ClassificaÃ§Ã£o (AnÃ¡lise Discriminante)
- Teste de normalidade multivariada

---

## **8. ğŸ“Š ComparaÃ§Ã£o das Medidas**

| **Medida** | **Robusta a Outliers** | **Unidades** | **Uso Principal** |
|------------|----------------------|--------------|-------------------|
| **Amplitude** | âŒ NÃ£o | Mesmas dos dados | VisÃ£o rÃ¡pida |
| **VariÃ¢ncia** | âŒ NÃ£o | Quadrado das originais | Base matemÃ¡tica |
| **Desvio PadrÃ£o** | âŒ NÃ£o | Mesmas dos dados | DispersÃ£o interpretÃ¡vel |
| **CV** | âŒ NÃ£o | Adimensional (%) | ComparaÃ§Ãµes relativas |
| **IQR** | âœ… Sim | Mesmas dos dados | Dados assimÃ©tricos |

---

## **9. ğŸ“ AplicaÃ§Ãµes em Machine Learning**

### **9.1 Feature Scaling**

**PadronizaÃ§Ã£o (Z-score):**
```python
z = (x - Î¼) / Ïƒ

# Resultado: mÃ©dia = 0, desvio padrÃ£o = 1
```

**Quando usar:** Algoritmos sensÃ­veis a escala (KNN, SVM, Redes Neurais)

### **9.2 Feature Selection**

**Baixa VariÃ¢ncia = Feature Pouco Informativa**
```python
# Remover features com variÃ¢ncia < threshold
from sklearn.feature_selection import VarianceThreshold

selector = VarianceThreshold(threshold=0.1)
X_new = selector.fit_transform(X)
```

### **9.3 DetecÃ§Ã£o de Anomalias**

**MÃ©todo Z-score:**
```python
z_scores = (data - mean) / std
outliers = data[abs(z_scores) > 3]
```

**MÃ©todo IQR:**
```python
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1

outliers = data[(data < Q1 - 1.5*IQR) | (data > Q3 + 1.5*IQR)]
```

### **9.4 RegularizaÃ§Ã£o**

**Ridge Regression:** Penaliza alta variÃ¢ncia dos coeficientes
```python
# Minimiza: RSS + Î± Ã— Î£Î²Â²
```

---

## **10. ğŸ§® ExercÃ­cios Resolvidos**

### **ExercÃ­cio 1: CÃ¡lculo Completo**
**Problema:** Calcule todas as medidas de dispersÃ£o para: [2, 4, 6, 8, 10]

**SoluÃ§Ã£o:**
```
MÃ©dia: xÌ„ = 6

Amplitude:
R = 10 - 2 = 8

VariÃ¢ncia:
sÂ² = [(2-6)Â² + (4-6)Â² + (6-6)Â² + (8-6)Â² + (10-6)Â²] / 4
   = [16 + 4 + 0 + 4 + 16] / 4
   = 40 / 4 = 10

Desvio PadrÃ£o:
s = âˆš10 â‰ˆ 3.16

Coeficiente de VariaÃ§Ã£o:
CV = (3.16 / 6) Ã— 100% â‰ˆ 52.7%

Quartis:
Qâ‚ = 4, Qâ‚ƒ = 8
IQR = 8 - 4 = 4
```

### **ExercÃ­cio 2: ComparaÃ§Ã£o**
**Problema:** Qual grupo Ã© mais homogÃªneo?
```
Grupo A: xÌ„ = 100, s = 15
Grupo B: xÌ„ = 50, s = 10
```

**SoluÃ§Ã£o:**
```
CV_A = (15/100) Ã— 100% = 15%
CV_B = (10/50) Ã— 100% = 20%

ConclusÃ£o: Grupo A Ã© mais homogÃªneo (menor CV)
```

### **ExercÃ­cio 3: Outliers**
**Problema:** Detecte outliers usando IQR: [10, 12, 14, 15, 16, 18, 20, 25, 100]

**SoluÃ§Ã£o:**
```
Qâ‚ = 13, Qâ‚ƒ = 22.5
IQR = 22.5 - 13 = 9.5

Lower Fence = 13 - 1.5Ã—9.5 = -1.25
Upper Fence = 22.5 + 1.5Ã—9.5 = 36.75

Outliers: 100 (> 36.75)
```

---

## **11. ğŸ’» ImplementaÃ§Ã£o em Python**

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Dados de exemplo
dados = np.array([2, 4, 6, 8, 10])

# Medidas de DispersÃ£o
amplitude = np.ptp(dados)  # Peak to peak
variancia = np.var(dados, ddof=1)  # ddof=1 para amostra
desvio_padrao = np.std(dados, ddof=1)
cv = (desvio_padrao / np.mean(dados)) * 100

# Quartis e IQR
Q1 = np.percentile(dados, 25)
Q3 = np.percentile(dados, 75)
IQR = Q3 - Q1

# DetecÃ§Ã£o de outliers
lower_fence = Q1 - 1.5 * IQR
upper_fence = Q3 + 1.5 * IQR
outliers = dados[(dados < lower_fence) | (dados > upper_fence)]

# Resultados
print(f"Amplitude: {amplitude}")
print(f"VariÃ¢ncia: {variancia:.2f}")
print(f"Desvio PadrÃ£o: {desvio_padrao:.2f}")
print(f"CV: {cv:.2f}%")
print(f"IQR: {IQR}")
print(f"Outliers: {outliers}")

# Boxplot
plt.boxplot(dados)
plt.title("Boxplot dos Dados")
plt.show()
```

---

## **12. ğŸ”— Recursos Adicionais**

### **Livros Recomendados**
- **EstatÃ­stica BÃ¡sica** - Bussab & Morettin
- **Statistics for Data Science** - James et al.
- **Practical Statistics for Data Scientists** - Bruce & Bruce

### **Ferramentas Online**
- [StatKey](http://www.lock5stat.com/statkey/)
- [GeoGebra](https://www.geogebra.org/) - VisualizaÃ§Ãµes
- [Desmos](https://www.desmos.com/calculator) - Calculadora

### **Bibliotecas Python**
```python
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
```

---

**Voltar para:** [EstatÃ­stica](../README.md) | [Notebooks](../../README.md)
